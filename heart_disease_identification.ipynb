{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Identification\n",
    "Binary classification problem for identifying cases of heart disease in patients. Within this exercise we will demonstrate the use of different feature selection methods, as well as compare the performance of a tuned Logistic Regression model against a more advanced Gradient Boosted Machine model on a small sample set.\n",
    "\n",
    "Even with the use of cross-validation we can find that a well-tuned Logit model can perform just as well as a more advanced GBM model on small sample sizes.\n",
    "\n",
    "The data for this example can be found in the following Kaggle link; https://www.kaggle.com/ronitf/heart-disease-uci/version/1#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import statsmodels.formula.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heart_df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa27aa03668>"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(heart_df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for class imbalance\n",
    "Here we see that our binary response variable is not imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Categorical Features \n",
    "\n",
    "We'll need to convert categorical features to dummy variables using pandas. Otherwise the logistic regression model won't be able to directly take in those features as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heart_df = pd.get_dummies(heart_df, columns=['target','sex','fbs','exang','cp','restecg'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training and Testing Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(heart_df.drop('target_1',axis=1), \n",
    "                                                    heart_df['target_1'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = pd.DataFrame(X_train_sc, index=X_train.index, columns = X_train.columns)\n",
    "X_test_sc = pd.DataFrame(X_test_sc, index=X_test.index, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "We will use Backward Elimination, ANOVA, Recursive Feature Elimination (RFE), and Select From Model (SFM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination\n",
    "We running backward elimination we found the following predictor variables to have a statistically significant relationship to our response variable (p > 0.05).\n",
    "* oldpeak\t\n",
    "* ca\t\n",
    "* thal\t\n",
    "* sex_1\n",
    "* exang_1\t\n",
    "* cp_1\t\n",
    "* cp_2\t\n",
    "* cp_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target_1</td>     <th>  R-squared:         </th> <td>   0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   23.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.56e-25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:11:28</td>     <th>  Log-Likelihood:    </th> <td> -82.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   212</td>      <th>  AIC:               </th> <td>   182.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   203</td>      <th>  BIC:               </th> <td>   213.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>constant</th> <td>    0.5566</td> <td>    0.025</td> <td>   22.217</td> <td> 0.000</td> <td>    0.507</td> <td>    0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oldpeak</th>  <td>   -0.1057</td> <td>    0.028</td> <td>   -3.779</td> <td> 0.000</td> <td>   -0.161</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>       <td>   -0.0955</td> <td>    0.027</td> <td>   -3.574</td> <td> 0.000</td> <td>   -0.148</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thal</th>     <td>   -0.0793</td> <td>    0.026</td> <td>   -3.016</td> <td> 0.003</td> <td>   -0.131</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex_1</th>    <td>   -0.0657</td> <td>    0.026</td> <td>   -2.528</td> <td> 0.012</td> <td>   -0.117</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exang_1</th>  <td>   -0.0714</td> <td>    0.028</td> <td>   -2.506</td> <td> 0.013</td> <td>   -0.128</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_1</th>     <td>    0.1036</td> <td>    0.030</td> <td>    3.484</td> <td> 0.001</td> <td>    0.045</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_2</th>     <td>    0.1698</td> <td>    0.030</td> <td>    5.723</td> <td> 0.000</td> <td>    0.111</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_3</th>     <td>    0.0775</td> <td>    0.027</td> <td>    2.839</td> <td> 0.005</td> <td>    0.024</td> <td>    0.131</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.745</td> <th>  Durbin-Watson:     </th> <td>   1.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.154</td> <th>  Jarque-Bera (JB):  </th> <td>   3.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.320</td> <th>  Prob(JB):          </th> <td>   0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.864</td> <th>  Cond. No.          </th> <td>    2.23</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               target_1   R-squared:                       0.484\n",
       "Model:                            OLS   Adj. R-squared:                  0.463\n",
       "Method:                 Least Squares   F-statistic:                     23.77\n",
       "Date:                Thu, 19 Mar 2020   Prob (F-statistic):           1.56e-25\n",
       "Time:                        12:11:28   Log-Likelihood:                -82.423\n",
       "No. Observations:                 212   AIC:                             182.8\n",
       "Df Residuals:                     203   BIC:                             213.1\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "constant       0.5566      0.025     22.217      0.000       0.507       0.606\n",
       "oldpeak       -0.1057      0.028     -3.779      0.000      -0.161      -0.051\n",
       "ca            -0.0955      0.027     -3.574      0.000      -0.148      -0.043\n",
       "thal          -0.0793      0.026     -3.016      0.003      -0.131      -0.027\n",
       "sex_1         -0.0657      0.026     -2.528      0.012      -0.117      -0.014\n",
       "exang_1       -0.0714      0.028     -2.506      0.013      -0.128      -0.015\n",
       "cp_1           0.1036      0.030      3.484      0.001       0.045       0.162\n",
       "cp_2           0.1698      0.030      5.723      0.000       0.111       0.228\n",
       "cp_3           0.0775      0.027      2.839      0.005       0.024       0.131\n",
       "==============================================================================\n",
       "Omnibus:                        3.745   Durbin-Watson:                   1.902\n",
       "Prob(Omnibus):                  0.154   Jarque-Bera (JB):                3.788\n",
       "Skew:                          -0.320   Prob(JB):                        0.150\n",
       "Kurtosis:                       2.864   Cond. No.                         2.23\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc['constant'] = 1\n",
    "X_train_sc = X_train_sc[['constant','age', 'trestbps','chol','thalach','oldpeak','slope','ca','thal','sex_1','fbs_1','exang_1','cp_1','cp_2','cp_3','restecg_1','restecg_2']]\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8,9,10,11,12,13,14,15,16]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 2, 3, 4, 5, 6, 7, 8,9,10,11,12,13,14,15,16]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 2, 3, 4, 5, 6, 7, 8,9,10,11,12,13,14,15]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 2, 3, 4, 5, 6, 7, 8,9,10,11,12,13,14]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 2, 3, 4, 5, 6, 7, 8,9,11,12,13,14]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 2, 4, 5, 6, 7, 8,9,11,12,13,14]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 2, 5, 6, 7, 8,9,11,12,13,14]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 5, 6, 7, 8,9,11,12,13,14]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "X_train_opt = X_train_sc.iloc[:,[0, 5, 7, 8,9,11,12,13,14]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce training and testing data sets to only relevant fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sc['constant'] = 1\n",
    "X_test_sc = X_test_sc[['constant','age', 'trestbps','chol','thalach','oldpeak','slope','ca','thal','sex_1','fbs_1','exang_1','cp_1','cp_2','cp_3','restecg_1','restecg_2']]\n",
    "X_test_opt = X_test_sc.iloc[:, [0, 5, 7, 8,9,11,12,13,14]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure results on from test set using fields identified from Backward Elimination process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  9]\n",
      " [ 6 41]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the opt Training set\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train_opt, y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "y_pred_logreg_be = classifier.predict(X_test_opt)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_logreg_be = confusion_matrix(y_test, y_pred_logreg_be)\n",
    "\n",
    "print(cm_logreg_be)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the precision, recall, and F1 scores when using our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82, 0.8723404255319149, 0.8453608247422681, None)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_be, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View coefficient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>constant</td>\n",
       "      <td>0.123317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>-0.830286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>-0.680969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thal</td>\n",
       "      <td>-0.537372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sex_1</td>\n",
       "      <td>-0.465986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang_1</td>\n",
       "      <td>-0.483228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cp_1</td>\n",
       "      <td>0.460451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cp_2</td>\n",
       "      <td>1.053924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cp_3</td>\n",
       "      <td>0.464026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         0\n",
       "0  constant  0.123317\n",
       "1   oldpeak -0.830286\n",
       "2        ca -0.680969\n",
       "3      thal -0.537372\n",
       "4     sex_1 -0.465986\n",
       "5   exang_1 -0.483228\n",
       "6      cp_1  0.460451\n",
       "7      cp_2  1.053924\n",
       "8      cp_3  0.464026"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(X_test_opt.columns),pd.DataFrame(np.transpose(classifier.coef_))], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA\n",
    "From this exercise we are able to identify the following variables that contain a P value < 0.05. This approach gives us very similar values to use when compared to the Backward Elimination process. However, ANOVA did not perform as well as the Backward Elimination process.\n",
    "* ca\n",
    "* thal\n",
    "* sex_1\n",
    "* exang_1\n",
    "* cp_1\n",
    "* cp_2\n",
    "* cp_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df = X_train_sc.copy()\n",
    "model_df['target'] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>4.74e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:12:28</td>     <th>  Log-Likelihood:    </th> <td> -75.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   212</td>      <th>  AIC:               </th> <td>   185.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   195</td>      <th>  BIC:               </th> <td>   242.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.5566</td> <td>    0.025</td> <td>   22.477</td> <td> 0.000</td> <td>    0.508</td> <td>    0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>   -0.0238</td> <td>    0.030</td> <td>   -0.786</td> <td> 0.433</td> <td>   -0.084</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trestbps</th>  <td>   -0.0360</td> <td>    0.028</td> <td>   -1.298</td> <td> 0.196</td> <td>   -0.091</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>      <td>   -0.0244</td> <td>    0.027</td> <td>   -0.907</td> <td> 0.366</td> <td>   -0.077</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalach</th>   <td>    0.0401</td> <td>    0.032</td> <td>    1.267</td> <td> 0.207</td> <td>   -0.022</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oldpeak</th>   <td>   -0.0536</td> <td>    0.035</td> <td>   -1.525</td> <td> 0.129</td> <td>   -0.123</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>     <td>    0.0490</td> <td>    0.034</td> <td>    1.436</td> <td> 0.153</td> <td>   -0.018</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>        <td>   -0.0918</td> <td>    0.028</td> <td>   -3.319</td> <td> 0.001</td> <td>   -0.146</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thal</th>      <td>   -0.0782</td> <td>    0.027</td> <td>   -2.944</td> <td> 0.004</td> <td>   -0.130</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex_1</th>     <td>   -0.0867</td> <td>    0.027</td> <td>   -3.226</td> <td> 0.001</td> <td>   -0.140</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs_1</th>     <td>    0.0267</td> <td>    0.026</td> <td>    1.026</td> <td> 0.306</td> <td>   -0.025</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exang_1</th>   <td>   -0.0594</td> <td>    0.029</td> <td>   -2.049</td> <td> 0.042</td> <td>   -0.117</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_1</th>      <td>    0.0871</td> <td>    0.030</td> <td>    2.892</td> <td> 0.004</td> <td>    0.028</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_2</th>      <td>    0.1491</td> <td>    0.030</td> <td>    4.903</td> <td> 0.000</td> <td>    0.089</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_3</th>      <td>    0.0738</td> <td>    0.028</td> <td>    2.648</td> <td> 0.009</td> <td>    0.019</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restecg_1</th> <td>    0.0259</td> <td>    0.026</td> <td>    0.986</td> <td> 0.326</td> <td>   -0.026</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restecg_2</th> <td>   -0.0067</td> <td>    0.026</td> <td>   -0.257</td> <td> 0.797</td> <td>   -0.058</td> <td>    0.045</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.329</td> <th>  Durbin-Watson:     </th> <td>   1.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.515</td> <th>  Jarque-Bera (JB):  </th> <td>   1.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.170</td> <th>  Prob(JB):          </th> <td>   0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.786</td> <th>  Cond. No.          </th> <td>    3.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.515\n",
       "Model:                            OLS   Adj. R-squared:                  0.476\n",
       "Method:                 Least Squares   F-statistic:                     12.97\n",
       "Date:                Thu, 19 Mar 2020   Prob (F-statistic):           4.74e-23\n",
       "Time:                        12:12:28   Log-Likelihood:                -75.695\n",
       "No. Observations:                 212   AIC:                             185.4\n",
       "Df Residuals:                     195   BIC:                             242.5\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.5566      0.025     22.477      0.000       0.508       0.605\n",
       "age           -0.0238      0.030     -0.786      0.433      -0.084       0.036\n",
       "trestbps      -0.0360      0.028     -1.298      0.196      -0.091       0.019\n",
       "chol          -0.0244      0.027     -0.907      0.366      -0.077       0.029\n",
       "thalach        0.0401      0.032      1.267      0.207      -0.022       0.102\n",
       "oldpeak       -0.0536      0.035     -1.525      0.129      -0.123       0.016\n",
       "slope          0.0490      0.034      1.436      0.153      -0.018       0.116\n",
       "ca            -0.0918      0.028     -3.319      0.001      -0.146      -0.037\n",
       "thal          -0.0782      0.027     -2.944      0.004      -0.130      -0.026\n",
       "sex_1         -0.0867      0.027     -3.226      0.001      -0.140      -0.034\n",
       "fbs_1          0.0267      0.026      1.026      0.306      -0.025       0.078\n",
       "exang_1       -0.0594      0.029     -2.049      0.042      -0.117      -0.002\n",
       "cp_1           0.0871      0.030      2.892      0.004       0.028       0.147\n",
       "cp_2           0.1491      0.030      4.903      0.000       0.089       0.209\n",
       "cp_3           0.0738      0.028      2.648      0.009       0.019       0.129\n",
       "restecg_1      0.0259      0.026      0.986      0.326      -0.026       0.078\n",
       "restecg_2     -0.0067      0.026     -0.257      0.797      -0.058       0.045\n",
       "==============================================================================\n",
       "Omnibus:                        1.329   Durbin-Watson:                   1.959\n",
       "Prob(Omnibus):                  0.515   Jarque-Bera (JB):                1.428\n",
       "Skew:                          -0.170   Prob(JB):                        0.490\n",
       "Kurtosis:                       2.786   Cond. No.                         3.10\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ols('target ~ age + trestbps + chol + thalach + oldpeak + slope + ca + thal + sex_1 + fbs_1 + exang_1 + cp_1 + cp_2 + cp_3 + restecg_1 + restecg_2', data = model_df).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34 10]\n",
      " [ 6 41]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the opt Training set\n",
    "X_train_opt = X_train_sc[['ca','thal','sex_1','exang_1','cp_1','cp_2','cp_3']].copy()\n",
    "X_test_opt = X_test_sc[['ca','thal','sex_1','exang_1','cp_1','cp_2','cp_3']].copy()\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train_opt, y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "y_pred_logreg_anova = classifier.predict(X_test_opt)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm_logreg_anova = confusion_matrix(y_test, y_pred_logreg_anova)\n",
    "\n",
    "print(cm_logreg_anova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the precision, recall, and F1 scores when using our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.803921568627451, 0.8723404255319149, 0.8367346938775511, None)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_anova, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Selection\n",
    "We can see that the results from using RFE for feature selection do not perform as well as Backward Elimination as RFE requires us to select the desired number of features before modeling. The following predictor variables were identified using the RFS approach.\n",
    "* oldpeak\n",
    "* ca\n",
    "* thal\n",
    "* exang_1\n",
    "* cp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(fit_intercept=False)\n",
    "rfe = RFE(logreg, n_features_to_select=5, step=1)\n",
    "rfe = rfe.fit(X_train_sc, y_train)\n",
    "\n",
    "feature_index = rfe.get_support(True)\n",
    "order = rfe.ranking_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['oldpeak', 'ca', 'thal', 'exang_1', 'cp_2'], dtype='object')"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.columns[feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'ca'),\n",
       " (1, 'cp_2'),\n",
       " (1, 'exang_1'),\n",
       " (1, 'oldpeak'),\n",
       " (1, 'thal'),\n",
       " (2, 'cp_1'),\n",
       " (3, 'cp_3'),\n",
       " (4, 'sex_1'),\n",
       " (5, 'thalach'),\n",
       " (6, 'trestbps'),\n",
       " (7, 'slope'),\n",
       " (8, 'chol'),\n",
       " (9, 'constant'),\n",
       " (10, 'restecg_1'),\n",
       " (11, 'fbs_1'),\n",
       " (12, 'age'),\n",
       " (13, 'restecg_2')]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), X_train_sc.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>exang_1</th>\n",
       "      <th>cp_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>3.892820</td>\n",
       "      <td>-0.713946</td>\n",
       "      <td>1.160793</td>\n",
       "      <td>1.471115</td>\n",
       "      <td>-0.642910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.440462</td>\n",
       "      <td>-0.713946</td>\n",
       "      <td>1.160793</td>\n",
       "      <td>-0.679757</td>\n",
       "      <td>1.555428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.015631</td>\n",
       "      <td>-0.713946</td>\n",
       "      <td>-0.501965</td>\n",
       "      <td>-0.679757</td>\n",
       "      <td>-0.642910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.865294</td>\n",
       "      <td>-0.713946</td>\n",
       "      <td>-0.501965</td>\n",
       "      <td>-0.679757</td>\n",
       "      <td>1.555428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.513763</td>\n",
       "      <td>0.256288</td>\n",
       "      <td>1.160793</td>\n",
       "      <td>1.471115</td>\n",
       "      <td>-0.642910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      oldpeak        ca      thal   exang_1      cp_2\n",
       "221  3.892820 -0.713946  1.160793  1.471115 -0.642910\n",
       "8   -0.440462 -0.713946  1.160793 -0.679757  1.555428\n",
       "89  -0.015631 -0.713946 -0.501965 -0.679757 -0.642910\n",
       "154 -0.865294 -0.713946 -0.501965 -0.679757  1.555428\n",
       "201  1.513763  0.256288  1.160793  1.471115 -0.642910"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc.iloc[:,feature_index].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32 12]\n",
      " [ 7 40]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the opt Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "X_train_opt = X_train_sc.iloc[:,feature_index]\n",
    "classifier.fit(X_train_opt, y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "X_test_opt = X_test_sc.iloc[:,feature_index]\n",
    "y_pred_logreg_rfe = classifier.predict(X_test_opt)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm_logreg_rfe = confusion_matrix(y_test, y_pred_logreg_rfe)\n",
    "\n",
    "print(cm_logreg_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7692307692307693, 0.851063829787234, 0.8080808080808081, None)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_rfe, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select From Model\n",
    "While Backward Elimination performed quite well earlier in our process, the SFM approach slightly outperformed the BE approach. The following predictor variables were identified using the SFM approach.\n",
    "* constant\n",
    "* trestbps\n",
    "* thalach\n",
    "* oldpeak* slope\n",
    "* ca\n",
    "* thal\n",
    "* sex_1\n",
    "* fbs_1\n",
    "* exang_1\n",
    "* cp_1\n",
    "* cp_2\n",
    "* cp_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['constant', 'trestbps', 'thalach', 'oldpeak', 'slope', 'ca', 'thal',\n",
       "       'sex_1', 'fbs_1', 'exang_1', 'cp_1', 'cp_2', 'cp_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf = SelectFromModel(logreg, threshold = 0.05, max_features=13)\n",
    "smf.fit(X_train_sc, y_train)\n",
    "feature_idx = smf.get_support()\n",
    "feature_name = X_train_sc.columns[feature_idx]\n",
    "feature_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  8]\n",
      " [ 5 42]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the opt Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "X_train_opt = X_train_sc.iloc[:,feature_idx]\n",
    "classifier.fit(X_train_opt, y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "X_test_opt = X_test_sc.iloc[:,feature_idx]\n",
    "y_pred_logreg_sfm = classifier.predict(X_test_opt)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm_logreg_sfm = confusion_matrix(y_test, y_pred_logreg_sfm)\n",
    "\n",
    "print(cm_logreg_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84, 0.8936170212765957, 0.8659793814432989, None)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_sfm, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare logit performance across all feature selection techniques\n",
    "Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82, 0.8723404255319149, 0.8453608247422681, None)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_be, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.803921568627451, 0.8723404255319149, 0.8367346938775511, None)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_anova, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7692307692307693, 0.851063829787234, 0.8080808080808081, None)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_rfe, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select From Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84, 0.8936170212765957, 0.8659793814432989, None)"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_sfm, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Logistic Regression\n",
    "Create logistic regression model using the variables identified using the Select From Model approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.360475\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>target</td>      <th>  No. Observations:  </th>  <td>   212</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   199</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 18 Mar 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.4751</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>18:34:43</td>     <th>  Log-Likelihood:    </th> <td> -76.421</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -145.59</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.301e-23</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.2982</td> <td>    0.215</td> <td>    1.385</td> <td> 0.166</td> <td>   -0.124</td> <td>    0.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trestbps</th>  <td>   -0.4288</td> <td>    0.209</td> <td>   -2.053</td> <td> 0.040</td> <td>   -0.838</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalach</th>   <td>    0.3187</td> <td>    0.246</td> <td>    1.295</td> <td> 0.195</td> <td>   -0.164</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oldpeak</th>   <td>   -0.5515</td> <td>    0.308</td> <td>   -1.793</td> <td> 0.073</td> <td>   -1.154</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>     <td>    0.4119</td> <td>    0.299</td> <td>    1.379</td> <td> 0.168</td> <td>   -0.174</td> <td>    0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>        <td>   -0.7651</td> <td>    0.223</td> <td>   -3.424</td> <td> 0.001</td> <td>   -1.203</td> <td>   -0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thal</th>      <td>   -0.5755</td> <td>    0.204</td> <td>   -2.815</td> <td> 0.005</td> <td>   -0.976</td> <td>   -0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex_1</th>     <td>   -0.6724</td> <td>    0.244</td> <td>   -2.756</td> <td> 0.006</td> <td>   -1.151</td> <td>   -0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs_1</th>     <td>    0.2004</td> <td>    0.231</td> <td>    0.866</td> <td> 0.386</td> <td>   -0.253</td> <td>    0.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exang_1</th>   <td>   -0.3910</td> <td>    0.227</td> <td>   -1.724</td> <td> 0.085</td> <td>   -0.836</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_1</th>      <td>    0.4276</td> <td>    0.229</td> <td>    1.866</td> <td> 0.062</td> <td>   -0.022</td> <td>    0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_2</th>      <td>    1.1344</td> <td>    0.256</td> <td>    4.437</td> <td> 0.000</td> <td>    0.633</td> <td>    1.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp_3</th>      <td>    0.5386</td> <td>    0.199</td> <td>    2.709</td> <td> 0.007</td> <td>    0.149</td> <td>    0.928</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                  212\n",
       "Model:                          Logit   Df Residuals:                      199\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Wed, 18 Mar 2020   Pseudo R-squ.:                  0.4751\n",
       "Time:                        18:34:43   Log-Likelihood:                -76.421\n",
       "converged:                       True   LL-Null:                       -145.59\n",
       "                                        LLR p-value:                 1.301e-23\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2982      0.215      1.385      0.166      -0.124       0.720\n",
       "trestbps      -0.4288      0.209     -2.053      0.040      -0.838      -0.019\n",
       "thalach        0.3187      0.246      1.295      0.195      -0.164       0.801\n",
       "oldpeak       -0.5515      0.308     -1.793      0.073      -1.154       0.051\n",
       "slope          0.4119      0.299      1.379      0.168      -0.174       0.997\n",
       "ca            -0.7651      0.223     -3.424      0.001      -1.203      -0.327\n",
       "thal          -0.5755      0.204     -2.815      0.005      -0.976      -0.175\n",
       "sex_1         -0.6724      0.244     -2.756      0.006      -1.151      -0.194\n",
       "fbs_1          0.2004      0.231      0.866      0.386      -0.253       0.654\n",
       "exang_1       -0.3910      0.227     -1.724      0.085      -0.836       0.053\n",
       "cp_1           0.4276      0.229      1.866      0.062      -0.022       0.877\n",
       "cp_2           1.1344      0.256      4.437      0.000       0.633       1.636\n",
       "cp_3           0.5386      0.199      2.709      0.007       0.149       0.928\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = X_train_sc.copy()\n",
    "model_df['target'] = y_train.values\n",
    "\n",
    "model = smf.logit(formula=\"target ~ trestbps + thalach + oldpeak + slope + ca + thal + sex_1 + fbs_1 + exang_1 + cp_1 + cp_2 + cp_3\", data= model_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Machine \n",
    "Now that we have identified the performance of logistic regression models with various feature selection approaches we are going to compare that performance to that of a tree-based forward learning ensemble model. \n",
    "\n",
    "Just like with the logistic regression models we are going to try and optimize the model to account for our relatively small data set (for GBM models). We will run a grid search to identify the optimal hyperparameters and predictor variables to use in the model. \n",
    "\n",
    "We will then compare the performance of our best performing GBM and Logistic Regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_211\"; Java(TM) SE Runtime Environment (build 1.8.0_211-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)\n",
      "  Starting server from /Users/carsonransford/anaconda3/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/9w/d96qt62n1ng_k1j1k7f7231m0000gp/T/tmp5cprmvui\n",
      "  JVM stdout: /var/folders/9w/d96qt62n1ng_k1j1k7f7231m0000gp/T/tmp5cprmvui/h2o_carsonransford_started_from_python.out\n",
      "  JVM stderr: /var/folders/9w/d96qt62n1ng_k1j1k7f7231m0000gp/T/tmp5cprmvui/h2o_carsonransford_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 13 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_carsonransford_96ej56</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>7.111 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         06 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.3\n",
       "H2O cluster version age:    1 month and 13 days\n",
       "H2O cluster name:           H2O_from_python_carsonransford_96ej56\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    7.111 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "df = h2o.H2OFrame(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"target_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  age</th><th style=\"text-align: right;\">  trestbps</th><th style=\"text-align: right;\">  chol</th><th style=\"text-align: right;\">  thalach</th><th style=\"text-align: right;\">  oldpeak</th><th style=\"text-align: right;\">  slope</th><th style=\"text-align: right;\">  ca</th><th style=\"text-align: right;\">  thal</th><th style=\"text-align: right;\">  target_1</th><th style=\"text-align: right;\">  sex_1</th><th style=\"text-align: right;\">  fbs_1</th><th style=\"text-align: right;\">  exang_1</th><th style=\"text-align: right;\">  cp_1</th><th style=\"text-align: right;\">  cp_2</th><th style=\"text-align: right;\">  cp_3</th><th style=\"text-align: right;\">  restecg_1</th><th style=\"text-align: right;\">  restecg_2</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   63</td><td style=\"text-align: right;\">       145</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">      150</td><td style=\"text-align: right;\">      2.3</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   37</td><td style=\"text-align: right;\">       130</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">      187</td><td style=\"text-align: right;\">      3.5</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   41</td><td style=\"text-align: right;\">       130</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">      172</td><td style=\"text-align: right;\">      1.4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   56</td><td style=\"text-align: right;\">       120</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">      178</td><td style=\"text-align: right;\">      0.8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   57</td><td style=\"text-align: right;\">       120</td><td style=\"text-align: right;\">   354</td><td style=\"text-align: right;\">      163</td><td style=\"text-align: right;\">      0.6</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   57</td><td style=\"text-align: right;\">       140</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">      148</td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   56</td><td style=\"text-align: right;\">       140</td><td style=\"text-align: right;\">   294</td><td style=\"text-align: right;\">      153</td><td style=\"text-align: right;\">      1.3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   44</td><td style=\"text-align: right;\">       120</td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">      173</td><td style=\"text-align: right;\">      0  </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   52</td><td style=\"text-align: right;\">       172</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">      162</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   57</td><td style=\"text-align: right;\">       150</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">      174</td><td style=\"text-align: right;\">      1.6</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[response] = df[response].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca', 'thal', 'sex_1', 'fbs_1', 'exang_1', 'cp_1', 'cp_2', 'cp_3', 'restecg_1', 'restecg_2']\n"
     ]
    }
   ],
   "source": [
    "predictors = df.drop(['target_1'], axis = 1).columns\n",
    "# del predictors[-1]\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Testing Approach\n",
    "We are going to first try training our GBM model using training and validation data sets instead of using cross validation. Due to the small sample size of this data set we will most likely get better results using corss validation, but let's compare the performance of this model to another GBM we will make later on which is trained using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = df.split_frame(\n",
    "    ratios=[0.6,0.2], \n",
    "    seed=101, \n",
    "    destination_frames=['train.hex','valid.hex','test.hex']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train basic GBM model with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: || 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1584634725492_1\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10807.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                      50.0              10807.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        5.0        5.0         5.0         8.0        15.0        12.54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.015952584632008802\n",
      "RMSE: 0.12630354164475674\n",
      "LogLoss: 0.09939418398039385\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "AUCPR: 0.9903846153846153\n",
      "Gini: 1.0\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6317179932170792: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/84.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/104.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>84.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/188.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1 Error          Rate\n",
       "0      0  84.0    0.0   0.0    (0.0/84.0)\n",
       "1      1   0.0  104.0   0.0   (0.0/104.0)\n",
       "2  Total  84.0  104.0   0.0   (0.0/188.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.992707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.992707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.992707</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.992707</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.992707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.992707</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.631718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value    idx\n",
       "0                        max f1   0.631718    1.000000  102.0\n",
       "1                        max f2   0.631718    1.000000  102.0\n",
       "2                  max f0point5   0.631718    1.000000  102.0\n",
       "3                  max accuracy   0.631718    1.000000  102.0\n",
       "4                 max precision   0.992707    1.000000    0.0\n",
       "5                    max recall   0.631718    1.000000  102.0\n",
       "6               max specificity   0.992707    1.000000    0.0\n",
       "7              max absolute_mcc   0.631718    1.000000  102.0\n",
       "8    max min_per_class_accuracy   0.631718    1.000000  102.0\n",
       "9   max mean_per_class_accuracy   0.631718    1.000000  102.0\n",
       "10                      max tns   0.992707   84.000000    0.0\n",
       "11                      max fns   0.992707  103.000000    0.0\n",
       "12                      max fps   0.009294   84.000000  186.0\n",
       "13                      max tps   0.631718  104.000000  102.0\n",
       "14                      max tnr   0.992707    1.000000    0.0\n",
       "15                      max fnr   0.992707    0.990385    0.0\n",
       "16                      max fpr   0.009294    1.000000  186.0\n",
       "17                      max tpr   0.631718    1.000000  102.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 55.32 %, avg score: 55.31 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.991542</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992504</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.991380</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991958</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.990672</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991708</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.990364</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991385</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.989046</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991068</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.101064</td>\n",
       "      <td>0.982133</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988863</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.154255</td>\n",
       "      <td>0.977956</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985773</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.972956</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983412</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.939637</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975475</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.892087</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963334</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.778705</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940356</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.601064</td>\n",
       "      <td>0.233330</td>\n",
       "      <td>0.951417</td>\n",
       "      <td>1.663717</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.869201</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.858300</td>\n",
       "      <td>66.371681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.696809</td>\n",
       "      <td>0.127008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.435115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176457</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.774015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>43.511450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.056084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077518</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.685792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.112426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.613240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.242604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.553082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010638         0.991542  1.807692   \n",
       "1         2                  0.021277         0.991380  1.807692   \n",
       "2         3                  0.031915         0.990672  1.807692   \n",
       "3         4                  0.042553         0.990364  1.807692   \n",
       "4         5                  0.053191         0.989046  1.807692   \n",
       "5         6                  0.101064         0.982133  1.807692   \n",
       "6         7                  0.154255         0.977956  1.807692   \n",
       "7         8                  0.202128         0.972956  1.807692   \n",
       "8         9                  0.303191         0.939637  1.807692   \n",
       "9        10                  0.398936         0.892087  1.807692   \n",
       "10       11                  0.500000         0.778705  1.807692   \n",
       "11       12                  0.601064         0.233330  0.951417   \n",
       "12       13                  0.696809         0.127008  0.000000   \n",
       "13       14                  0.797872         0.056084  0.000000   \n",
       "14       15                  0.898936         0.029371  0.000000   \n",
       "15       16                  1.000000         0.009294  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.807692       1.000000  0.992504                  1.000000   \n",
       "1          1.807692       1.000000  0.991411                  1.000000   \n",
       "2          1.807692       1.000000  0.991210                  1.000000   \n",
       "3          1.807692       1.000000  0.990414                  1.000000   \n",
       "4          1.807692       1.000000  0.989799                  1.000000   \n",
       "5          1.807692       1.000000  0.986413                  1.000000   \n",
       "6          1.807692       1.000000  0.979902                  1.000000   \n",
       "7          1.807692       1.000000  0.975804                  1.000000   \n",
       "8          1.807692       1.000000  0.959602                  1.000000   \n",
       "9          1.807692       1.000000  0.924887                  1.000000   \n",
       "10         1.807692       1.000000  0.849653                  1.000000   \n",
       "11         1.663717       0.526316  0.517172                  0.920354   \n",
       "12         1.435115       0.000000  0.176457                  0.793893   \n",
       "13         1.253333       0.000000  0.077518                  0.693333   \n",
       "14         1.112426       0.000000  0.040462                  0.615385   \n",
       "15         1.000000       0.000000  0.017993                  0.553191   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.992504      0.019231                 0.019231   80.769231   \n",
       "1           0.991958      0.019231                 0.038462   80.769231   \n",
       "2           0.991708      0.019231                 0.057692   80.769231   \n",
       "3           0.991385      0.019231                 0.076923   80.769231   \n",
       "4           0.991068      0.019231                 0.096154   80.769231   \n",
       "5           0.988863      0.086538                 0.182692   80.769231   \n",
       "6           0.985773      0.096154                 0.278846   80.769231   \n",
       "7           0.983412      0.086538                 0.365385   80.769231   \n",
       "8           0.975475      0.182692                 0.548077   80.769231   \n",
       "9           0.963334      0.173077                 0.721154   80.769231   \n",
       "10          0.940356      0.182692                 0.903846   80.769231   \n",
       "11          0.869201      0.096154                 1.000000   -4.858300   \n",
       "12          0.774015      0.000000                 1.000000 -100.000000   \n",
       "13          0.685792      0.000000                 1.000000 -100.000000   \n",
       "14          0.613240      0.000000                 1.000000 -100.000000   \n",
       "15          0.553082      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         80.769231  \n",
       "1         80.769231  \n",
       "2         80.769231  \n",
       "3         80.769231  \n",
       "4         80.769231  \n",
       "5         80.769231  \n",
       "6         80.769231  \n",
       "7         80.769231  \n",
       "8         80.769231  \n",
       "9         80.769231  \n",
       "10        80.769231  \n",
       "11        66.371681  \n",
       "12        43.511450  \n",
       "13        25.333333  \n",
       "14        11.242604  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.08637364325082462\n",
      "RMSE: 0.29389393197346664\n",
      "LogLoss: 0.28264176556891873\n",
      "Mean Per-Class Error: 0.08603896103896103\n",
      "AUC: 0.9675324675324675\n",
      "AUCPR: 0.9382781862538968\n",
      "Gini: 0.9350649350649349\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49796601402315904: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>(3.0/22.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>(1.0/28.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>(4.0/50.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1   Error         Rate\n",
       "0      0  19.0   3.0  0.1364   (3.0/22.0)\n",
       "1      1   1.0  27.0  0.0357   (1.0/28.0)\n",
       "2  Total  20.0  30.0    0.08   (4.0/50.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.885902</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>0.838888</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.650724</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>0.913961</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold      value   idx\n",
       "0                        max f1   0.497966   0.931034  29.0\n",
       "1                        max f2   0.432911   0.965517  32.0\n",
       "2                  max f0point5   0.885902   0.925926  19.0\n",
       "3                  max accuracy   0.497966   0.920000  29.0\n",
       "4                 max precision   0.992466   1.000000   0.0\n",
       "5                    max recall   0.432911   1.000000  32.0\n",
       "6               max specificity   0.992466   1.000000   0.0\n",
       "7              max absolute_mcc   0.497966   0.838888  29.0\n",
       "8    max min_per_class_accuracy   0.650724   0.892857  26.0\n",
       "9   max mean_per_class_accuracy   0.497966   0.913961  29.0\n",
       "10                      max tns   0.992466  22.000000   0.0\n",
       "11                      max fns   0.992466  27.000000   0.0\n",
       "12                      max fps   0.010502  22.000000  49.0\n",
       "13                      max tps   0.432911  28.000000  32.0\n",
       "14                      max tnr   0.992466   1.000000   0.0\n",
       "15                      max fnr   0.992466   0.964286   0.0\n",
       "16                      max fpr   0.010502   1.000000  49.0\n",
       "17                      max tpr   0.432911   1.000000  32.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 56.00 %, avg score: 62.17 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.991896</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.991326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.991144</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991884</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.989943</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991578</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.981446</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989829</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.978680</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985937</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.973697</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984034</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.945670</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.869458</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962724</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.748029</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.823816</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.934942</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>64.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.484409</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.607143</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.597069</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>60.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.391290</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.435840</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-64.285714</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.238702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310505</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.752266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.120315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167407</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.687281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031174</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.621671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                      0.02         0.991896  1.785714   \n",
       "1         2                      0.02         0.991326  0.000000   \n",
       "2         3                      0.04         0.991144  1.785714   \n",
       "3         4                      0.04         0.990978  0.000000   \n",
       "4         5                      0.06         0.989943  1.785714   \n",
       "5         6                      0.10         0.981446  1.785714   \n",
       "6         7                      0.16         0.978680  1.785714   \n",
       "7         8                      0.20         0.973697  1.785714   \n",
       "8         9                      0.30         0.945670  1.785714   \n",
       "9        10                      0.40         0.869458  1.785714   \n",
       "10       11                      0.50         0.748029  1.071429   \n",
       "11       12                      0.60         0.484409  1.428571   \n",
       "12       13                      0.70         0.391290  0.357143   \n",
       "13       14                      0.80         0.238702  0.000000   \n",
       "14       15                      0.90         0.120315  0.000000   \n",
       "15       16                      1.00         0.010502  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.785714            1.0  0.992466                  1.000000   \n",
       "1          1.785714            0.0  0.000000                  1.000000   \n",
       "2          1.785714            1.0  0.991303                  1.000000   \n",
       "3          1.785714            0.0  0.000000                  1.000000   \n",
       "4          1.785714            1.0  0.990965                  1.000000   \n",
       "5          1.785714            1.0  0.987206                  1.000000   \n",
       "6          1.785714            1.0  0.979449                  1.000000   \n",
       "7          1.785714            1.0  0.976426                  1.000000   \n",
       "8          1.785714            1.0  0.964406                  1.000000   \n",
       "9          1.785714            1.0  0.918421                  1.000000   \n",
       "10         1.642857            0.6  0.823816                  0.920000   \n",
       "11         1.607143            0.8  0.597069                  0.900000   \n",
       "12         1.428571            0.2  0.435840                  0.800000   \n",
       "13         1.250000            0.0  0.310505                  0.700000   \n",
       "14         1.111111            0.0  0.167407                  0.622222   \n",
       "15         1.000000            0.0  0.031174                  0.560000   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.992466      0.035714                 0.035714   78.571429   \n",
       "1           0.992466      0.000000                 0.035714 -100.000000   \n",
       "2           0.991884      0.035714                 0.071429   78.571429   \n",
       "3           0.991884      0.000000                 0.071429 -100.000000   \n",
       "4           0.991578      0.035714                 0.107143   78.571429   \n",
       "5           0.989829      0.071429                 0.178571   78.571429   \n",
       "6           0.985937      0.107143                 0.285714   78.571429   \n",
       "7           0.984034      0.071429                 0.357143   78.571429   \n",
       "8           0.977492      0.178571                 0.535714   78.571429   \n",
       "9           0.962724      0.178571                 0.714286   78.571429   \n",
       "10          0.934942      0.107143                 0.821429    7.142857   \n",
       "11          0.878630      0.142857                 0.964286   42.857143   \n",
       "12          0.815374      0.035714                 1.000000  -64.285714   \n",
       "13          0.752266      0.000000                 1.000000 -100.000000   \n",
       "14          0.687281      0.000000                 1.000000 -100.000000   \n",
       "15          0.621671      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         78.571429  \n",
       "1         78.571429  \n",
       "2         78.571429  \n",
       "3         78.571429  \n",
       "4         78.571429  \n",
       "5         78.571429  \n",
       "6         78.571429  \n",
       "7         78.571429  \n",
       "8         78.571429  \n",
       "9         78.571429  \n",
       "10        64.285714  \n",
       "11        60.714286  \n",
       "12        42.857143  \n",
       "13        25.000000  \n",
       "14        11.111111  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.016 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497163</td>\n",
       "      <td>0.687478</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.496434</td>\n",
       "      <td>0.686024</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.147 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.470451</td>\n",
       "      <td>0.635144</td>\n",
       "      <td>0.923363</td>\n",
       "      <td>0.612891</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.164894</td>\n",
       "      <td>0.477798</td>\n",
       "      <td>0.649174</td>\n",
       "      <td>0.828734</td>\n",
       "      <td>0.586369</td>\n",
       "      <td>1.587302</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.171 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.444729</td>\n",
       "      <td>0.586922</td>\n",
       "      <td>0.951236</td>\n",
       "      <td>0.887513</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.456635</td>\n",
       "      <td>0.608434</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.810726</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.184 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.422954</td>\n",
       "      <td>0.547324</td>\n",
       "      <td>0.953068</td>\n",
       "      <td>0.888203</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.122340</td>\n",
       "      <td>0.439479</td>\n",
       "      <td>0.576118</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.813088</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.196 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.405012</td>\n",
       "      <td>0.515146</td>\n",
       "      <td>0.956387</td>\n",
       "      <td>0.939401</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.117021</td>\n",
       "      <td>0.431521</td>\n",
       "      <td>0.560441</td>\n",
       "      <td>0.879870</td>\n",
       "      <td>0.871455</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.205 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.388557</td>\n",
       "      <td>0.486291</td>\n",
       "      <td>0.963313</td>\n",
       "      <td>0.943849</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.416367</td>\n",
       "      <td>0.532337</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.215 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.373343</td>\n",
       "      <td>0.459244</td>\n",
       "      <td>0.962626</td>\n",
       "      <td>0.943168</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.111702</td>\n",
       "      <td>0.405559</td>\n",
       "      <td>0.511470</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.902400</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.225 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.361083</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>0.967262</td>\n",
       "      <td>0.946586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.395810</td>\n",
       "      <td>0.493114</td>\n",
       "      <td>0.915584</td>\n",
       "      <td>0.905381</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.235 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.348324</td>\n",
       "      <td>0.415327</td>\n",
       "      <td>0.968178</td>\n",
       "      <td>0.947241</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.111702</td>\n",
       "      <td>0.388276</td>\n",
       "      <td>0.477327</td>\n",
       "      <td>0.915584</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.245 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.337529</td>\n",
       "      <td>0.396030</td>\n",
       "      <td>0.969666</td>\n",
       "      <td>0.967605</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.101064</td>\n",
       "      <td>0.382638</td>\n",
       "      <td>0.464768</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.906276</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.253 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.327704</td>\n",
       "      <td>0.378850</td>\n",
       "      <td>0.971726</td>\n",
       "      <td>0.969120</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.101064</td>\n",
       "      <td>0.372482</td>\n",
       "      <td>0.445866</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.910868</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.261 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.316923</td>\n",
       "      <td>0.360128</td>\n",
       "      <td>0.975504</td>\n",
       "      <td>0.971656</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>0.368733</td>\n",
       "      <td>0.437665</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.907516</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.269 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.308667</td>\n",
       "      <td>0.345632</td>\n",
       "      <td>0.977507</td>\n",
       "      <td>0.973168</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>0.361824</td>\n",
       "      <td>0.424155</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.911243</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.276 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.301792</td>\n",
       "      <td>0.333349</td>\n",
       "      <td>0.978079</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.354478</td>\n",
       "      <td>0.410350</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.917627</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.283 sec</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.293957</td>\n",
       "      <td>0.319730</td>\n",
       "      <td>0.979396</td>\n",
       "      <td>0.974434</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>0.350497</td>\n",
       "      <td>0.402442</td>\n",
       "      <td>0.930195</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.290 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.286736</td>\n",
       "      <td>0.306942</td>\n",
       "      <td>0.980998</td>\n",
       "      <td>0.975713</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>0.342969</td>\n",
       "      <td>0.388274</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.886731</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.298 sec</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.280743</td>\n",
       "      <td>0.296910</td>\n",
       "      <td>0.982257</td>\n",
       "      <td>0.967071</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.343969</td>\n",
       "      <td>0.388003</td>\n",
       "      <td>0.930195</td>\n",
       "      <td>0.916359</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.305 sec</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.274647</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.983745</td>\n",
       "      <td>0.968212</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.337124</td>\n",
       "      <td>0.374999</td>\n",
       "      <td>0.944805</td>\n",
       "      <td>0.922830</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.314 sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.268217</td>\n",
       "      <td>0.275506</td>\n",
       "      <td>0.984890</td>\n",
       "      <td>0.969042</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>0.333695</td>\n",
       "      <td>0.368308</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.923798</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:22:58</td>\n",
       "      <td>0.321 sec</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.262686</td>\n",
       "      <td>0.266237</td>\n",
       "      <td>0.986378</td>\n",
       "      <td>0.970121</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.328143</td>\n",
       "      <td>0.358641</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.924101</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2020-03-19 12:22:58   0.016 sec              0.0       0.497163   \n",
       "1     2020-03-19 12:22:58   0.147 sec              1.0       0.470451   \n",
       "2     2020-03-19 12:22:58   0.171 sec              2.0       0.444729   \n",
       "3     2020-03-19 12:22:58   0.184 sec              3.0       0.422954   \n",
       "4     2020-03-19 12:22:58   0.196 sec              4.0       0.405012   \n",
       "5     2020-03-19 12:22:58   0.205 sec              5.0       0.388557   \n",
       "6     2020-03-19 12:22:58   0.215 sec              6.0       0.373343   \n",
       "7     2020-03-19 12:22:58   0.225 sec              7.0       0.361083   \n",
       "8     2020-03-19 12:22:58   0.235 sec              8.0       0.348324   \n",
       "9     2020-03-19 12:22:58   0.245 sec              9.0       0.337529   \n",
       "10    2020-03-19 12:22:58   0.253 sec             10.0       0.327704   \n",
       "11    2020-03-19 12:22:58   0.261 sec             11.0       0.316923   \n",
       "12    2020-03-19 12:22:58   0.269 sec             12.0       0.308667   \n",
       "13    2020-03-19 12:22:58   0.276 sec             13.0       0.301792   \n",
       "14    2020-03-19 12:22:58   0.283 sec             14.0       0.293957   \n",
       "15    2020-03-19 12:22:58   0.290 sec             15.0       0.286736   \n",
       "16    2020-03-19 12:22:58   0.298 sec             16.0       0.280743   \n",
       "17    2020-03-19 12:22:58   0.305 sec             17.0       0.274647   \n",
       "18    2020-03-19 12:22:58   0.314 sec             18.0       0.268217   \n",
       "19    2020-03-19 12:22:58   0.321 sec             19.0       0.262686   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.687478      0.500000         0.000000       1.000000   \n",
       "1           0.635144      0.923363         0.612891       1.807692   \n",
       "2           0.586922      0.951236         0.887513       1.807692   \n",
       "3           0.547324      0.953068         0.888203       1.807692   \n",
       "4           0.515146      0.956387         0.939401       1.807692   \n",
       "5           0.486291      0.963313         0.943849       1.807692   \n",
       "6           0.459244      0.962626         0.943168       1.807692   \n",
       "7           0.437788      0.967262         0.946586       0.000000   \n",
       "8           0.415327      0.968178         0.947241       1.807692   \n",
       "9           0.396030      0.969666         0.967605       1.807692   \n",
       "10          0.378850      0.971726         0.969120       1.807692   \n",
       "11          0.360128      0.975504         0.971656       1.807692   \n",
       "12          0.345632      0.977507         0.973168       1.807692   \n",
       "13          0.333349      0.978079         0.973557       1.807692   \n",
       "14          0.319730      0.979396         0.974434       1.807692   \n",
       "15          0.306942      0.980998         0.975713       1.807692   \n",
       "16          0.296910      0.982257         0.967071       1.807692   \n",
       "17          0.286275      0.983745         0.968212       1.807692   \n",
       "18          0.275506      0.984890         0.969042       1.807692   \n",
       "19          0.266237      0.986378         0.970121       1.807692   \n",
       "\n",
       "    training_classification_error  validation_rmse  validation_logloss  \\\n",
       "0                        0.446809         0.496434            0.686024   \n",
       "1                        0.164894         0.477798            0.649174   \n",
       "2                        0.132979         0.456635            0.608434   \n",
       "3                        0.122340         0.439479            0.576118   \n",
       "4                        0.117021         0.431521            0.560441   \n",
       "5                        0.106383         0.416367            0.532337   \n",
       "6                        0.111702         0.405559            0.511470   \n",
       "7                        0.106383         0.395810            0.493114   \n",
       "8                        0.111702         0.388276            0.477327   \n",
       "9                        0.101064         0.382638            0.464768   \n",
       "10                       0.101064         0.372482            0.445866   \n",
       "11                       0.090426         0.368733            0.437665   \n",
       "12                       0.090426         0.361824            0.424155   \n",
       "13                       0.085106         0.354478            0.410350   \n",
       "14                       0.079787         0.350497            0.402442   \n",
       "15                       0.069149         0.342969            0.388274   \n",
       "16                       0.074468         0.343969            0.388003   \n",
       "17                       0.074468         0.337124            0.374999   \n",
       "18                       0.069149         0.333695            0.368308   \n",
       "19                       0.063830         0.328143            0.358641   \n",
       "\n",
       "    validation_auc  validation_pr_auc  validation_lift  \\\n",
       "0         0.500000           0.000000         1.000000   \n",
       "1         0.828734           0.586369         1.587302   \n",
       "2         0.883117           0.810726         1.785714   \n",
       "3         0.892045           0.813088         1.785714   \n",
       "4         0.879870           0.871455         1.785714   \n",
       "5         0.909091           0.898990         1.785714   \n",
       "6         0.909091           0.902400         1.785714   \n",
       "7         0.915584           0.905381         1.785714   \n",
       "8         0.915584           0.908044         1.785714   \n",
       "9         0.910714           0.906276         1.785714   \n",
       "10        0.922078           0.910868         1.785714   \n",
       "11        0.917208           0.907516         1.785714   \n",
       "12        0.922078           0.911243         1.785714   \n",
       "13        0.935065           0.917627         1.785714   \n",
       "14        0.930195           0.916418         1.785714   \n",
       "15        0.941558           0.886731         1.785714   \n",
       "16        0.930195           0.916359         1.785714   \n",
       "17        0.944805           0.922830         1.785714   \n",
       "18        0.946429           0.923798         1.785714   \n",
       "19        0.948052           0.924101         1.785714   \n",
       "\n",
       "    validation_classification_error  \n",
       "0                              0.44  \n",
       "1                              0.26  \n",
       "2                              0.16  \n",
       "3                              0.16  \n",
       "4                              0.16  \n",
       "5                              0.16  \n",
       "6                              0.14  \n",
       "7                              0.16  \n",
       "8                              0.14  \n",
       "9                              0.14  \n",
       "10                             0.14  \n",
       "11                             0.14  \n",
       "12                             0.14  \n",
       "13                             0.14  \n",
       "14                             0.12  \n",
       "15                             0.12  \n",
       "16                             0.12  \n",
       "17                             0.12  \n",
       "18                             0.12  \n",
       "19                             0.12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thal</td>\n",
       "      <td>54.316025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>33.044357</td>\n",
       "      <td>0.608372</td>\n",
       "      <td>0.153726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>26.484346</td>\n",
       "      <td>0.487597</td>\n",
       "      <td>0.123208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cp_2</td>\n",
       "      <td>17.351141</td>\n",
       "      <td>0.319448</td>\n",
       "      <td>0.080719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exang_1</td>\n",
       "      <td>16.549093</td>\n",
       "      <td>0.304682</td>\n",
       "      <td>0.076988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thalach</td>\n",
       "      <td>15.429133</td>\n",
       "      <td>0.284062</td>\n",
       "      <td>0.071778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>13.456038</td>\n",
       "      <td>0.247736</td>\n",
       "      <td>0.062599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age</td>\n",
       "      <td>10.744454</td>\n",
       "      <td>0.197814</td>\n",
       "      <td>0.049984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex_1</td>\n",
       "      <td>8.626025</td>\n",
       "      <td>0.158812</td>\n",
       "      <td>0.040129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chol</td>\n",
       "      <td>7.213172</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.033556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slope</td>\n",
       "      <td>4.961172</td>\n",
       "      <td>0.091339</td>\n",
       "      <td>0.023080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>restecg_1</td>\n",
       "      <td>3.355404</td>\n",
       "      <td>0.061776</td>\n",
       "      <td>0.015610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_1</td>\n",
       "      <td>1.380617</td>\n",
       "      <td>0.025418</td>\n",
       "      <td>0.006423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cp_3</td>\n",
       "      <td>1.275838</td>\n",
       "      <td>0.023489</td>\n",
       "      <td>0.005935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fbs_1</td>\n",
       "      <td>0.769779</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>0.003581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variable  relative_importance  scaled_importance  percentage\n",
       "0        thal            54.316025           1.000000    0.252684\n",
       "1          ca            33.044357           0.608372    0.153726\n",
       "2     oldpeak            26.484346           0.487597    0.123208\n",
       "3        cp_2            17.351141           0.319448    0.080719\n",
       "4     exang_1            16.549093           0.304682    0.076988\n",
       "5     thalach            15.429133           0.284062    0.071778\n",
       "6    trestbps            13.456038           0.247736    0.062599\n",
       "7         age            10.744454           0.197814    0.049984\n",
       "8       sex_1             8.626025           0.158812    0.040129\n",
       "9        chol             7.213172           0.132800    0.033556\n",
       "10      slope             4.961172           0.091339    0.023080\n",
       "11  restecg_1             3.355404           0.061776    0.015610\n",
       "12       cp_1             1.380617           0.025418    0.006423\n",
       "13       cp_3             1.275838           0.023489    0.005935\n",
       "14      fbs_1             0.769779           0.014172    0.003581\n",
       "15  restecg_2             0.000000           0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#We only provide the required parameters, everything else is default\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x=predictors, y=response\n",
    "          , training_frame=train\n",
    "          , validation_frame = valid)\n",
    "\n",
    "## Show a detailed model summary\n",
    "print(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8816287878787878\n"
     ]
    }
   ],
   "source": [
    "perf = gbm.model_performance(test)\n",
    "print(perf.auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.1437556325929775\n",
      "RMSE: 0.3791512001734631\n",
      "LogLoss: 0.46121205289080586\n",
      "Mean Per-Class Error: 0.16998106060606055\n",
      "AUC: 0.8816287878787878\n",
      "AUCPR: 0.8421909853217955\n",
      "Gini: 0.7632575757575757\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44081962206639347: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>(7.0/32.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>(4.0/33.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>(11.0/65.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1   Error          Rate\n",
       "0      0  25.0   7.0  0.2188    (7.0/32.0)\n",
       "1      1   4.0  29.0  0.1212    (4.0/33.0)\n",
       "2  Total  29.0  36.0  0.1692   (11.0/65.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.440820</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.189169</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.600304</td>\n",
       "      <td>0.828025</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.440820</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.071525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.440820</td>\n",
       "      <td>0.663820</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.511184</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.440820</td>\n",
       "      <td>0.830019</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.071525</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.071525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold      value   idx\n",
       "0                        max f1   0.440820   0.840580  35.0\n",
       "1                        max f2   0.189169   0.898876  45.0\n",
       "2                  max f0point5   0.600304   0.828025  30.0\n",
       "3                  max accuracy   0.440820   0.830769  35.0\n",
       "4                 max precision   0.992416   1.000000   0.0\n",
       "5                    max recall   0.071525   1.000000  51.0\n",
       "6               max specificity   0.992416   1.000000   0.0\n",
       "7              max absolute_mcc   0.440820   0.663820  35.0\n",
       "8    max min_per_class_accuracy   0.511184   0.812500  32.0\n",
       "9   max mean_per_class_accuracy   0.440820   0.830019  35.0\n",
       "10                      max tns   0.992416  32.000000   0.0\n",
       "11                      max fns   0.992416  32.000000   0.0\n",
       "12                      max fps   0.010091  32.000000  64.0\n",
       "13                      max tps   0.071525  33.000000  51.0\n",
       "14                      max tnr   0.992416   1.000000   0.0\n",
       "15                      max fnr   0.992416   0.969697   0.0\n",
       "16                      max fpr   0.010091   1.000000  64.0\n",
       "17                      max tpr   0.071525   1.000000  51.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 50.77 %, avg score: 52.53 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.991298</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.990144</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991543</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.988945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.988271</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990627</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.987430</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989935</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.983318</td>\n",
       "      <td>1.313131</td>\n",
       "      <td>1.688312</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.984655</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>31.313131</td>\n",
       "      <td>68.831169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.963550</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975926</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>77.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948847</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.976002</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.860756</td>\n",
       "      <td>1.406926</td>\n",
       "      <td>1.674242</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.916047</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.955018</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>40.692641</td>\n",
       "      <td>67.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.736036</td>\n",
       "      <td>1.641414</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.807065</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.920875</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>64.141414</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.511184</td>\n",
       "      <td>1.406926</td>\n",
       "      <td>1.611570</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.658598</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.865240</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>40.692641</td>\n",
       "      <td>61.157025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.362852</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>1.464646</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.432016</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.798590</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>-34.343434</td>\n",
       "      <td>46.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.190369</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>1.356902</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272031</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.728382</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>-34.343434</td>\n",
       "      <td>35.690236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.070083</td>\n",
       "      <td>0.562771</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.133763</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-43.722944</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.030610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.120690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046970</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.586127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>12.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.525254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.015385         0.991298  1.969697   \n",
       "1         2                  0.030769         0.990144  1.969697   \n",
       "2         3                  0.030769         0.988945  0.000000   \n",
       "3         4                  0.046154         0.988271  1.969697   \n",
       "4         5                  0.061538         0.987430  1.969697   \n",
       "5         6                  0.107692         0.983318  1.313131   \n",
       "6         7                  0.153846         0.963550  1.969697   \n",
       "7         8                  0.200000         0.937595  1.969697   \n",
       "8         9                  0.307692         0.860756  1.406926   \n",
       "9        10                  0.400000         0.736036  1.641414   \n",
       "10       11                  0.507692         0.511184  1.406926   \n",
       "11       12                  0.600000         0.362852  0.656566   \n",
       "12       13                  0.692308         0.190369  0.656566   \n",
       "13       14                  0.800000         0.070083  0.562771   \n",
       "14       15                  0.892308         0.030610  0.000000   \n",
       "15       16                  1.000000         0.010091  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.969697       1.000000  0.992416                  1.000000   \n",
       "1          1.969697       1.000000  0.990669                  1.000000   \n",
       "2          1.969697       0.000000  0.000000                  1.000000   \n",
       "3          1.969697       1.000000  0.988795                  1.000000   \n",
       "4          1.969697       1.000000  0.987859                  1.000000   \n",
       "5          1.688312       0.666667  0.984655                  0.857143   \n",
       "6          1.772727       1.000000  0.975926                  0.900000   \n",
       "7          1.818182       1.000000  0.948847                  0.923077   \n",
       "8          1.674242       0.714286  0.916047                  0.850000   \n",
       "9          1.666667       0.833333  0.807065                  0.846154   \n",
       "10         1.611570       0.714286  0.658598                  0.818182   \n",
       "11         1.464646       0.333333  0.432016                  0.743590   \n",
       "12         1.356902       0.333333  0.272031                  0.688889   \n",
       "13         1.250000       0.285714  0.133763                  0.634615   \n",
       "14         1.120690       0.000000  0.046970                  0.568966   \n",
       "15         1.000000       0.000000  0.020873                  0.507692   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.992416      0.030303                 0.030303   96.969697   \n",
       "1           0.991543      0.030303                 0.060606   96.969697   \n",
       "2           0.991543      0.000000                 0.060606 -100.000000   \n",
       "3           0.990627      0.030303                 0.090909   96.969697   \n",
       "4           0.989935      0.030303                 0.121212   96.969697   \n",
       "5           0.987672      0.060606                 0.181818   31.313131   \n",
       "6           0.984148      0.090909                 0.272727   96.969697   \n",
       "7           0.976002      0.090909                 0.363636   96.969697   \n",
       "8           0.955018      0.151515                 0.515152   40.692641   \n",
       "9           0.920875      0.151515                 0.666667   64.141414   \n",
       "10          0.865240      0.151515                 0.818182   40.692641   \n",
       "11          0.798590      0.060606                 0.878788  -34.343434   \n",
       "12          0.728382      0.060606                 0.939394  -34.343434   \n",
       "13          0.648337      0.060606                 1.000000  -43.722944   \n",
       "14          0.586127      0.000000                 1.000000 -100.000000   \n",
       "15          0.525254      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         96.969697  \n",
       "1         96.969697  \n",
       "2         96.969697  \n",
       "3         96.969697  \n",
       "4         96.969697  \n",
       "5         68.831169  \n",
       "6         77.272727  \n",
       "7         81.818182  \n",
       "8         67.424242  \n",
       "9         66.666667  \n",
       "10        61.157025  \n",
       "11        46.464646  \n",
       "12        35.690236  \n",
       "13        25.000000  \n",
       "14        12.068966  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModelMetrics.confusion_matrix of >"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n",
      "0.88\n",
      "0.8435502958579884\n"
     ]
    }
   ],
   "source": [
    "base_gbm_recall = round(29/33 , 2)\n",
    "base_gbm_precision = round(29/36, 2)\n",
    "base_gbm_f1 = 2*((base_gbm_precision * base_gbm_recall)/(base_gbm_precision + base_gbm_recall))\n",
    "\n",
    "print(base_gbm_precision)\n",
    "print(base_gbm_recall)\n",
    "print(base_gbm_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Grid Search, starting with number of trees and then moving onto; learn rate, max depth, row and column sampling, and stratified row sampling\n",
    "* Build as many trees (ntrees) as it takes until the validation set error starts increasing.\n",
    "* A lower learning rate (learn_rate) is generally better, but will require more trees. Using learn_rate=0.02and learn_rate_annealing=0.995 (reduction of learning rate with each additional tree) can help speed up convergence without sacrificing accuracy too much, and is great to hyper-parameter searches. For faster scans, use values of 0.05 and 0.99 instead.\n",
    "* The optimum maximum allowed depth for the trees (max_depth) is data dependent, deeper trees take longer to train, especially at depths greater than 10.\n",
    "* Row and column sampling (sample_rate and col_sample_rate) can improve generalization and lead to lower validation and test set errors. Good general values for large datasets are around 0.7 to 0.8 (sampling 70-80 percent of the data) for both parameters. Column sampling per tree (col_sample_rate_per_tree) can also be tuned. Note that it is multiplicative with col_sample_rate, so setting both parameters to 0.8 results in 64% of columns being considered at any given node to split.\n",
    "* For highly imbalanced classification datasets (e.g., fewer buyers than non-buyers), stratified row sampling based on response class membership can help improve predictive accuracy. It is configured with sample_rate_per_class (array of ratios, one per response class in lexicographic order).\n",
    "* Most other options only have a small impact on the model performance, but are worth tuning with a Random hyper-parameter search nonetheless, if highest performance is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's identify the appropriate max depth of our GBM model. Please note this step can be included in our grid search, but for large data sets this can help reduce the number of model combinations that have to be tested during the grid search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "## Depth 10 is usually plenty of depth for most datasets, but you never know\n",
    "hyper_params = {'max_depth' : [3,5,7,9]}\n",
    "\n",
    "#Build initial GBM Model\n",
    "gbm_grid = H2OGradientBoostingEstimator(\n",
    "        ## more trees is better if the learning rate is small enough \n",
    "        ## here, use \"more than enough\" trees - we have early stopping\n",
    "        ntrees=10000,\n",
    "        ## smaller learning rate is better\n",
    "        ## since we have learning_rate_annealing, we can afford to start with a \n",
    "        #bigger learning rate\n",
    "        learn_rate=0.05,\n",
    "        ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "        ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "        learn_rate_annealing = 0.99,\n",
    "        ## sample 90% of rows per tree\n",
    "        sample_rate = 0.9,\n",
    "        ## sample 90% of columns per split\n",
    "        col_sample_rate = 0.9,\n",
    "        ## fix a random number generator seed for reproducibility\n",
    "        seed = 1234,\n",
    "        ## score every 10 trees to make early stopping reproducible \n",
    "        #(it depends on the scoring interval)\n",
    "        score_tree_interval = 10, \n",
    "        ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "        #5 consecutive scoring events\n",
    "        stopping_rounds = 10,\n",
    "        stopping_metric = \"AUC\",\n",
    "        stopping_tolerance = 1e-4)\n",
    "\n",
    "#Build grid search with previously made GBM and hyper parameters\n",
    "grid = H2OGridSearch(model = gbm_grid\n",
    "                     ,hyper_params = hyper_params,\n",
    "                         grid_id = 'depth_grid',\n",
    "                         search_criteria = {'strategy': \"Cartesian\"})\n",
    "\n",
    "\n",
    "#Train grid search\n",
    "grid.train(x=predictors, \n",
    "           y=response,\n",
    "           training_frame = train,\n",
    "           validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max_depth           model_ids                 auc\n",
      "0           5  depth_grid_model_2  0.9707792207792209\n",
      "1           9  depth_grid_model_4  0.9707792207792209\n",
      "2           7  depth_grid_model_3  0.9691558441558442\n",
      "3           3  depth_grid_model_1  0.9577922077922079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## sort the grid models by decreasing AUC\n",
    "sorted_grid = grid.get_grid(sort_by='auc',decreasing=True)\n",
    "print(sorted_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxDepth 9\n",
      "MinDepth 5\n"
     ]
    }
   ],
   "source": [
    "max_depths = sorted_grid.sorted_metric_table()['max_depth'][0:2]\n",
    "new_max = int(max(max_depths, key=int))\n",
    "new_min = int(min(max_depths, key=int))\n",
    "\n",
    "print(\"MaxDepth \" + str(new_max))\n",
    "print(\"MinDepth \" + str(new_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM hyperparameters\n",
    "gbm_params1 = {'learn_rate': [0.01, 0.1],\n",
    "                'max_depth': [5,9], # range(new_min, new_max),# \n",
    "                'sample_rate': [0.8, 1.0],\n",
    "                'col_sample_rate': [0.8, 0.9]\n",
    "}\n",
    "\n",
    "\n",
    "gbm_grid = H2OGradientBoostingEstimator(\n",
    "        ## more trees is better if the learning rate is small enough \n",
    "        ## here, use \"more than enough\" trees - we have early stopping\n",
    "        ntrees=10000,\n",
    "        ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "        ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "        learn_rate_annealing = 0.99,\n",
    "        ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "        #5 consecutive scoring events\n",
    "        stopping_rounds = 10,\n",
    "        stopping_metric = \"AUC\",\n",
    "        stopping_tolerance = 1e-4,\n",
    "        distribution = \"bernoulli\",\n",
    "        seed = 1234,\n",
    "        score_tree_interval = 10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "# Train and validate a cartesian grid of GBMs\n",
    "gbm_grid1 = H2OGridSearch(model = gbm_grid,\n",
    "                          grid_id = 'gbm_grid1',\n",
    "                          hyper_params = gbm_params1)\n",
    "\n",
    "gbm_grid1.train(x=predictors\n",
    "                , y=response\n",
    "                , training_frame=train\n",
    "                , validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the grid results, sorted by validation AUC\n",
    "gbm_gridperf1 = gbm_grid1.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the model that performed best on our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_grid1_model_15\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>53898.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.431818</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.781818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0              220.0                     220.0              53898.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        5.0        9.0    6.431818        12.0        17.0    14.781818  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0013599875931356504\n",
      "RMSE: 0.03687800961461519\n",
      "LogLoss: 0.025532623785282364\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "AUCPR: 0.9903846153846153\n",
      "Gini: 1.0\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8546836610554706: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/84.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/104.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>84.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/188.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1 Error          Rate\n",
       "0      0  84.0    0.0   0.0    (0.0/84.0)\n",
       "1      1   0.0  104.0   0.0   (0.0/104.0)\n",
       "2  Total  84.0  104.0   0.0   (0.0/188.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.854684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value    idx\n",
       "0                        max f1   0.854684    1.000000  102.0\n",
       "1                        max f2   0.854684    1.000000  102.0\n",
       "2                  max f0point5   0.854684    1.000000  102.0\n",
       "3                  max accuracy   0.854684    1.000000  102.0\n",
       "4                 max precision   0.999475    1.000000    0.0\n",
       "5                    max recall   0.854684    1.000000  102.0\n",
       "6               max specificity   0.999475    1.000000    0.0\n",
       "7              max absolute_mcc   0.854684    1.000000  102.0\n",
       "8    max min_per_class_accuracy   0.854684    1.000000  102.0\n",
       "9   max mean_per_class_accuracy   0.854684    1.000000  102.0\n",
       "10                      max tns   0.999475   84.000000    0.0\n",
       "11                      max fns   0.999475  103.000000    0.0\n",
       "12                      max fps   0.000824   84.000000  186.0\n",
       "13                      max tps   0.854684  104.000000  102.0\n",
       "14                      max tnr   0.999475    1.000000    0.0\n",
       "15                      max fnr   0.999475    0.990385    0.0\n",
       "16                      max fpr   0.000824    1.000000  186.0\n",
       "17                      max tpr   0.854684    1.000000  102.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 55.32 %, avg score: 55.32 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999372</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999308</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999239</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.998896</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.101064</td>\n",
       "      <td>0.997186</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.154255</td>\n",
       "      <td>0.996358</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998002</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.983831</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994817</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.970546</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991164</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.934314</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984686</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>80.769231</td>\n",
       "      <td>80.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.601064</td>\n",
       "      <td>0.071245</td>\n",
       "      <td>0.951417</td>\n",
       "      <td>1.663717</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.520211</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.906588</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.858300</td>\n",
       "      <td>66.371681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.696809</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.435115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049164</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.788774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>43.511450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.691827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.112426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.242604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.553184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010638         0.999357  1.807692   \n",
       "1         2                  0.021277         0.999222  1.807692   \n",
       "2         3                  0.031915         0.999085  1.807692   \n",
       "3         4                  0.042553         0.998999  1.807692   \n",
       "4         5                  0.053191         0.998896  1.807692   \n",
       "5         6                  0.101064         0.997186  1.807692   \n",
       "6         7                  0.154255         0.996358  1.807692   \n",
       "7         8                  0.202128         0.994731  1.807692   \n",
       "8         9                  0.303191         0.983831  1.807692   \n",
       "9        10                  0.398936         0.970546  1.807692   \n",
       "10       11                  0.500000         0.934314  1.807692   \n",
       "11       12                  0.601064         0.071245  0.951417   \n",
       "12       13                  0.696809         0.035713  0.000000   \n",
       "13       14                  0.797872         0.014908  0.000000   \n",
       "14       15                  0.898936         0.004904  0.000000   \n",
       "15       16                  1.000000         0.000824  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.807692       1.000000  0.999423                  1.000000   \n",
       "1          1.807692       1.000000  0.999321                  1.000000   \n",
       "2          1.807692       1.000000  0.999181                  1.000000   \n",
       "3          1.807692       1.000000  0.999031                  1.000000   \n",
       "4          1.807692       1.000000  0.998959                  1.000000   \n",
       "5          1.807692       1.000000  0.998087                  1.000000   \n",
       "6          1.807692       1.000000  0.996744                  1.000000   \n",
       "7          1.807692       1.000000  0.995668                  1.000000   \n",
       "8          1.807692       1.000000  0.989554                  1.000000   \n",
       "9          1.807692       1.000000  0.979593                  1.000000   \n",
       "10         1.807692       1.000000  0.959115                  1.000000   \n",
       "11         1.663717       0.526316  0.520211                  0.920354   \n",
       "12         1.435115       0.000000  0.049164                  0.793893   \n",
       "13         1.253333       0.000000  0.023403                  0.693333   \n",
       "14         1.112426       0.000000  0.009422                  0.615385   \n",
       "15         1.000000       0.000000  0.002394                  0.553191   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.999423      0.019231                 0.019231   80.769231   \n",
       "1           0.999372      0.019231                 0.038462   80.769231   \n",
       "2           0.999308      0.019231                 0.057692   80.769231   \n",
       "3           0.999239      0.019231                 0.076923   80.769231   \n",
       "4           0.999183      0.019231                 0.096154   80.769231   \n",
       "5           0.998664      0.086538                 0.182692   80.769231   \n",
       "6           0.998002      0.096154                 0.278846   80.769231   \n",
       "7           0.997449      0.086538                 0.365385   80.769231   \n",
       "8           0.994817      0.182692                 0.548077   80.769231   \n",
       "9           0.991164      0.173077                 0.721154   80.769231   \n",
       "10          0.984686      0.182692                 0.903846   80.769231   \n",
       "11          0.906588      0.096154                 1.000000   -4.858300   \n",
       "12          0.788774      0.000000                 1.000000 -100.000000   \n",
       "13          0.691827      0.000000                 1.000000 -100.000000   \n",
       "14          0.615107      0.000000                 1.000000 -100.000000   \n",
       "15          0.553184      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         80.769231  \n",
       "1         80.769231  \n",
       "2         80.769231  \n",
       "3         80.769231  \n",
       "4         80.769231  \n",
       "5         80.769231  \n",
       "6         80.769231  \n",
       "7         80.769231  \n",
       "8         80.769231  \n",
       "9         80.769231  \n",
       "10        80.769231  \n",
       "11        66.371681  \n",
       "12        43.511450  \n",
       "13        25.333333  \n",
       "14        11.242604  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.07977682525451289\n",
      "RMSE: 0.282447916003133\n",
      "LogLoss: 0.25544286280320255\n",
      "Mean Per-Class Error: 0.09090909090909083\n",
      "AUC: 0.9659090909090909\n",
      "AUCPR: 0.9371021566664627\n",
      "Gini: 0.9318181818181819\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3987352164623461: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>(4.0/22.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/28.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>(4.0/50.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1   Error         Rate\n",
       "0      0  18.0   4.0  0.1818   (4.0/22.0)\n",
       "1      1   0.0  28.0     0.0   (0.0/28.0)\n",
       "2  Total  18.0  32.0    0.08   (4.0/50.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.962779</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>0.846114</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.398735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold      value   idx\n",
       "0                        max f1   0.398735   0.933333  31.0\n",
       "1                        max f2   0.398735   0.972222  31.0\n",
       "2                  max f0point5   0.962779   0.925926  19.0\n",
       "3                  max accuracy   0.398735   0.920000  31.0\n",
       "4                 max precision   0.999733   1.000000   0.0\n",
       "5                    max recall   0.398735   1.000000  31.0\n",
       "6               max specificity   0.999733   1.000000   0.0\n",
       "7              max absolute_mcc   0.398735   0.846114  31.0\n",
       "8    max min_per_class_accuracy   0.743737   0.892857  26.0\n",
       "9   max mean_per_class_accuracy   0.398735   0.909091  31.0\n",
       "10                      max tns   0.999733  22.000000   0.0\n",
       "11                      max fns   0.999733  27.000000   0.0\n",
       "12                      max fps   0.000848  22.000000  49.0\n",
       "13                      max tps   0.398735  28.000000  31.0\n",
       "14                      max tnr   0.999733   1.000000   0.0\n",
       "15                      max fnr   0.999733   0.964286   0.0\n",
       "16                      max fpr   0.000848   1.000000  49.0\n",
       "17                      max tpr   0.398735   1.000000  31.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 56.00 %, avg score: 61.43 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.998904</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.998562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.998343</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.997430</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.994770</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997751</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.992136</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.982799</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993758</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.932430</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988583</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.812634</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.892264</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.969319</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>64.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.547619</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.656809</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.917234</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>54.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.302690</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.395696</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.842729</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-28.571429</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.086314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173799</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.759112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.044245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062455</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.681706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.614257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                      0.02         0.999488  1.785714   \n",
       "1         2                      0.02         0.999243  0.000000   \n",
       "2         3                      0.04         0.998904  1.785714   \n",
       "3         4                      0.04         0.998562  0.000000   \n",
       "4         5                      0.06         0.998343  1.785714   \n",
       "5         6                      0.10         0.997430  1.785714   \n",
       "6         7                      0.16         0.994770  1.785714   \n",
       "7         8                      0.20         0.992136  1.785714   \n",
       "8         9                      0.30         0.982799  1.785714   \n",
       "9        10                      0.40         0.932430  1.785714   \n",
       "10       11                      0.50         0.812634  1.071429   \n",
       "11       12                      0.60         0.513941  1.071429   \n",
       "12       13                      0.70         0.302690  0.714286   \n",
       "13       14                      0.80         0.086314  0.000000   \n",
       "14       15                      0.90         0.044245  0.000000   \n",
       "15       16                      1.00         0.000848  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.785714            1.0  0.999733                  1.000000   \n",
       "1          1.785714            0.0  0.000000                  1.000000   \n",
       "2          1.785714            1.0  0.999233                  1.000000   \n",
       "3          1.785714            0.0  0.000000                  1.000000   \n",
       "4          1.785714            1.0  0.998534                  1.000000   \n",
       "5          1.785714            1.0  0.997862                  1.000000   \n",
       "6          1.785714            1.0  0.996260                  1.000000   \n",
       "7          1.785714            1.0  0.993983                  1.000000   \n",
       "8          1.785714            1.0  0.987281                  1.000000   \n",
       "9          1.785714            1.0  0.973057                  1.000000   \n",
       "10         1.642857            0.6  0.892264                  0.920000   \n",
       "11         1.547619            0.6  0.656809                  0.866667   \n",
       "12         1.428571            0.4  0.395696                  0.800000   \n",
       "13         1.250000            0.0  0.173799                  0.700000   \n",
       "14         1.111111            0.0  0.062455                  0.622222   \n",
       "15         1.000000            0.0  0.007214                  0.560000   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.999733      0.035714                 0.035714   78.571429   \n",
       "1           0.999733      0.000000                 0.035714 -100.000000   \n",
       "2           0.999483      0.035714                 0.071429   78.571429   \n",
       "3           0.999483      0.000000                 0.071429 -100.000000   \n",
       "4           0.999167      0.035714                 0.107143   78.571429   \n",
       "5           0.998645      0.071429                 0.178571   78.571429   \n",
       "6           0.997751      0.107143                 0.285714   78.571429   \n",
       "7           0.996997      0.071429                 0.357143   78.571429   \n",
       "8           0.993758      0.178571                 0.535714   78.571429   \n",
       "9           0.988583      0.178571                 0.714286   78.571429   \n",
       "10          0.969319      0.107143                 0.821429    7.142857   \n",
       "11          0.917234      0.107143                 0.928571    7.142857   \n",
       "12          0.842729      0.071429                 1.000000  -28.571429   \n",
       "13          0.759112      0.000000                 1.000000 -100.000000   \n",
       "14          0.681706      0.000000                 1.000000 -100.000000   \n",
       "15          0.614257      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         78.571429  \n",
       "1         78.571429  \n",
       "2         78.571429  \n",
       "3         78.571429  \n",
       "4         78.571429  \n",
       "5         78.571429  \n",
       "6         78.571429  \n",
       "7         78.571429  \n",
       "8         78.571429  \n",
       "9         78.571429  \n",
       "10        64.285714  \n",
       "11        54.761905  \n",
       "12        42.857143  \n",
       "13        25.000000  \n",
       "14        11.111111  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.315 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497163</td>\n",
       "      <td>0.687478</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.496434</td>\n",
       "      <td>0.686024</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.326 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.329771</td>\n",
       "      <td>0.384113</td>\n",
       "      <td>0.973729</td>\n",
       "      <td>0.970231</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.369364</td>\n",
       "      <td>0.442565</td>\n",
       "      <td>0.939935</td>\n",
       "      <td>0.924816</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.341 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.263106</td>\n",
       "      <td>0.269052</td>\n",
       "      <td>0.986951</td>\n",
       "      <td>0.980163</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.058511</td>\n",
       "      <td>0.327959</td>\n",
       "      <td>0.358360</td>\n",
       "      <td>0.959416</td>\n",
       "      <td>0.935671</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.360 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.215538</td>\n",
       "      <td>0.198637</td>\n",
       "      <td>0.995765</td>\n",
       "      <td>0.987097</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.037234</td>\n",
       "      <td>0.299098</td>\n",
       "      <td>0.306549</td>\n",
       "      <td>0.970779</td>\n",
       "      <td>0.941326</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.372 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.180857</td>\n",
       "      <td>0.155057</td>\n",
       "      <td>0.999199</td>\n",
       "      <td>0.989775</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.290990</td>\n",
       "      <td>0.287307</td>\n",
       "      <td>0.969156</td>\n",
       "      <td>0.940050</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.389 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.152553</td>\n",
       "      <td>0.123546</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.990202</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.266230</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.943749</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.403 sec</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.127549</td>\n",
       "      <td>0.099626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277237</td>\n",
       "      <td>0.258104</td>\n",
       "      <td>0.975649</td>\n",
       "      <td>0.944641</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.414 sec</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.109938</td>\n",
       "      <td>0.083666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273617</td>\n",
       "      <td>0.248086</td>\n",
       "      <td>0.972403</td>\n",
       "      <td>0.942889</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.425 sec</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.096245</td>\n",
       "      <td>0.071988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279629</td>\n",
       "      <td>0.252739</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.938056</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.437 sec</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.085085</td>\n",
       "      <td>0.062708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.252302</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.939487</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.450 sec</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.076942</td>\n",
       "      <td>0.055949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279658</td>\n",
       "      <td>0.251536</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.939016</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.461 sec</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280604</td>\n",
       "      <td>0.254012</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.939016</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.473 sec</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.063605</td>\n",
       "      <td>0.045285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282711</td>\n",
       "      <td>0.255742</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.937563</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.485 sec</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.058265</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280154</td>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.938764</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.496 sec</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.054091</td>\n",
       "      <td>0.038221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279706</td>\n",
       "      <td>0.251358</td>\n",
       "      <td>0.969156</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.506 sec</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.050863</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281194</td>\n",
       "      <td>0.253462</td>\n",
       "      <td>0.969156</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.517 sec</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.047827</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282493</td>\n",
       "      <td>0.255646</td>\n",
       "      <td>0.969156</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.528 sec</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.045167</td>\n",
       "      <td>0.031672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283647</td>\n",
       "      <td>0.257538</td>\n",
       "      <td>0.969156</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.539 sec</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.043184</td>\n",
       "      <td>0.030090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281917</td>\n",
       "      <td>0.255059</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.938764</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-19 12:31:45</td>\n",
       "      <td>5.550 sec</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.041306</td>\n",
       "      <td>0.028685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282417</td>\n",
       "      <td>0.255548</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.937102</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2020-03-19 12:31:45   5.315 sec              0.0       0.497163   \n",
       "1     2020-03-19 12:31:45   5.326 sec             10.0       0.329771   \n",
       "2     2020-03-19 12:31:45   5.341 sec             20.0       0.263106   \n",
       "3     2020-03-19 12:31:45   5.360 sec             30.0       0.215538   \n",
       "4     2020-03-19 12:31:45   5.372 sec             40.0       0.180857   \n",
       "5     2020-03-19 12:31:45   5.389 sec             50.0       0.152553   \n",
       "6     2020-03-19 12:31:45   5.403 sec             60.0       0.127549   \n",
       "7     2020-03-19 12:31:45   5.414 sec             70.0       0.109938   \n",
       "8     2020-03-19 12:31:45   5.425 sec             80.0       0.096245   \n",
       "9     2020-03-19 12:31:45   5.437 sec             90.0       0.085085   \n",
       "10    2020-03-19 12:31:45   5.450 sec            100.0       0.076942   \n",
       "11    2020-03-19 12:31:45   5.461 sec            110.0       0.069400   \n",
       "12    2020-03-19 12:31:45   5.473 sec            120.0       0.063605   \n",
       "13    2020-03-19 12:31:45   5.485 sec            130.0       0.058265   \n",
       "14    2020-03-19 12:31:45   5.496 sec            140.0       0.054091   \n",
       "15    2020-03-19 12:31:45   5.506 sec            150.0       0.050863   \n",
       "16    2020-03-19 12:31:45   5.517 sec            160.0       0.047827   \n",
       "17    2020-03-19 12:31:45   5.528 sec            170.0       0.045167   \n",
       "18    2020-03-19 12:31:45   5.539 sec            180.0       0.043184   \n",
       "19    2020-03-19 12:31:45   5.550 sec            190.0       0.041306   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.687478      0.500000         0.000000       1.000000   \n",
       "1           0.384113      0.973729         0.970231       1.807692   \n",
       "2           0.269052      0.986951         0.980163       1.807692   \n",
       "3           0.198637      0.995765         0.987097       1.807692   \n",
       "4           0.155057      0.999199         0.989775       1.807692   \n",
       "5           0.123546      0.999771         0.990202       1.807692   \n",
       "6           0.099626      1.000000         0.990385       1.807692   \n",
       "7           0.083666      1.000000         0.990385       1.807692   \n",
       "8           0.071988      1.000000         0.990385       1.807692   \n",
       "9           0.062708      1.000000         0.990385       1.807692   \n",
       "10          0.055949      1.000000         0.990385       1.807692   \n",
       "11          0.049967      1.000000         0.990385       1.807692   \n",
       "12          0.045285      1.000000         0.990385       1.807692   \n",
       "13          0.041458      1.000000         0.990385       1.807692   \n",
       "14          0.038221      1.000000         0.990385       1.807692   \n",
       "15          0.035655      1.000000         0.990385       1.807692   \n",
       "16          0.033590      1.000000         0.990385       1.807692   \n",
       "17          0.031672      1.000000         0.990385       1.807692   \n",
       "18          0.030090      1.000000         0.990385       1.807692   \n",
       "19          0.028685      1.000000         0.990385       1.807692   \n",
       "\n",
       "    training_classification_error  validation_rmse  validation_logloss  \\\n",
       "0                        0.446809         0.496434            0.686024   \n",
       "1                        0.095745         0.369364            0.442565   \n",
       "2                        0.058511         0.327959            0.358360   \n",
       "3                        0.037234         0.299098            0.306549   \n",
       "4                        0.005319         0.290990            0.287307   \n",
       "5                        0.005319         0.279700            0.266230   \n",
       "6                        0.000000         0.277237            0.258104   \n",
       "7                        0.000000         0.273617            0.248086   \n",
       "8                        0.000000         0.279629            0.252739   \n",
       "9                        0.000000         0.280273            0.252302   \n",
       "10                       0.000000         0.279658            0.251536   \n",
       "11                       0.000000         0.280604            0.254012   \n",
       "12                       0.000000         0.282711            0.255742   \n",
       "13                       0.000000         0.280154            0.252569   \n",
       "14                       0.000000         0.279706            0.251358   \n",
       "15                       0.000000         0.281194            0.253462   \n",
       "16                       0.000000         0.282493            0.255646   \n",
       "17                       0.000000         0.283647            0.257538   \n",
       "18                       0.000000         0.281917            0.255059   \n",
       "19                       0.000000         0.282417            0.255548   \n",
       "\n",
       "    validation_auc  validation_pr_auc  validation_lift  \\\n",
       "0         0.500000           0.000000         1.000000   \n",
       "1         0.939935           0.924816         1.785714   \n",
       "2         0.959416           0.935671         1.785714   \n",
       "3         0.970779           0.941326         1.785714   \n",
       "4         0.969156           0.940050         1.785714   \n",
       "5         0.974026           0.943749         1.785714   \n",
       "6         0.975649           0.944641         1.785714   \n",
       "7         0.972403           0.942889         1.785714   \n",
       "8         0.965909           0.938056         1.785714   \n",
       "9         0.967532           0.939487         1.785714   \n",
       "10        0.967532           0.939016         1.785714   \n",
       "11        0.967532           0.939016         1.785714   \n",
       "12        0.965909           0.937563         1.785714   \n",
       "13        0.967532           0.938764         1.785714   \n",
       "14        0.969156           0.940217         1.785714   \n",
       "15        0.969156           0.940217         1.785714   \n",
       "16        0.969156           0.940217         1.785714   \n",
       "17        0.969156           0.940217         1.785714   \n",
       "18        0.967532           0.938764         1.785714   \n",
       "19        0.965909           0.937102         1.785714   \n",
       "\n",
       "    validation_classification_error  \n",
       "0                              0.44  \n",
       "1                              0.10  \n",
       "2                              0.08  \n",
       "3                              0.06  \n",
       "4                              0.08  \n",
       "5                              0.08  \n",
       "6                              0.06  \n",
       "7                              0.08  \n",
       "8                              0.10  \n",
       "9                              0.08  \n",
       "10                             0.08  \n",
       "11                             0.08  \n",
       "12                             0.08  \n",
       "13                             0.08  \n",
       "14                             0.08  \n",
       "15                             0.08  \n",
       "16                             0.08  \n",
       "17                             0.08  \n",
       "18                             0.08  \n",
       "19                             0.08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thal</td>\n",
       "      <td>45.304630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>38.763332</td>\n",
       "      <td>0.855615</td>\n",
       "      <td>0.150643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>31.328876</td>\n",
       "      <td>0.691516</td>\n",
       "      <td>0.121751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>22.862373</td>\n",
       "      <td>0.504637</td>\n",
       "      <td>0.088848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exang_1</td>\n",
       "      <td>20.959801</td>\n",
       "      <td>0.462641</td>\n",
       "      <td>0.081455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cp_2</td>\n",
       "      <td>19.768978</td>\n",
       "      <td>0.436357</td>\n",
       "      <td>0.076827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>18.565571</td>\n",
       "      <td>0.409794</td>\n",
       "      <td>0.072150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thalach</td>\n",
       "      <td>16.391623</td>\n",
       "      <td>0.361809</td>\n",
       "      <td>0.063702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>slope</td>\n",
       "      <td>11.307073</td>\n",
       "      <td>0.249579</td>\n",
       "      <td>0.043942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chol</td>\n",
       "      <td>11.008889</td>\n",
       "      <td>0.242997</td>\n",
       "      <td>0.042783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sex_1</td>\n",
       "      <td>10.688115</td>\n",
       "      <td>0.235917</td>\n",
       "      <td>0.041536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>restecg_1</td>\n",
       "      <td>5.455285</td>\n",
       "      <td>0.120413</td>\n",
       "      <td>0.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_1</td>\n",
       "      <td>1.802177</td>\n",
       "      <td>0.039779</td>\n",
       "      <td>0.007004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cp_3</td>\n",
       "      <td>1.653667</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.006427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fbs_1</td>\n",
       "      <td>1.458409</td>\n",
       "      <td>0.032191</td>\n",
       "      <td>0.005668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variable  relative_importance  scaled_importance  percentage\n",
       "0        thal            45.304630           1.000000    0.176064\n",
       "1          ca            38.763332           0.855615    0.150643\n",
       "2     oldpeak            31.328876           0.691516    0.121751\n",
       "3         age            22.862373           0.504637    0.088848\n",
       "4     exang_1            20.959801           0.462641    0.081455\n",
       "5        cp_2            19.768978           0.436357    0.076827\n",
       "6    trestbps            18.565571           0.409794    0.072150\n",
       "7     thalach            16.391623           0.361809    0.063702\n",
       "8       slope            11.307073           0.249579    0.043942\n",
       "9        chol            11.008889           0.242997    0.042783\n",
       "10      sex_1            10.688115           0.235917    0.041536\n",
       "11  restecg_1             5.455285           0.120413    0.021200\n",
       "12       cp_1             1.802177           0.039779    0.007004\n",
       "13       cp_3             1.653667           0.036501    0.006427\n",
       "14      fbs_1             1.458409           0.032191    0.005668\n",
       "15  restecg_2             0.000000           0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbm = gbm_gridperf1.models[0]\n",
    "best_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.15123610460671078\n",
      "RMSE: 0.3888908646480536\n",
      "LogLoss: 0.5598722142442601\n",
      "Mean Per-Class Error: 0.16903409090909083\n",
      "AUC: 0.8674242424242424\n",
      "AUCPR: 0.8371671021864244\n",
      "Gini: 0.7348484848484849\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5742015621263754: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>(5.0/32.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>(6.0/33.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>(11.0/65.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1   Error          Rate\n",
       "0      0  27.0   5.0  0.1562    (5.0/32.0)\n",
       "1      1   6.0  27.0  0.1818    (6.0/33.0)\n",
       "2  Total  33.0  32.0  0.1692   (11.0/65.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.574202</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.102430</td>\n",
       "      <td>0.893855</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.772241</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.574202</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.574202</td>\n",
       "      <td>0.661932</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.574202</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.574202</td>\n",
       "      <td>0.830966</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold      value   idx\n",
       "0                        max f1   0.574202   0.830769  31.0\n",
       "1                        max f2   0.102430   0.893855  46.0\n",
       "2                  max f0point5   0.772241   0.851064  26.0\n",
       "3                  max accuracy   0.574202   0.830769  31.0\n",
       "4                 max precision   0.999109   1.000000   0.0\n",
       "5                    max recall   0.005463   1.000000  59.0\n",
       "6               max specificity   0.999109   1.000000   0.0\n",
       "7              max absolute_mcc   0.574202   0.661932  31.0\n",
       "8    max min_per_class_accuracy   0.574202   0.818182  31.0\n",
       "9   max mean_per_class_accuracy   0.574202   0.830966  31.0\n",
       "10                      max tns   0.999109  32.000000   0.0\n",
       "11                      max fns   0.999109  32.000000   0.0\n",
       "12                      max fps   0.001299  32.000000  64.0\n",
       "13                      max tps   0.005463  33.000000  59.0\n",
       "14                      max tnr   0.999109   1.000000   0.0\n",
       "15                      max fnr   0.999109   0.969697   0.0\n",
       "16                      max fpr   0.001299   1.000000  64.0\n",
       "17                      max tpr   0.005463   1.000000  59.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 50.77 %, avg score: 52.08 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.999090</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.999013</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.998861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.998630</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998921</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.997777</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.995408</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.983688</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.990258</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.996316</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-34.343434</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.928456</td>\n",
       "      <td>1.688312</td>\n",
       "      <td>1.674242</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.984893</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>68.831169</td>\n",
       "      <td>67.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.789023</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.742424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868339</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.957996</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>74.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.537706</td>\n",
       "      <td>1.125541</td>\n",
       "      <td>1.611570</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.638228</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.890167</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>12.554113</td>\n",
       "      <td>61.157025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.287626</td>\n",
       "      <td>0.328283</td>\n",
       "      <td>1.414141</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.429473</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.819291</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>-67.171717</td>\n",
       "      <td>41.414141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.356902</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207271</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.737688</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>-1.515152</td>\n",
       "      <td>35.690236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.022675</td>\n",
       "      <td>0.281385</td>\n",
       "      <td>1.212121</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.078505</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>-71.861472</td>\n",
       "      <td>21.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014761</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.583346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>8.672936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.281385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.520846</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-71.861472</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.015385         0.999090  1.969697   \n",
       "1         2                  0.030769         0.999013  1.969697   \n",
       "2         3                  0.030769         0.998861  0.000000   \n",
       "3         4                  0.046154         0.998736  1.969697   \n",
       "4         5                  0.061538         0.998630  1.969697   \n",
       "5         6                  0.107692         0.997777  1.969697   \n",
       "6         7                  0.153846         0.995408  1.969697   \n",
       "7         8                  0.200000         0.983688  0.656566   \n",
       "8         9                  0.307692         0.928456  1.688312   \n",
       "9        10                  0.400000         0.789023  1.969697   \n",
       "10       11                  0.507692         0.537706  1.125541   \n",
       "11       12                  0.600000         0.287626  0.328283   \n",
       "12       13                  0.692308         0.127755  0.984848   \n",
       "13       14                  0.800000         0.022675  0.281385   \n",
       "14       15                  0.892308         0.006282  0.000000   \n",
       "15       16                  1.000000         0.001299  0.281385   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.969697       1.000000  0.999109                  1.000000   \n",
       "1          1.969697       1.000000  0.999079                  1.000000   \n",
       "2          1.969697       0.000000  0.000000                  1.000000   \n",
       "3          1.969697       1.000000  0.998841                  1.000000   \n",
       "4          1.969697       1.000000  0.998653                  1.000000   \n",
       "5          1.969697       1.000000  0.998245                  1.000000   \n",
       "6          1.969697       1.000000  0.996972                  1.000000   \n",
       "7          1.666667       0.333333  0.990258                  0.846154   \n",
       "8          1.674242       0.857143  0.963680                  0.850000   \n",
       "9          1.742424       1.000000  0.868339                  0.884615   \n",
       "10         1.611570       0.571429  0.638228                  0.818182   \n",
       "11         1.414141       0.166667  0.429473                  0.717949   \n",
       "12         1.356902       0.500000  0.207271                  0.688889   \n",
       "13         1.212121       0.142857  0.078505                  0.615385   \n",
       "14         1.086729       0.000000  0.014761                  0.551724   \n",
       "15         1.000000       0.142857  0.002989                  0.507692   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.999109      0.030303                 0.030303   96.969697   \n",
       "1           0.999094      0.030303                 0.060606   96.969697   \n",
       "2           0.999094      0.000000                 0.060606 -100.000000   \n",
       "3           0.999010      0.030303                 0.090909   96.969697   \n",
       "4           0.998921      0.030303                 0.121212   96.969697   \n",
       "5           0.998631      0.090909                 0.212121   96.969697   \n",
       "6           0.998134      0.090909                 0.303030   96.969697   \n",
       "7           0.996316      0.030303                 0.333333  -34.343434   \n",
       "8           0.984893      0.181818                 0.515152   68.831169   \n",
       "9           0.957996      0.181818                 0.696970   96.969697   \n",
       "10          0.890167      0.121212                 0.818182   12.554113   \n",
       "11          0.819291      0.030303                 0.848485  -67.171717   \n",
       "12          0.737688      0.090909                 0.939394   -1.515152   \n",
       "13          0.648952      0.030303                 0.969697  -71.861472   \n",
       "14          0.583346      0.000000                 0.969697 -100.000000   \n",
       "15          0.520846      0.030303                 1.000000  -71.861472   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         96.969697  \n",
       "1         96.969697  \n",
       "2         96.969697  \n",
       "3         96.969697  \n",
       "4         96.969697  \n",
       "5         96.969697  \n",
       "6         96.969697  \n",
       "7         66.666667  \n",
       "8         67.424242  \n",
       "9         74.242424  \n",
       "10        61.157025  \n",
       "11        41.414141  \n",
       "12        35.690236  \n",
       "13        21.212121  \n",
       "14         8.672936  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_gbm_perf = best_gbm.model_performance(test)\n",
    "print(best_gbm_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n",
      "0.82\n",
      "0.8298795180722892\n"
     ]
    }
   ],
   "source": [
    "gs_gbm_recall = round(27/33 , 2)\n",
    "gs_gbm_precision = round(27/32, 2)\n",
    "gs_gbm_f1 = 2*((gs_gbm_precision * gs_gbm_recall)/(gs_gbm_precision + gs_gbm_recall))\n",
    "\n",
    "print(gs_gbm_precision)\n",
    "print(gs_gbm_recall)\n",
    "print(gs_gbm_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAHFCAYAAAA0SmdSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xt8jvXjx/HXbYd7J7vnPIexmGVzGqFsSkWWY1GECjmVkhBjP8aQljNRku83k4QO8k3KsZRT2DKJUQ4z30wodrN02+H+/eGx+9vdrDb3Zqf38/G4Ht/d1/W5rs/nc62vvR+f63N9boPVarUiIiIiIresXFE3QERERKSkU6ASERERcZAClYiIiIiDFKhEREREHKRAJSIiIuIgBSoRERERBylQiYiIiDhIgUpERETEQQpUIiIiIg5SoBIpI7p37467uzuXL1/OtcyTTz6Ji4sLv/zyS4HVW6tWLQYPHpzv8zIyMjAYDIwcOfIfy27duhWDwcDOnTtvpYkO1V1c/fDDD0RHR5OcnFzUTREpExSoRMqIQYMG8ccff/D+++/f9HhqaiqffPIJXbp0oVq1agVW7/r16/m///u/Arue5M0PP/zAlClTFKhEbhMFKpEyomPHjtSoUYN33nnnpsdXrVrFtWvXGDRoUIHUd+3aNQCaNWtG3bp1C+Sa8s+uX79ORkZGUTdDpMxRoBIpI5ycnOjfvz/x8fEcOnQox/Fly5ZRvXp1OnbsaNs3adIkWrVqRcWKFfH29uauu+4iNjaWv36neq1atXj00Uf58MMPCQkJwc3NjenTp9uO/fmR37Vr1xg9ejRNmzbFZDJRsWJFQkNDWb9+fa5tX7x4MfXr18doNNKwYUM+/PDDPPV53759dOnShQoVKuDm5kbz5s35+OOP83TuX2U/VlyzZg1jxozB19cXLy8vHnnkES5cuIDZbGbw4MFUrlyZypUrM2jQINLS0mzn//kxYl76c+jQIbp164aPjw9ubm40a9aMFStW3LRN77//PqNGjaJGjRq4ubkRGxtLnz59ALj33nsxGAwYDAbee+89ADZt2kS3bt2oVasW7u7u1K9fn+eff55ff/3V7voTJ07EYDCQmJjIE088gbe3N76+vgwePBiz2WxXNisriwULFtC0aVPc3d3x8fGhdevWbNiwwa7cqlWruOeee/Dw8KB8+fI8/PDDHDx48JZ+JyLFiXNRN0BEbp+BAwfy2muv8c477zBv3jzb/iNHjrBv3z7Gjx+Pk5OTbf/p06cZNmwYfn5+WK1Wvv32W4YNG8bZs2dzPMbbt28fP/zwAxMnTsTf3x8vL6+btuHatWtcvnyZiIgIatSogcViYcuWLTz66KOsWLGCvn372pVfu3YtJpOJV155BXd3dxYtWsQTTzyBs7Mz3bt3z7WvW7dupXPnzoSGhvL2229Tvnx5Vq1axeOPP86KFSt46qmnbuUWMm7cONq3b8/y5cs5efIkY8aMoW/fvmRlZdGiRQtWrVpFfHw8EydOxGQyMXfu3Hz358iRI4SGhuLr68uiRYuoUKEC7777Lv369ePChQuMHj3a7poRERGEhYXx9ttvA3D33Xdz7tw5oqKiWLJkCU2aNAEgICAAgOPHjxMWFsaQIUMwmUycOnWKOXPmcN9993Hw4EGcne3/NPTo0YPevXszZMgQDh48yIQJEyhXrpytPoCnnnqK1atXM2TIEKZNm4aLiwvx8fGcOnXKVmbq1KlER0czePBgoqKisFgszJw5kzZt2hAXF8edd955S78TkWLBKiJlStu2ba2VK1e2Xr9+3bbv5ZdftgLWH3/8MdfzMjMzrenp6dZJkyZZq1atanesZs2aVhcXF+vx48dznFezZk3roEGDcr1uRkaGNT093dq/f39ry5YtbfvT09OtgNXT09N6/vx5u/L169e3NmjQwLZvy5YtVsC6Y8cO276AgABry5YtrRkZGXb1Pfzww9aaNWtas7Kycm1Tdt0vvfRSjjq6d+9uV3b48OFWwDp69Gi7/V26dLG7T/npz+OPP251c3Oz/ve//7W7ZocOHaxeXl5Ws9ls16YHH3wwRx9WrVqV457cTFZWljU9Pd164sQJK2DdsGGD7diECROsgHXu3Ll25wwdOtTq6elp+/zll19aAevkyZNzrefUqVNWJycn66hRo+z2m81ma9WqVa19+/b923aKFHd65CdSxgwaNIiLFy/y6aefAjceRb333nvce++91K9f367s1q1badeuHSaTCScnJ1xcXJg6dSrnz5/P8XgoJCSEevXq5akNa9asITQ0FE9PT5ydnXFxcWH58uUkJibmKPvQQw9RpUoV22cnJyd69erF0aNHOXfu3E2vf/ToUY4fP86TTz6J1WolIyPDtnXq1Imff/6Z48eP56mtf9WlSxe7z0FBQQB07tw5x/7z58/zxx9/5Ls/X375JR06dKBmzZp25/bv35+rV6+yd+9eu/2PPfZYvvrwyy+/MHToUGrVqmW7/9m/u5v9Drp162b3uUmTJqSlpdn+G/jiiy8AeOGFF3Ktc+PGjWRmZtKvXz+734e7uzv33nsv27dvz1cfRIobBSqRMubxxx/HZDKxbNkyAD7//HN++eWXHJPR9+zZw8MPP4yTkxP/+te/2L17N/v372f8+PHA/yadZ6tevXqe6v/ggw/o3bs3tWvXZuXKlezZs4f9+/fTr1+/HNcE8PX1zXXfX0NdtuxlH0aOHImLi4vdNmLECAAuXryYp/b+VcWKFe0+u7q6/u3+vwaqvPTn0qVLN72fNWrUsCuXLa/3HiAzM5P27dvz6aefMn78eLZt28a+fftsS07c7HdQqVIlu89Go9Gu7IULF3B1dbULin+V/Ttp1qxZjt/Jxx9/fMu/D5HiQnOoRMoYd3d3+vTpw9KlS0lJSeGdd96hfPny9OzZ067cqlWrMBqNfPbZZ7ZwAPDRRx/d9LoGgyFP9b/33nvUr1+fVatW2Z1jsVhuWv5mo1DZ+/76hz5b5cqVAYiKisoxupKtQYMGeWpvQctLfypUqEBKSkqOcmfPngX+179seb33AAcPHuSHH37gvffe48knn7TtP3r0aJ6v8VdVqlTh+vXrXLhwIddQld3mdevW5Rh5g/z1QaQ4UqASKYMGDRrEW2+9xaxZs/j8888ZMGAAHh4edmUMBgMuLi6UK/e/gezff//d9qbYrTIYDLi6utr9AT179iyfffbZTctv2bLF7g91ZmYmH3zwAXfeeedNR3sAgoODueOOO0hISGDq1KkOtbeg5aU/7dq1Y8OGDfzyyy92a4K9++67eHl50apVq3+s56+jSNmy73v28WxLliy55T517NiRWbNmsXjxYiZNmnTTMtmjnSdOnOCRRx655bpEiisFKpEyqEWLFjRp0oT58+djtVpvuvZU586def3113nqqacYPHgwFy9eZObMmTmCV3516dKFoUOH8uKLL9K9e3eSk5OZOnUqNWrU4OTJkznKV6xYkQcffJCJEyfi4eHBwoUL+emnn3IdKYMboeHtt9+mc+fOdOzYkX79+lGjRg0uXbrEkSNHOHjwIGvWrHGoH7cqL/2Jjo7miy++4P777ycqKgofHx9WrFjBpk2bmDNnDuXLl//Heho1agTcCEru7u64ublRt25dGjZsiL+/PxEREWRkZODj48Onn37Ktm3bbrlPDzzwAH369CE6OpqUlBQ6d+6Mi4sLBw4coHz58rzwwgvUq1ePyZMnM378eI4fP054eDg+Pj6cO3eOffv2YTKZcg1jIiWBApVIGTVo0CBeeuklgoODufvuu3Mc79ChA0uXLmXWrFl06dKFmjVr8uyzz+Lj48Ozzz57y/UOHjyYCxcusHTpUpYuXUq9evWYOHEiJ0+e5LXXXstRvkePHgQEBPB///d/nDlzhoCAAFatWvWPE7Hbt2/P3r17mT59Oi+99BKXL1+mcuXKBAcH07t371tuv6Py0p/g4GB27drFhAkTGDZsGBaLhaCgIN59912efvrpPNVTv3595syZw8KFC7n//vvJzMy0LRfx2WefMXLkSIYOHYqzszMdOnRg8+bN+Pv733K/3nvvPVq0aME777zDO++8g4eHB8HBwUycONFWJioqikaNGrFgwQJWrlyJxWKhevXqtGzZMsdkf5GSxmC1/mWFPhERKXAZGRm4uLjw0ksvMX/+/KJujogUML3lJyIiIuIgBSoRERERB+mRn4iIiIiDNEIlIiIi4iAFKhEREREHKVCJiIiIOEjrUBWSrKwszp49S/ny5fWVCiIiIiWE1WrlypUr1KhRw+6bIv6JAlUhOXv2LH5+fkXdDBEREbkFZ86coVatWnkur0BVSLK/GuLMmTN4e3sXcWtEREQkL8xmM35+fnn6iqc/U6AqJNmP+by9vRWoRERESpj8TtfRpHQRERERBylQiYiIiDhIgUpERETEQQpUIiIiIg5SoBIRERFxkAKViIiIiIMUqEREREQcpEAlIiIi4iAFKhEREREHKVCJiIiIOEiBSkRERMRBClQiIiIiDlKgEhEREXGQApWIiIiIg5yLugGlnSnGBG5F3QoREZHSxTrZWtRNsKMRKhEREREHKVCJiIiIOKjUB6rt27djMBi4fPmyQ9fx9/dn/vz5BdQqERERKU1KXaC6//77GTlyZFE3Q0RERMqQUheoRERERG63UhWoBgwYwNdff82CBQswGAwYDAaSkpIAiI+Pp0WLFnh4eBAaGsqxY8ds5504cYJHHnmEatWq4eXlRcuWLdm6dWsR9UJERERKmlIVqBYsWEDr1q0ZMmQIKSkppKSk4OfnB8CECROYM2cOcXFxODs7M3DgQNt5V69epVOnTmzdupUDBw4QHh5O165dSU5OznPdFosFs9lst4mIiEjZUKoClclkwtXVFQ8PD3x9ffH19cXJyQmA6dOn07ZtW4KDgxk/fjy7d+/mjz/+AKBp06Y8++yzNG7cmPr16/PKK69Qt25dPv300zzXHRMTg8lksm3ZQU5ERERKv1IVqP5OkyZNbD9Xr14dgPPnzwOQlpZGREQEwcHB+Pj44OXlxdGjR/M1QhUZGUlqaqptO3PmTMF2QERERIqtMrNSuouLi+1ng8EAQFZWFgBjx45l06ZNzJ49m4CAANzd3Xn88ce5fv16nq9vNBoxGo0F22gREREpEUpdoHJ1dSUzMzNf5+zYsYMBAwbQvXt34MacquzJ7CIiIiL/pNQ98vP392fv3r0kJSVx8eJF2yjU3wkICGDt2rUkJCRw8OBB+vbtm6fzRERERKAUBqoxY8bg5OREcHAwVapUydM8qHnz5lGhQgVCQ0Pp2rUr4eHhNG/e/Da0VkREREoDg9VqLV5f11xKmM1mTCYTjAfciro1IiIipYt1cuHEl+y/36mpqXh7e+f5vFI3QiUiIiJyuylQiYiIiDio1L3lV9ykRuZvyFBERERKHo1QiYiIiDhIgUpERETEQQpUIiIiIg7SHKpCZooxadkEERFxWGEtEyAFQyNUIiIiIg5SoBIRERFxkAKViIiIiIMUqEREREQcpEAlIiIi4qAyHaiysrKYMWMGAQEBGI1GateuzfTp0wEYN24cgYGBeHh4ULduXaKiokhPTy/iFouIiEhxVKaXTYiMjGTp0qXMmzePNm3akJKSwtGjRwEoX748sbGx1KhRg0OHDjFkyBDKly9PREREEbdaREREihuD1WotkwtbXLlyhSpVqrBo0SIGDx78j+VnzZrFmjVriIuLu+lxi8WCxWKxfTabzfj5+cF4tA6ViIg4TOtQ3R5msxmTyURqav6+i7fMjlAlJiZisVho167dTY9/9NFHzJ8/n+PHj3P16lUyMjL+9sbGxMQwZcqUwmquiIiIFGNldg6Vu7t7rse+/fZbevfuTceOHfnss884cOAAEyZM4Pr167meExkZSWpqqm07c+ZMYTRbREREiqEyO0JVv3593N3d2bZtW45Hfrt27aJOnTpMmDDBtu/06dN/ez2j0YjRaCyUtoqIiEjxVmYDlZubG+PGjSMiIgJXV1fCwsK4cOEChw8fJiAggOTkZFavXk3Lli3ZsGEDn3zySVE3WURERIqpMvvIDyAqKoqXX36ZSZMmERQUxBNPPMH58+d55JFHGDVqFMOHDyckJITdu3cTFRVV1M0VERGRYqrMvuVX2LLfEtBbfiIiUhD0lt/tcatv+ZXpESoRERGRgqBAJSIiIuKgMjsp/XZJjczfkKGIiIiUPBqhEhEREXGQApWIiIiIgxSoRERERBykOVSFzBRj0rIJIiJ/otf/pTTSCJWIiIiIgxSoRERERBykQCUiIiLioCINVNu3b8dgMHD58uVcy8TGxuLj43MbW3VDdHQ0ISEht71eERERKXk0QiUiIiLiIAUqEREREQcVeqCyWCyMGDGCqlWr4ubmRps2bdi/f3+u5WNjY6lduzYeHh50796dX3/91e549qO4JUuW4Ofnh4eHBz179szx2HDZsmUEBQXh5uZGgwYNePPNN+2Ojxs3jsDAQDw8PKhbty5RUVGkp6fn2q5Tp04REBDAsGHDyMrKuoU7ISIiIqVVoQeqiIgIPv74Y5YvX853331HQEAA4eHh/PbbbznK7t27l4EDB/L888+TkJDAAw88wCuvvJKj3PHjx/nggw9Yv349GzduJCEhgRdeeMF2fOnSpUyYMIHp06eTmJjIq6++SlRUFMuXL7eVKV++PLGxsRw5coQFCxawdOlS5s2bd9M+/PDDD4SFhdGzZ08WL15MuXI5b5vFYsFsNtttIiIiUjYYrFZroa2wlpaWRoUKFYiNjaVv374ApKen4+/vz8iRI2nZsiUPPPAAly5dwsfHh759+3Lp0iW++OIL2zV69+7Nxo0bbSNQ0dHRvPLKKyQlJVGrVi0ANm7cSOfOnfn555/x9fWldu3azJgxgz59+tiu88orr/D555+ze/fum7Z11qxZrFmzhri4OFs969atY/HixXTp0oXIyEjGjBmTa1+jo6OZMmVKzgPj0cKeIiJ/ooU9pTgzm82YTCZSU1Px9vbO83mFOkJ14sQJ0tPTCQsLs+1zcXGhVatWJCYm5iifmJhI69at7fb99TNA7dq1bWEqu0xWVhbHjh3jwoULnDlzhkGDBuHl5WXbXnnlFU6cOGE756OPPqJNmzb4+vri5eVFVFQUycnJdvUkJyfTvn17Jk6c+LdhCiAyMpLU1FTbdubMmb+/OSIiIlJqFOpXz2QPfhkMhhz7/7rvz+XzK/taBoPBNr9p6dKl3H333XblnJycAPj222/p3bs3U6ZMITw8HJPJxOrVq5kzZ45d+SpVqlCjRg1Wr17NoEGD/japGo1GjEbjLbVfRERESrZCHaEKCAjA1dWVnTt32valp6cTFxdHUFBQjvLBwcF8++23dvv++hlujBydPXvW9nnPnj2UK1eOwMBAqlWrRs2aNTl58iQBAQF22x133AHArl27qFOnDhMmTKBFixbUr1+f06dP56jH3d2dzz77DDc3N8LDw7ly5cot3wsREREpvQp1hMrT05Nhw4YxduxYKlasSO3atZk5cya///47gwYN4uDBg3blR4wYQWhoKDNnzuTRRx9l8+bNbNy4Mcd13dzc6N+/P7Nnz8ZsNjNixAh69eqFr68vcGM+04gRI/D29qZjx45YLBbi4uK4dOkSo0ePJiAggOTkZFavXk3Lli3ZsGEDn3zySa592LBhAx07dqRjx45s3LgRLy+vgr9ZIiIiUmIV+lt+r732Go899hhPP/00zZs35/jx42zatIkKFSrkKHvPPffwr3/9i4ULFxISEsLmzZuZOHFijnIBAQH06NGDTp060aFDBxo1amS3LMLgwYP517/+RWxsLI0bN6Zt27bExsbaRqgeeeQRRo0axfDhwwkJCWH37t1ERUXl2gcvLy+++OILrFYrnTp1Ii0trQDujIiIiJQWhfqWX2HIfvsuISGhqJvyt7LfEtBbfiIi9vSWnxRnxfItPxEREZGyoFDnUAmkRuYv4YqIiEjJU+Ie+ZUUtzpkKCIiIkVHj/xEREREiogClYiIiIiDFKhEREREHKRJ6YXMFGPSsgkiJYxe6xeR/NIIlYiIiIiDFKhEREREHKRAJSIiIuIgBSoRERERBylQiYiIiDio1AaqjRs30qZNG3x8fKhUqRJdunThxIkTtuO7d+8mJCQENzc3WrRowbp16zAYDHZfunzkyBE6deqEl5cX1apV4+mnn+bixYtF0R0REREpxkptoEpLS2P06NHs37+fbdu2Ua5cObp3705WVhZXrlyha9euNG7cmO+++45p06Yxbtw4u/NTUlJo27YtISEhxMXFsXHjRn755Rd69ep10/osFgtms9luExERkbKh1K5D9dhjj9l9/ve//03VqlU5cuQIO3fuxGAwsHTpUtzc3AgODubnn39myJAhtvKLFy+mefPmvPrqq7Z977zzDn5+fvz4448EBgbaXT8mJoYpU6YUbqdERESkWCq1I1QnTpygb9++1K1bF29vb+644w4AkpOTOXbsGE2aNMHN7X8rbrZq1cru/Pj4eL766iu8vLxsW4MGDWzX/qvIyEhSU1Nt25kzZwqxdyIiIlKclNoRqq5du+Ln58fSpUupUaMGWVlZNGrUiOvXr2O1WjEYDHblrVb7lZGzsrLo2rUrM2bMyHHt6tWr59hnNBoxGo0F2wkREREpEUploPr1119JTExkyZIl3HvvvQDs3LnTdrxBgwasXLkSi8ViC0FxcXF212jevDkff/wx/v7+ODuXytskIiIiBaRUPvKrUKEClSpV4u233+b48eN8+eWXjB492na8b9++ZGVlMXToUBITE9m0aROzZ88GsI1cvfDCC/z222/06dOHffv2cfLkSTZv3szAgQPJzMwskn6JiIhI8VQqA1W5cuVYvXo18fHxNGrUiFGjRjFr1izbcW9vb9avX09CQgIhISFMmDCBSZMmAdjmVdWoUYNdu3aRmZlJeHg4jRo14qWXXsJkMlGuXKm8bSIiInKLDNa/Th4qo1auXMkzzzxDamoq7u7uDl/PbDZjMplgPOD2j8VFpBixTtY/iyJlVfbf79TUVLy9vfN8XpmdHPTuu+9St25datasycGDBxk3bhy9evUqkDAlIiIiZUuZDVTnzp1j0qRJnDt3jurVq9OzZ0+mT59e1M0SERGREkiP/ArJrQ4ZioiISNG51b/fml0tIiIi4iAFKhEREREHKVCJiIiIOKjMTkq/XUwxJi2bIFLItMyBiBQ1jVCJiIiIOEiBSkRERMRBClQiIiIiDlKgysU333xD165dqVGjBgaDgXXr1hV1k0RERKSYUqDKRVpaGk2bNmXRokVF3RQREREp5golUFmtVmbOnEndunVxd3enadOmfPTRRwBMnTqVGjVq8Ouvv9rKd+vWjfvuu4+srCwA5s6dS+PGjfH09MTPz4/nn3+eq1ev2srHxsbi4+PDpk2bCAoKwsvLi4cffpiUlBRbmYyMDEaMGIGPjw+VKlVi3Lhx9O/fn0cffTRPfejYsSOvvPIKPXr0KIhbIiIiIqVYoQSqiRMnsmzZMhYvXszhw4cZNWoUTz31FF9//TUTJkzA39+fwYMHA/DWW2/xzTffsGLFCsqVu9GccuXK8frrr/PDDz+wfPlyvvzySyIiIuzq+P3335k9ezYrVqzgm2++ITk5mTFjxtiOz5gxg5UrV7Js2TJ27dqF2Wwu1Md2FosFs9lst4mIiEjZUODf5ZeWlkblypX58ssvad26tW3/4MGD+f3333n//fc5efIkISEhPP/88yxcuJC3336bJ598MtdrfvjhhwwbNoyLFy8CN0aonnnmGY4fP069evUAePPNN5k6dSrnzp0DwNfXlzFjxthCVmZmJnXr1qVZs2b5DlYGg4FPPvnkb0e3oqOjmTJlSs4D49E6VCKFTOtQiUhBudXv8ivwhT2PHDnCH3/8wUMPPWS3//r16zRr1gyAunXrMnv2bJ599lmeeOKJHGHqq6++4tVXX+XIkSOYzWYyMjL4448/SEtLw9PTEwAPDw9bmAKoXr0658+fByA1NZVffvmFVq1a2Y47OTlx11132R4rFrTIyEhGjx5t+2w2m/Hz8yuUukRERKR4KfBAlR1YNmzYQM2aNe2OGY1G28/ffPMNTk5OJCUlkZGRgbPzjaacPn2aTp068dxzzzFt2jQqVqzIzp07GTRoEOnp6bbzXVxc7K5tMBj462CbwWCw+1zAg3F2jEajXf9ERESk7CjwOVTBwcEYjUaSk5MJCAiw27JHbNasWcPatWvZvn07Z86cYdq0abbz4+LiyMjIYM6cOdxzzz0EBgZy9uzZfLXBZDJRrVo19u3bZ9uXmZnJgQMHCqaTIiIiIn9S4CNU5cuXZ8yYMYwaNYqsrCzatGmD2Wxm9+7deHl50a5dO4YNG8aMGTNo06YNsbGxdO7cmY4dO3LPPfdQr149MjIyWLhwIV27dmXXrl289dZb+W7Hiy++SExMDAEBATRo0ICFCxdy6dKlHKNWubl69SrHjx+3fT516hQJCQlUrFiR2rVr57s9IiIiUnoVylt+06ZNY9KkScTExBAUFER4eDjr16/H39+fAQMG0KpVK4YPHw7AQw89xPDhw3nqqae4evUqISEhzJ07lxkzZtCoUSNWrlxJTExMvtswbtw4+vTpQ79+/WjdujVeXl6Eh4fj5pa3GeJxcXE0a9bMNu9r9OjRNGvWjEmTJuW7LSIiIlK6FfhbfsVVVlYWQUFB9OrVy+4RY2HJfktAb/mJFD695SciBaXYvOVXXJw+fZrNmzfTtm1bLBYLixYt4tSpU/Tt27eomyYiIiKlTKn96ply5coRGxtLy5YtCQsL49ChQ2zdupWgoCCSk5Px8vLKdUtOTi7q5ouIiEgJUmYe+f1ZRkYGSUlJuR739/e3LeNwq251yFBERESKjh755YOzszMBAQFF3QwREREpJUrtIz8RERGR20WBSkRERMRBZfKR3+1kijFp2QSRfNIyCCJS0miESkRERMRBClQiIiIiDlKgEhEREXGQApWIiIiIgxSobuLgwYP06dMHPz8/3N3dCQoKYsGCBUXdLBERESmm9JbfTcTHx1OnuGDDAAAgAElEQVSlShXee+89/Pz82L17N0OHDsXJyYnhw4cXdfNERESkmCnRI1RZWVnMmDGDgIAAjEYjtWvXZvr06SQlJWEwGFi9ejWhoaG4ubnRsGFDtm/fnqfrDhw4kNdff522bdtSt25dnnrqKZ555hnWrl1buB0SERGREqlEj1BFRkaydOlS5s2bR5s2bUhJSeHo0aO242PHjmX+/PkEBwczd+5cunXrxqlTp6hUqVK+60pNTaVixYq5HrdYLFgsFttns9mc7zpERESkZCqxI1RXrlxhwYIFzJw5k/79+1OvXj3atGnD4MGDbWWGDx/OY489RlBQEIsXL8ZkMvHvf/8733Xt2bOHDz74gGeffTbXMjExMZhMJtvm5+d3S/0SERGRkqfEBqrExEQsFgvt2rXLtUzr1q1tPzs7O9OiRQsSExPzVc/hw4d55JFHmDRpEg899FCu5SIjI0lNTbVtZ86cyVc9IiIiUnKV2Ed+7u7ut3SewWDIc9kjR47w4IMPMmTIECZOnPi3ZY1GI0aj8ZbaJCIiIiVbiR2hql+/Pu7u7mzbti3XMt9++63t54yMDOLj42nQoEGern/48GEeeOAB+vfvz/Tp0x1ur4iIiJReJXaEys3NjXHjxhEREYGrqythYWFcuHCBw4cP2x4DvvHGG9SvX5+goCDmzZvHpUuXGDhw4D9eOztMdejQgdGjR3Pu3DkAnJycqFKlSqH2S0REREqeEhuoAKKionB2dmbSpEmcPXuW6tWr89xzz9mOv/baa8yYMYMDBw5Qr149/vOf/1C5cuV/vO6HH37IhQsXWLlyJStXrrTtr1OnDklJSYXRFRERESnBDFar1VrUjShoSUlJ3HHHHRw4cICQkJAiaYPZbMZkMsF4wK1ImiBSYlknl7p/lkSkhMj++52amoq3t3eezyuxc6hEREREiosS/cjvVj333HO89957Nz321FNP8dZbbxVYXamR+Uu4IiIiUvKUykd+/+T8+fO5rmTu7e1N1apVHa7jVocMRUREpOjc6t/vMjlCVbVq1QIJTSIiIiKgOVQiIiIiDlOgEhEREXFQmXzkdzuZYkxaNkHKNC2BICJlgUaoRERERBykQCUiIiLioFIZqGJjY/Hx8SnqZoiIiEgZUWiB6v7772fkyJGFdXkbf39/5s+fX+j1iIiIiOSmyEaorFYrGRkZRVW9iIiISIEplEA1YMAAvv76axYsWIDBYMBgMBAbG4vBYGDTpk20aNECo9HIjh07AFi/fj133XUXbm5u1K1blylTptiFrejoaGrXro3RaKRGjRqMGDECuDEKdvr0aUaNGmWr58/WrVtHYGAgbm5uPPTQQ5w5c8bumiEhISxZsgQ/Pz88PDzo2bMnly9ftpXZvn07rVq1wtPTEx8fH8LCwjh9+nRh3DIREREpwQolUC1YsIDWrVszZMgQUlJSSElJwc/PD4CIiAhiYmJITEykSZMmbNq0iaeeeooRI0Zw5MgRlixZQmxsLNOnTwfgo48+Yt68eSxZsoSffvqJdevW0bhxYwDWrl1LrVq1mDp1qq2ebL///jvTp09n+fLl7Nq1C7PZTO/eve3aefz4cT744APWr1/Pxo0bSUhI4IUXXgAgIyODRx99lLZt2/L999+zZ88ehg4dmiO0ZbNYLJjNZrtNREREyoZCWYfKZDLh6uqKh4cHvr6+ABw9ehSAqVOn8tBDD9nKTp8+nfHjx9O/f38A6taty7Rp04iIiGDy5MkkJyfj6+tL+/btcXFxoXbt2rRq1QqAihUr4uTkRPny5W31ZEtPT2fRokXcfffdACxfvpygoCD27dtnO/+PP/5g+fLl1KpVC4CFCxfSuXNn5syZg6urK6mpqXTp0oV69eoBEBQUlGufY2JimDJlisP3TkREREqe2z6HqkWLFnaf4+PjmTp1Kl5eXrYte2Tr999/p2fPnly7do26desyZMgQPvnkkzzNvXJ2drarq0GDBvj4+JCYmGjbV7t2bVuYAmjdujVZWVkcO3aMihUrMmDAAMLDw+natSsLFiywGwH7q8jISFJTU23bnx8vioiISOl22wOVp6en3eesrCymTJlCQkKCbTt06BA//fQTbm5u+Pn5cezYMd544w3c3d15/vnnue+++0hPT//Hum72eC63R3Z/Ppb9v8uWLWPPnj2EhoayZs0aAgMD+fbbb296rtFoxNvb224TERGRsqHQApWrqyuZmZn/WK558+YcO3aMgICAHFu5cjea5+7uTrdu3Xj99dfZvn07e/bs4dChQ39bT0ZGBnFxcbbPx44d4/LlyzRo0MC2Lzk5mbNnz9o+79mzh3LlyhEYGGjb16xZMyIjI9m9ezeNGjXi/fffz//NEBERkVKt0L7Lz9/fn71795KUlISXlxdZWVk3LTdp0iS6dOmCn58fPXv2pFy5cnz//fccOnSIV155hdjYWDIzM7n77rvx8PBgxYoVuLu7U6dOHVs933zzDb1798ZoNFK5cmUAXFxcePHFF3n99ddxcXFh+PDh3HPPPbb5UwBubm7079+f2bNnYzabGTFiBL169cLX15dTp07x9ttv061bN2rUqMGxY8f48ccf6devX2HdMhERESmhCm2EasyYMTg5OREcHEyVKlVITk6+abnw8HA+++wztmzZQsuWLbnnnnuYO3euLTD5+PiwdOlSwsLCaNKkCdu2bWP9+vVUqlQJuDHJPSkpiXr16lGlShXbdT08PBg3bhx9+/aldevWuLu7s3r1aru6AwIC6NGjB506daJDhw40atSIN99803b+0aNHeeyxxwgMDGTo0KEMHz6cZ599tjBul4iIiJRgBqvVWia/Cj46Opp169aRkJBQKNc3m82YTCYYD7gVShUiJYJ1cpn8J0ZESqjsv9+pqan5mg9dKr/LT0REROR2UqASERERcVCZfeRX2G51yFBERESKjh75iYiIiBQRBSoRERERBylQiYiIiDio0Bb2lBtMMSYtmyDFnpY2EBFxjEaoRERERBykQCUiIiLioCINVNu3b8dgMHD58mWHruPv78/8+fMLqFVw//33M3LkyAK7noiIiJRutzVQKaiIiIhIaaRHfiIiIiIOum2BasCAAXz99dcsWLAAg8GAwWAgKSkJgPj4eFq0aIGHhwehoaEcO3bMdt6JEyd45JFHqFatGl5eXrRs2ZKtW7f+bV1z586lcePGeHp64ufnx/PPP8/Vq1ftyuzatYu2bdvi4eFBhQoVCA8P59KlS7bjWVlZREREULFiRXx9fYmOji6weyEiIiKly20LVAsWLKB169YMGTKElJQUUlJS8PPzA2DChAnMmTOHuLg4nJ2dGThwoO28q1ev0qlTJ7Zu3cqBAwcIDw+na9euJCcn51pXuXLleP311/nhhx9Yvnw5X375JREREbbjCQkJtGvXjoYNG7Jnzx527txJ165dyczMtJVZvnw5np6e7N27l5kzZzJ16lS2bNmSa50WiwWz2Wy3iYiISNlwW7/L7/777yckJMQ2gXz79u088MADbN26lXbt2gHw+eef07lzZ65du4ab280XcGrYsCHDhg1j+PDhwI1J6SNHjsx1ftaHH37IsGHDuHjxIgB9+/YlOTmZnTt35trOzMxMduzYYdvXqlUrHnzwQV577bWbnhMdHc2UKVNyHhiP1qGSYk/rUImI3FCiv8uvSZMmtp+rV68OwPnz5wFIS0sjIiKC4OBgfHx88PLy4ujRo387QvXVV1/x0EMPUbNmTcqXL0+/fv349ddfSUtLA/43QpXXNmW3K7tNNxMZGUlqaqptO3PmzN93WkREREqNYhGoXFxcbD8bDAbgxhwmgLFjx/Lxxx8zffp0duzYQUJCAo0bN+b69es3vdbp06fp1KkTjRo14uOPPyY+Pp433ngDgPT0dADc3d3z1absdmW36WaMRiPe3t52m4iIiJQNtzVQubq62s1TyosdO3YwYMAAunfvTuPGjfH19bVNZr+ZuLg4MjIymDNnDvfccw+BgYGcPXvWrkyTJk3Ytm3brXRBREREJIfbGqj8/f3Zu3cvSUlJXLx48W9HfLIFBASwdu1aEhISOHjwIH379v3b8+rVq0dGRgYLFy7k5MmTrFixgrfeesuuTGRkJPv37+f555/n+++/5+jRoyxevNg2x0pEREQkP25roBozZgxOTk4EBwdTpUqVv50HlW3evHlUqFCB0NBQunbtSnh4OM2bN8+1fEhICHPnzmXGjBk0atSIlStXEhMTY1cmMDCQzZs3c/DgQVq1akXr1q35z3/+g7OzvitaRERE8u+2vuVXlmS/JaC3/KQk0Ft+IiI3lOi3/ERERERKMgUqEREREQdp0lAhS43M35ChiIiIlDwaoRIRERFxkAKViIiIiIMUqEREREQcpDlUhcwUY9KyCaWMlhgQEZG/0giViIiIiIMUqEREREQcVCoC1YABA3j00UeLuhkiIiJSRpWKQCUiIiJSlBSoRERERBxUogLVRx99ROPGjXF3d6dSpUq0b9+etLS0HOUsFgsjRoygatWquLm50aZNG/bv3287vn37dgwGAxs2bKBp06a4ublx9913c+jQIbvr7N69m/vuuw93d3f8/PwYMWLETesTERGRsq3EBKqUlBT69OnDwIEDSUxMZPv27fTo0QOrNecr7BEREXz88ccsX76c7777joCAAMLDw/ntt9/syo0dO5bZs2ezf/9+qlatSrdu3UhPTwfg0KFDhIeH06NHD77//nvWrFnDzp07GT58+G3pr4iIiJQcBuvNEkkx9N1333HXXXeRlJREnTp17I4NGDCAy5cvs27dOtLS0qhQoQKxsbH07dsXgPT0dPz9/Rk5ciRjx45l+/btPPDAA6xevZonnngCgN9++41atWoRGxtLr1696NevH+7u7ixZssRWz86dO2nbti1paWm4udkvLmWxWLBYLLbPZrMZPz8/GI/WoSpltA6ViEjpZTabMZlMpKbm77t4S8wIVdOmTWnXrh2NGzemZ8+eLF26lEuXLuUod+LECdLT0wkLC7Ptc3FxoVWrViQmJtqVbd26te3nihUrcuedd9rKxMfHExsbi5eXl20LDw8nKyuLU6dO5ag3JiYGk8lk2/z8/Aqq6yIiIlLMlZhA5eTkxJYtW/jiiy8IDg5m4cKF3HnnnTnCTfaAm8FgyLH/r/tuJrtMVlYWzz77LAkJCbbt4MGD/PTTT9SrVy/HeZGRkaSmptq2M2fO3GpXRUREpIQpMYEKboSdsLAwpkyZwoEDB3B1deWTTz6xKxMQEICrqys7d+607UtPTycuLo6goCC7st9++63t50uXLvHjjz/SoEEDAJo3b87hw4cJCAjIsbm6uuZom9FoxNvb224TERGRsqHEfJff3r172bZtGx06dKBq1ars3buXCxcuEBQUxPfff28r5+npybBhwxg7diwVK1akdu3azJw5k99//51BgwbZXXPq1KlUqlSJatWqMWHCBCpXrmxbIHTcuHHcc889vPDCCwwZMgRPT08SExPZsmULCxcuvK19FxERkeKtxAQqb29vvvnmG+bPn4/ZbKZOnTrMmTOHjh07smbNGruyr732GllZWTz99NNcuXKFFi1asGnTJipUqJCj3EsvvcRPP/1E06ZN+fTTT22jT02aNOHrr79mwoQJ3HvvvVitVurVq2ebxC4iIiKSrcS85VeQst/yu3TpEj4+PoVSR/ZbAnrLr/TRW34iIqVXqX/LT0RERKS4UqASERERcVCZfOR3O9zqkKGIiIgUHT3yExERESkiClQiIiIiDlKgEhEREXFQiVmHqqQyxZi0bEIpoKUSRETk72iESkRERMRBClQiIiIiDlKgEhEREXFQmQhUSUlJGAwGEhISHLqOv78/8+fPL6BWiYiISGlRJgKViIiISGFSoBIRERFxUKkKVFlZWcyYMYOAgACMRiO1a9dm+vTptuMnT57kgQcewMPDg6ZNm7Jnzx678z/++GMaNmyI0WjE39+fOXPm3O4uiIiISAlUqgJVZGQkM2bMICoqiiNHjvD+++9TrVo12/EJEyYwZswYEhISCAwMpE+fPmRkZAAQHx9Pr1696N27N4cOHSI6OpqoqChiY2PzVLfFYsFsNtttIiIiUjaUmoU9r1y5woIFC1i0aBH9+/cHoF69erRp04akpCQAxowZQ+fOnQGYMmUKDRs25Pjx4zRo0IC5c+fSrl07oqKiAAgMDOTIkSPMmjWLAQMG/GP9MTExTJkypVD6JiIiIsVbqRmhSkxMxGKx0K5du1zLNGnSxPZz9erVATh//rzt/LCwMLvyYWFh/PTTT2RmZv5j/ZGRkaSmptq2M2fO3Eo3REREpAQqNSNU7u7u/1jGxcXF9rPBYABuzLsCsFqttn3ZrNa8f92I0WjEaDTmubyIiIiUHqVmhKp+/fq4u7uzbdu2Wzo/ODiYnTt32u3bvXs3gYGBODk5FUQTRUREpJQqNSNUbm5ujBs3joiICFxdXQkLC+PChQscPnz4bx8DZnv55Zdp2bIl06ZN44knnmDPnj0sWrSIN9988za0XkREREqyUhOoAKKionB2dmbSpEmcPXuW6tWr89xzz+Xp3ObNm/PBBx8wadIkpk2bRvXq1Zk6dWqeJqSLiIhI2Waw5meikOSZ2WzGZDLBeMCtqFsjjrJO1v9NRETKguy/36mpqXh7e+f5vFIzh0pERESkqJSqR37FUWpk/hKuiIiIlDwaoRIRERFxkAKViIiIiIMUqEREREQcpEAlIiIi4iBNSi9kphiTlk0oobRUgoiI5JVGqEREREQcpEAlIiIi4iAFKhEREREHKVDlYu3atYSHh1O5cmUMBgMJCQlF3SQREREpphSocpGWlkZYWBivvfZaUTdFREREirliH6g++ugjGjdujLu7O5UqVaJ9+/akpaUBsGzZMoKCgnBzc6NBgwa8+eabtvPeffddvLy8+Omnn2z7XnzxRQIDA23n/52nn36aSZMm0b59+4LvlIiIiJQqxXrZhJSUFPr06cPMmTPp3r07V65cYceOHVitVpYuXcrkyZNZtGgRzZo148CBAwwZMgRPT0/69+9Pv379+Oyzz3jyySfZvXs3W7duZcmSJezatQtPT88Cb6vFYsFisdg+m83mAq9DREREiqdiH6gyMjLo0aMHderUAaBx48YATJs2jTlz5tCjRw8A7rjjDo4cOcKSJUvo378/AEuWLKFJkyaMGDGCtWvXMnnyZFq2bFkobY2JiWHKlCmFcm0REREp3gxWq7XYrl6YmZlJeHg4+/btIzw8nA4dOvD444+TkZFB1apVcXd3p1y5/z21zMjIwGQy8csvv9j2bd68mfDwcEJDQ/nmm29wcnLKVxuSkpK44447OHDgACEhIbmWu9kIlZ+fH4xHC3uWUFrYU0Sk7DGbzZhMJlJTU/H29s7zecV6hMrJyYktW7awe/duNm/ezMKFC5kwYQLr168HYOnSpdx99905zvmz7BB19uxZ0tLS8nVz8sNoNGI0Ggvl2iIiIlK8FftJ6QaDgbCwMKZMmcKBAwdwdXVl165d1KxZk5MnTxIQEGC33XHHHbZzd+/ezcyZM1m/fj3e3t68+OKLRdgTERERKa2K9QjV3r172bZtGx06dKBq1ars3buXCxcuEBQURHR0NCNGjMDb25uOHTtisViIi4vj0qVLjB49mitXrvD000/z4osv0rFjR2rXrk2LFi3o0qULPXv2/Me6f/vtN5KTkzl79iwAx44dA8DX1xdfX99C7beIiIiULMU6UHl7e/PNN98wf/58zGYzderUYc6cOXTs2BEADw8PZs2aRUREBJ6enjRu3JiRI0cC8NJLL+Hp6cmrr74KQMOGDZkxYwbPPfccoaGh1KxZ82/r/vTTT3nmmWdsn3v37g3A5MmTiY6OLoTeioiISElVrCell2TZk9o0Kb3k0qR0EZGy51YnpRf7OVQiIiIixV2ZDFQ7duzAy8sr101EREQkP4r1HKrC0qJFi9v2ZcepkfkbMhQREZGSp0wGKnd3dwICAoq6GSIiIlJKlMlHfiIiIiIFSYFKRERExEFl8pHf7WSKMZXqZRO0tICIiIhGqEREREQcpkAlIiIi4iAFKhEREREHFWmgio2NxcfHpyibcFNr164lPDycypUrYzAYbtuaVSIiIlIyORSorl+/XlDtKFbS0tIICwvjtddeK+qmiIiISAmQr0B1//33M3z4cEaPHk3lypV56KGHSE1NZejQoVStWhVvb28efPBBDh48aDvn4MGDPPDAA5QvXx5vb2/uuusu4uLi2L59O8888wypqakYDAYMBgPR0dHAjaAWERFBzZo18fT05O6772b79u12bdm1axdt27bFw8ODChUqEB4ezqVLlwC4cuUKTz75JJ6enlSvXp158+Zx//33M3LkyDz18+mnn2bSpEm0b98+P7dHREREyqh8j1AtX74cZ2dndu3axVtvvUXnzp05d+4cn3/+OfHx8TRv3px27drx22+/AfDkk09Sq1Yt9u/fT3x8POPHj8fFxYXQ0FDmz5+Pt7c3KSkppKSkMGbMGACeeeYZdu3axerVq/n+++/p2bMnDz/8MD/99BMACQkJtGvXjoYNG7Jnzx527txJ165dyczMBGD06NHs2rWLTz/9lC1btrBjxw6+++67grpnN2WxWDCbzXabiIiIlA35XocqICCAmTNnAvDll19y6NAhzp8/j9FoBGD27NmsW7eOjz76iKFDh5KcnMzYsWNp0KABAPXr17ddy2QyYTAY8PX1te07ceIEq1at4r///S81atQAYMyYMWzcuJFly5bx6quvMnPmTFq0aMGbb75pO69hw4bAjdGp5cuX8/7779OuXTsAli1bZrtWYYmJiWHKlCmFWoeIiIgUT/kOVC1atLD9HB8fz9WrV6lUqZJdmWvXrnHixAngxmjR4MGDWbFiBe3bt6dnz57Uq1cv1+t/9913WK1WAgMD7fZbLBZbPQkJCfTs2fOm5588eZL09HRatWpl22cymbjzzjvz19F8ioyMZPTo0bbPZrMZPz+/Qq1TREREiod8BypPT0/bz1lZWVSvXj3H/CbA9vZedHQ0ffv2ZcOGDXzxxRdMnjyZ1atX071795tePysrCycnJ+Lj43FycrI75uXlBdz4cuPcWK03Vu42GAw33V9YjEajbZROREREyhaH3vJr3rw5586dw9nZmYCAALutcuXKtnKBgYGMGjWKzZs306NHD5YtWwaAq6urbd5TtmbNmpGZmcn58+dzXDP70WCTJk3Ytm3bTdtUr149XFxc2Ldvn22f2Wy2zb8SERERKWgOBar27dvTunVrHn30UTZt2kRSUhK7d+9m4sSJxMXFce3aNYYPH8727ds5ffo0u3btYv/+/QQFBQHg7+/P1atX2bZtGxcvXuT3338nMDCQJ598kn79+rF27VpOnTrF/v37mTFjBp9//jlw4/Ha/v37ef755/n+++85evQoixcv5uLFi5QvX57+/fszduxYvvrqKw4fPszAgQMpV65cjlGr3Pz2228kJCRw5MgRAI4dO0ZCQgLnzp1z5HaJiIhIKeVQoDIYDHz++efcd999DBw4kMDAQHr37k1SUhLVqlXDycmJX3/9lX79+hEYGEivXr3o2LGjbfJ2aGgozz33HE888QRVqlSxTXZftmwZ/fr14+WXX+bOO++kW7du7N271zYnKTAwkM2bN3Pw4EFatWpF69at+c9//oOz840nmHPnzqV169Z06dKF9u3bExYWRlBQEG5uefuW4k8//ZRmzZrRuXNnAHr37k2zZs146623HLldIiIiUkoZrIU9uagYSEtLo2bNmsyZM4dBgwbdljrNZjMmkwnGA3nLcSWSdXKp/89HRETKkOy/36mpqXh7e+f5vHxPSi8JDhw4wNGjR2nVqhWpqalMnToVgEceeaSIWyYiIiKlUakMVHBjPaxjx47h6urKXXfdxY4dO6hcuTI7duygY8eOuZ539erV29hKERERKQ3KxCO/P7t27Ro///xzrscDAgIKpJ5bHTIUERGRoqNHfnnk7u5eYKFJREREBBx8y09EREREFKhEREREHFbmHvndbqYYU4Esm6DlCURERIovjVCJiIiIOEiBSkRERMRBClQiIiIiDlKgysVLL73EXXfdhdFoJCQkpKibIyIiIsWYAlUurFYrAwcO5IknnijqpoiIiEgxV6IDVVZWFjNmzCAgIACj0Ujt2rWZPn06SUlJGAwGVq9eTWhoKG5ubjRs2JDt27fn+dqvv/46L7zwAnXr1i28DoiIiEipUKIDVWRkJDNmzCAqKoojR47w/vvvU61aNdvxsWPH8vLLL3PgwAFCQ0Pp1q0bv/76axG2WEREREqjEhuorly5woIFC5g5cyb9+/enXr16tGnThsGDB9vKDB8+nMcee4ygoCAWL16MyWTi3//+d6G0x2KxYDab7TYREREpG0psoEpMTMRisdCuXbtcy7Ru3dr2s7OzMy1atCAxMbFQ2hMTE4PJZLJtfn5+hVKPiIiIFD8lNlC5u7vf0nkGg6GAW3JDZGQkqamptu3MmTOFUo+IiIgUPyU2UNWvXx93d3e2bduWa5lvv/3W9nNGRgbx8fE0aNCgUNpjNBrx9va220RERKRsKLHf5efm5sa4ceOIiIjA1dWVsLAwLly4wOHDh22PAd944w3q169PUFAQ8+bN49KlSwwcODBP1z9+/DhXr17l3LlzXLt27f/bu/eoqKr3f+DvcQYYYGBUCBgUJUEQ7wqpiHc0NVMs0zQTvIWmmJeKYKWAltdULPPSR/2IH3Xpqrzk8kteQjGENK5aQV4hNCCSFESU6/794WJ+jYIyM8I48H6tddbinLPP3s95hjxP5+w5IC0tDQDQsWNHmJqa1tt5ERERkfEx2oIKAJYsWQKZTIawsDDk5ORApVJh9uzZ6v2rVq3C6tWrkZWeeTIAAB+DSURBVJqaChcXF3z33XewtbWtU98zZ87EmTNn1Os9evQAAGRmZsLZ2fmZngcREREZN4kQQhg6iGctKysLL774IlJTUw32lvOioiIolUogBIBc//5EeKP7mIiIiJ471dfvwsJCrabvGO0cKiIiIqLnRZMsqGbPng2FQlHj8u9HhkRERER10Sgf+T1Nfn5+rS/etLa2hp2dnd5j6HrLkIiIiAxH1+u3UU9K15Wdnd0zKZqIiIiIgCb6yI+IiIjoWWJBRURERKSnJvnIryEpVyr1fm0CX5lARET0fOMdKiIiIiI9saAiIiIi0hMLKiIiIiI9saAiIiIi0hMLqhoUFBRgxIgRcHR0hJmZGZycnBAUFFTry0CJiIioaWNBVYNmzZrBz88PR44cweXLlxEVFYUffviBf5aGiIiIamTUBVVVVRVWr14NV1dXmJmZoU2bNli+fDmysrIgkUiwf/9+9O3bF3K5HJ06dUJsbGyd+m3RogXeffddeHl5oW3btvD19cWcOXMQFxdXvydERERERsmo30MVGhqKbdu2ITIyEv369UNubi5+//139f4PP/wQGzZsQMeOHbF+/XqMGTMGmZmZsLGx0WqcnJwcHDx4EAMHDqy1TWlpKUpLS9XrfDxIRETUdBjtHaq7d+/i888/x5o1axAQEAAXFxf069cPM2fOVLcJCgrCuHHj4OHhgS1btkCpVGLHjh11HmPSpEmwsLBAq1atYG1tje3bt9faduXKlVAqlerFyclJr/MjIiIi42G0BVVGRgZKS0vh6+tbaxtvb2/1zzKZDF5eXsjIyKjzGJGRkUhJScHhw4dx7do1LFq0qNa2oaGhKCwsVC83btyo8zhERERk3Iz2kZ+5ublOx0kkkjq3dXBwgIODAzp06AAbGxv0798fS5YsgUqleqytmZkZzMzMdIqJiIiIjJvR3qFq3749zM3NERMTU2ubc+fOqX+uqKhAcnIyOnTooNN4Qjz8e3r/nidFREREBBjxHSq5XI6PPvoIwcHBMDU1hY+PD/7++2/89ttv6seAmzZtQvv27eHh4YHIyEjcvn0b06dPf2rf0dHR+Ouvv/DSSy9BoVAgPT0dwcHB8PHxgbOzcz2fGRERERkboy2oAGDJkiWQyWQICwtDTk4OVCqVxruiVq1ahdWrVyM1NRUuLi747rvvYGtr+9R+zc3NsW3bNixcuBClpaVwcnLC66+/jpCQkPo8HSIiIjJSElH9LKsRycrKwosvvojU1FR0797dIDEUFRVBqVQCIQDk+vUlwhvdR0RERPRcqr5+FxYWwtraus7HGe0cKiIiIqLnhVE/8tPV7NmzsWfPnhr3vf3229i6deszG6swVLsKl4iIiIxPo3zk9zT5+fm1vsnc2toadnZ2eo+h6y1DIiIiMhxdr99N8g6VnZ3dMymaiIiIiADOoSIiIiLSGwsqIiIiIj01yUd+DUm5UqnzaxP4ugQiIiLjwDtURERERHpiQUVERESkJ6MpqIQQCAwMRMuWLSGRSNC8eXMsWLDA0GERERERGU9BdezYMURFReHo0aPIzc1F586d622sH3/8EaNHj4ajoyMkEgkOHz5cb2MRERGR8TOaguratWtQqVTo27cvHBwcIJPV33z6e/fuoVu3bvjyyy/rbQwiIiJqPIyioJo6dSrmzZuH7OxsSCQSODs7AwAqKioQFBSE5s2bw8bGBosXL8a/X/y+efNmtG/fHnK5HPb29njjjTfqNN7IkSPx6aef4vXXX6+P0yEiIqJGxigKqs8//xzLli1D69atkZubi8TERADArl27IJPJcP78eXzxxReIjIzE9u3bAQBJSUl47733sGzZMly6dAnHjh3DgAED6i3G0tJSFBUVaSxERETUNBjFe6iUSiWsrKwglUrh4OCg3u7k5ITIyEhIJBK4u7vjl19+QWRkJN555x1kZ2fD0tISr776KqysrNC2bVv06NGj3mJcuXIlli5dWm/9ExER0fPLKO5Q1aZPnz6QSCTqdW9vb1y5cgWVlZUYNmwY2rZti3bt2mHKlCnYu3cvSkpK6i2W0NBQFBYWqpcbN27U21hERET0fDHqgupJrKyskJKSgn379kGlUiEsLAzdunXDnTt36mU8MzMzWFtbayxERETUNBh1QXXu3LnH1tu3bw+pVAoAkMlkGDp0KNasWYOLFy8iKysLp06dMkSoRERE1IgZxRyq2ty4cQOLFi3CrFmzkJKSgo0bN2LdunUAgKNHj+L69esYMGAAWrRogejoaFRVVcHd3f2p/RYXF+Pq1avq9czMTKSlpaFly5Zo06ZNvZ0PERERGSejLqj8/f1x//599OrVC1KpFPPmzUNgYCAAoHnz5jh48CAiIiLw4MEDtG/fHvv27UOnTp2e2m9SUhIGDx6sXl+0aBEAICAgAFFRUfVyLkRERGS8JOLfL26iZ6aoqAhKpRIIASDXrQ8Rzo+GiIioIVVfvwsLC7WaD23Uc6iIiIiIngdNrqDKzs6GQqGodcnOzjZ0iERERGRkjHoOlS4cHR2Rlpb2xP3PUmGodrcMiYiIyPg0uYJKJpPB1dXV0GEQERFRI9LkHvkRERERPWssqIiIiIj0xIKKiIiISE8sqIiIiIj0xIKKiIiISE8sqIiIiIj0ZNCCKioqCs2bNzdkCI8pLy/HRx99hC5dusDS0hKOjo7w9/dHTk6OoUMjIiKi55ReBVVZWdmziuO5UVJSgpSUFCxZsgQpKSk4ePAgLl++jDFjxhg6NCIiInpOaVVQDRo0CEFBQVi0aBFsbW0xbNgwFBYWIjAwEHZ2drC2tsaQIUNw4cIF9TEXLlzA4MGDYWVlBWtra3h6eiIpKQmxsbGYNm0aCgsLIZFIIJFIEBERAeBhoRYcHIxWrVrB0tISvXv3RmxsrEYs8fHxGDhwICwsLNCiRQsMHz4ct2/fBgDcvXsXkydPhqWlJVQqFSIjIzFo0CAsWLDgqeeoVCpx8uRJTJgwAe7u7ujTpw82btyI5ORk/lkaIiIiqpHWd6h27doFmUyG+Ph4bN26FaNGjUJeXh6io6ORnJyMnj17wtfXF//88w8AYPLkyWjdujUSExORnJyMkJAQmJiYoG/fvtiwYQOsra2Rm5uL3NxcfPDBBwCAadOmIT4+Hvv378fFixcxfvx4jBgxAleuXAEApKWlwdfXF506dcJPP/2Es2fPYvTo0aisrAQALFq0CPHx8Thy5AhOnjyJuLg4pKSk6Jyk6qLvSY8nS0tLUVRUpLEQERFREyG0MHDgQNG9e3f1ekxMjLC2thYPHjzQaOfi4iK++uorIYQQVlZWIioqqsb+du7cKZRKpca2q1evColEIv7880+N7b6+viI0NFQIIcSkSZOEj49PjX0WFRUJExMT8c0336i33blzR1hYWIj58+fX8Uz/v/v37wtPT08xefLkJ7YLDw8XAB5bCgsLtR6TiIiIDKOwsFCn67fWf8vPy8tL/XNycjKKi4thY2Oj0eb+/fu4du0agId3i2bOnIndu3dj6NChGD9+PFxcXGrtPyUlBUIIuLm5aWwvLS1Vj5OWlobx48fXePz169dRXl6OXr16qbcplUq4u7trd6J4OEF94sSJqKqqwubNm5/YNjQ0FIsWLVKvFxUVwcnJSesxiYiIyPhoXVBZWlqqf66qqoJKpXpsfhMA9eOxiIgIvPXWW/i///s/fP/99wgPD8f+/fvx2muv1dh/VVUVpFIpkpOTIZVKNfYpFAoAgLm5ea3xCSEAABKJpMbtdVVeXo4JEyYgMzMTp06dgrW19RPbm5mZwczMTKsxiIiIqHHQ61t+PXv2RF5eHmQyGVxdXTUWW1tbdTs3NzcsXLgQJ06cwOuvv46dO3cCAExNTdXznqr16NEDlZWVyM/Pf6xPBwcHAEDXrl0RExNTY0wuLi4wMTHBzz//rN5WVFSknn9VF9XF1JUrV/DDDz88dgeOiIiI6N/0KqiGDh0Kb29vjB07FsePH0dWVhYSEhKwePFiJCUl4f79+wgKCkJsbCz++OMPxMfHIzExER4eHgAAZ2dnFBcXIyYmBrdu3UJJSQnc3NwwefJk+Pv74+DBg8jMzERiYiJWr16N6OhoAA8fryUmJmLOnDm4ePEifv/9d2zZsgW3bt2ClZUVAgIC8OGHH+L06dP47bffMH36dDRr1uyxu1Y1qaiowBtvvIGkpCTs3bsXlZWVyMvLQ15eXqN8TQQRERHpT6+CSiKRIDo6GgMGDMD06dPh5uaGiRMnIisrC/b29pBKpSgoKIC/vz/c3NwwYcIEjBw5EkuXLgUA9O3bF7Nnz8abb76JF154AWvWrAEA7Ny5E/7+/nj//ffh7u6OMWPG4Pz58+o5SW5ubjhx4gQuXLiAXr16wdvbG9999x1ksodPMNevXw9vb2+8+uqrGDp0KHx8fODh4QG5XP7Uc7p58yaOHDmCmzdvonv37lCpVOolISFBn3QRERFRIyUR2k4uMkL37t1Dq1atsG7dOsyYMaNBxiwqKoJSqURhYeFT518RERHR80HX67fWk9KNQWpqKn7//Xf06tULhYWFWLZsGQDAz8/PwJERERFRY9QoCyoAWLt2LS5dugRTU1N4enoiLi4Otra2iIuLw8iRI2s9rri4uAGjJCIiosagSTzy+7f79+/jzz//rHW/q6vrMxmHj/yIiIiMDx/51ZG5ufkzK5qIiIiIAD2/5UdERERELKiIiIiI9MaCioiIiEhPLKiIiIiI9MSCioiIiEhPLKiIiIiI9MSCioiIiEhPLKiIiIiI9MSCioiIiEhPLKiIiIiI9MSCioiIiEhPLKiIiIiI9MSCioiIiEhPLKiIiIiI9CQzdACNlRACAFBUVGTgSIiIiKiuqq/b1dfxumJBVU8KCgoAAE5OTgaOhIiIiLR19+5dKJXKOrdnQVVPWrZsCQDIzs7W6gMh/RUVFcHJyQk3btyAtbW1ocNpMph3w2HuDYN5N5z6zL0QAnfv3oWjo6NWx7GgqifNmj2cnqZUKvkfmoFYW1sz9wbAvBsOc28YzLvh1FfudbkRwknpRERERHpiQUVERESkJ2lERESEoYNorKRSKQYNGgSZjE9WGxpzbxjMu+Ew94bBvBvO85Z7idD2e4FEREREpIGP/IiIiIj0xIKKiIiISE8sqIiIiIj0xIKKiIiISE8sqPSwefNmvPjii5DL5fD09ERcXNwT2x84cAAdO3aEmZkZOnbsiEOHDjVQpI2PNrnftm0b+vfvjxYtWqBFixYYOnQofv755waMtvHQ9ne+2v79+yGRSDB27Nh6jrDx0jb3d+7cwdy5c6FSqSCXy+Hh4YHo6OgGirbx0DbvGzZsgLu7O8zNzeHk5ISFCxfiwYMHDRRt4/Djjz9i9OjRcHR0hEQiweHDh596zJkzZ+Dp6Qm5XI527dph69atDRDpIwTpZP/+/cLExERs27ZNpKeni/nz5wtLS0vxxx9/1Ng+ISFBSKVSsWLFCpGRkSFWrFghZDKZOHfuXANHbvy0zf1bb70lNm3aJFJTU0VGRoaYNm2aUCqV4ubNmw0cuXHTNu/VsrKyRKtWrUT//v2Fn59fA0XbuGib+9LSUuHl5SVeeeUVcfbsWZGVlSXi4uJEWlpaA0du3LTN+549e4SZmZnYu3evyMzMFMePHxcqlUosWLCggSM3btHR0eLjjz8WBw4cEADEoUOHntj++vXrwsLCQsyfP1+kp6eLbdu2CRMTE/Htt982UMQPsaDSUa9evcTs2bM1tnXo0EGEhITU2H7ChAlixIgRGtuGDx8uJk6cWG8xNlba5v5RFRUVwsrKSuzatas+wmu0dMl7RUWF8PHxEdu3bxcBAQEsqHSkbe63bNki2rVrJ8rKyhoivEZL27zPnTtXDBkyRGPbokWLRL9+/eotxsauLgVVcHCw6NChg8a2WbNmiT59+tRnaI/hIz8dlJWVITk5GS+//LLG9pdffhkJCQk1HvPTTz891n748OG1tqea6ZL7R5WUlKC8vFz9B6zp6XTN+7Jly/DCCy9gxowZ9R1io6VL7o8cOQJvb2/MnTsX9vb26Ny5M1asWIHKysqGCLlR0CXv/fr1Q3JysnpKwfXr1xEdHY1Ro0bVe7xNWW3X16SkJJSXlzdYHM/H60WNzK1bt1BZWQl7e3uN7fb29sjLy6vxmLy8PK3aU810yf2jQkJC0KpVKwwdOrQ+QmyUdMl7fHw8duzYgbS0tIYIsdHSJffXr1/HqVOnMHnyZERHR+PKlSuYO3cuKioqEBYW1hBhGz1d8j5x4kT8/fff6NevH4QQqKiowLvvvouQkJCGCLnJqu36WlFRgVu3bkGlUjVIHCyo9CCRSDTWhRCPbdOnPdVO11yuWbMG+/btQ2xsLORyeX2F12jVNe93797F22+/jW3btsHW1rahwmvUtPmdr6qqgp2dHf7zn/9AKpXC09MTOTk5+Oyzz1hQaUmbvMfGxmL58uXYvHkzevfujatXr2L+/PlQqVRYsmRJQ4TbZNX0OdW0vT6xoNKBra0tpFLpY/+Xkp+f/1iVXM3BwUGr9lQzXXJfbe3atVixYgV++OEHdO3atT7DbHS0zfu1a9eQlZWF0aNHq7dVVVUBAGQyGS5dugQXF5f6DbqR0OV3XqVSwcTEBFKpVL3Nw8MDeXl5KCsrg6mpab3G3BjokvclS5ZgypQpmDlzJgCgS5cuuHfvHgIDA/Hxxx+jWTPOsqkPtV1fZTIZbGxsGiwOfro6MDU1haenJ06ePKmx/eTJk+jbt2+Nx3h7ez/W/sSJE7W2p5rpknsA+Oyzz/DJJ5/g2LFj8PLyqu8wGx1t896hQwf88ssvSEtLUy9jxozB4MGDkZaWBicnp4YK3ejp8jvv4+ODq1evqotYALh8+TJUKhWLqTrSJe8lJSWPFU1SqRTi4RfA6i3Wpq6266uXlxdMTEwaLpAGnQLfiFR/nXbHjh0iPT1dLFiwQFhaWoqsrCwhhBBTpkzR+CZIfHy8kEqlYtWqVSIjI0OsWrWKr03Qkba5X716tTA1NRXffvutyM3NVS9379411CkYJW3z/ih+y0932uY+OztbKBQKERQUJC5duiSOHj0q7OzsxKeffmqoUzBK2uY9PDxcWFlZiX379onr16+LEydOCBcXFzFhwgRDnYJRunv3rkhNTRWpqakCgFi/fr1ITU1Vv64iJCRETJkyRd2++rUJCxcuFOnp6WLHjh18bYKx2bRpk2jbtq0wNTUVPXv2FGfOnFHvGzhwoAgICNBo/8033wh3d3dhYmIiOnToIA4cONDAETce2uS+bdu2AsBjS3h4eMMHbuS0/Z3/NxZU+tE29wkJCaJ3797CzMxMtGvXTixfvlxUVFQ0cNTGT5u8l5eXi4iICOHi4iLkcrlwcnISc+bMEbdv3zZA5Mbr9OnTNf6bXZ3rgIAAMXDgQI1jYmNjRY8ePYSpqalwdnYWW7ZsafC4JULwPiQRERGRPjiHioiIiEhPLKiIiIiI9MSCioiIiEhPLKiIiIiI9MSCioiIiEhPLKiIiIiI9MSCioiIiEhPLKiI6Lk1aNAgLFiwQK8+oqKi0Lx582cUERFRzVhQEZFO8vPzMWvWLLRp0wZmZmZwcHDA8OHD8dNPPxk6NK1JJBIcPnzY0GHUKiIiAt27dzd0GET0BDJDB0BExmncuHEoLy/Hrl270K5dO/z111+IiYnBP//8Y+jQGg0hBCorKw0dBhHVAe9QEZHW7ty5g7Nnz2L16tUYPHgw2rZti169eiE0NBSjRo3SaBcYGAh7e3vI5XJ07twZR48eBQAUFBRg0qRJaN26NSwsLNClSxfs27fvieOWlZUhODgYrVq1gqWlJXr37o3Y2FiNNlFRUWjTpg0sLCzw2muvoaCgQKtzy8rKgkQiwddff43+/fvD3NwcL730Ei5fvozExER4eXlBoVBgxIgR+Pvvv9XHTZ06FWPHjsXSpUthZ2cHa2trzJo1C2VlZeo2paWleO+992BnZwe5XI5+/fohMTFRvT82NhYSiQTHjx+Hl5cXzMzMsHv3bixduhQXLlyARCKBRCJBVFQUAGD9+vXo0qULLC0t4eTkhDlz5qC4uFgjF82bN8fx48fh4eGhjjs3N1fjnP/73/+iU6dOMDMzg0qlQlBQkHpfYWEhAgMD1ec0ZMgQXLhwQaucEjUFLKiISGsKhQIKhQKHDx9GaWlpjW2qqqowcuRIJCQkYM+ePUhPT8eqVasglUoBAA8ePICnpyeOHj2KX3/9FYGBgZgyZQrOnz9f67jTpk1DfHw89u/fj4sXL2L8+PEYMWIErly5AgA4f/48pk+fjjlz5iAtLQ2DBw/Gp59+qtM5hoeHY/HixUhJSYFMJsOkSZMQHByMzz//HHFxcbh27RrCwsI0jomJiUFGRgZOnz6Nffv24dChQ1i6dKl6f3BwMA4cOIBdu3YhJSUFrq6uGD58+GN39YKDg7Fy5UpkZGTg5Zdfxvvvv49OnTohNzcXubm5ePPNNwEAzZo1wxdffIFff/0Vu3btwqlTpxAcHKzRV0lJCdauXYvdu3fjxx9/RHZ2Nj744AP1/i1btmDu3LkIDAzEL7/8giNHjsDV1RXAwztko0aNQl5eHqKjo5GcnIyePXvC19eXdyKJHtXgf46ZiBqFb7/9VrRo0ULI5XLRt29fERoaKi5cuKDef/z4cdGsWTNx6dKlOvf5yiuviPfff1+9PnDgQDF//nwhhBBXr14VEolE/PnnnxrH+Pr6itDQUCGEEJMmTRIjRozQ2P/mm28KpVL5xHEBiEOHDgkhhMjMzBQAxPbt29X79+3bJwCImJgY9baVK1cKd3d39XpAQIBo2bKluHfvnnrbli1bhEKhEJWVlaK4uFiYmJiIvXv3qveXlZUJR0dHsWbNGiGEEKdPnxYAxOHDhzXiCw8PF926dXviOQghxNdffy1sbGzU6zt37hQAxNWrV9XbNm3aJOzt7dXrjo6O4uOPP66xv5iYGGFtbS0ePHigsd3FxUV89dVXT42HqCnhHSoi0sm4ceOQk5ODI0eOYPjw4YiNjUXPnj3Vj6PS0tLQunVruLm51Xh8ZWUlli9fjq5du8LGxgYKhQInTpxAdnZ2je1TUlIghICbm5v6DplCocCZM2dw7do1AEBGRga8vb01jnt0va66du2q/tne3h4A0KVLF41t+fn5Gsd069YNFhYWGmMXFxfjxo0buHbtGsrLy+Hj46Peb2Jigl69eiEjI0OjHy8vrzrFePr0aQwbNgytWrWClZUV/P39UVBQgHv37qnbWFhYwMXFRb2uUqnUcefn5yMnJwe+vr419p+cnIzi4mL151O9ZGZmqnNORA9xUjoR6Uwul2PYsGEYNmwYwsLCMHPmTISHh2Pq1KkwNzd/4rHr1q1DZGQkNmzYoJ4HtGDBAo05R/9WVVUFqVSK5ORk9WPDagqFAsDDR1TPiomJifpniURS47aqqqo69SWRSNSxVfdVTQjx2DZLS8un9vnHH3/glVdewezZs/HJJ5+gZcuWOHv2LGbMmIHy8vIaz+PRWJ72GVVVVUGlUj02Tw0AX0VB9AjeoSKiZ6Zjx47quyNdu3bFzZs3cfny5RrbxsXFwc/PD2+//Ta6deuGdu3aqedC1aRHjx6orKxEfn4+XF1dNRYHBwf1+OfOndM47tH1+nThwgXcv39fY2yFQoHWrVvD1dUVpqamOHv2rHp/eXk5kpKS4OHh8cR+TU1NH/u2X1JSEioqKrBu3Tr06dMHbm5uyMnJ0SpeKysrODs7IyYmpsb9PXv2RF5eHmQy2WM5t7W11WososaOBRURaa2goABDhgzBnj17cPHiRWRmZuKbb77BmjVr4OfnBwAYOHAgBgwYgHHjxuHkyZPIzMzE999/j2PHjgEAXF1dcfLkSSQkJCAjIwOzZs1CXl5erWO6ublh8uTJ8Pf3x8GDB5GZmYnExESsXr0a0dHRAID33nsPx44dw5o1a3D58mV8+eWX6vEaQllZGWbMmIH09HR8//33CA8PR1BQEJo1awZLS0u8++67+PDDD3Hs2DGkp6fjnXfeQUlJCWbMmPHEfp2dnZGZmYm0tDTcunULpaWlcHFxQUVFBTZu3Ijr169j9+7d2Lp1q9YxR0REYN26dfjiiy9w5coVpKSkYOPGjQCAoUOHwtvbG2PHjsXx48eRlZWFhIQELF68GElJSTrliKjRMugMLiIySg8ePBAhISGiZ8+eQqlUCgsLC+Hu7i4WL14sSkpK1O0KCgrEtGnThI2NjZDL5aJz587i6NGj6n1+fn5CoVAIOzs7sXjxYuHv7y/8/PzUx/97UroQDydxh4WFCWdnZ2FiYiIcHBzEa6+9Ji5evKhus2PHDtG6dWthbm4uRo8eLdauXavTpPTU1FT1/urJ4rdv31Zv27lzp0a/AQEBws/PT4SFhQkbGxuhUCjEzJkzNSZ0379/X8ybN0/Y2toKMzMz4ePjI37++ecnjlOd73HjxonmzZsLAGLnzp1CCCHWr18vVCqVMDc3F8OHDxf/+9//NI5/NEYhhDh06JB49J/+rVu3Cnd3d2FiYiJUKpWYN2+eel9RUZGYN2+ecHR0FCYmJsLJyUlMnjxZZGdnPzGnRE2NRIhnOOmAiKiJmjp1Ku7cufNcv3GdiOoPH/kRERER6YkFFREREZGe+MiPiIiISE+8Q0VERESkJxZURERERHpiQUVERESkJxZURERERHpiQUVERESkJxZURERERHpiQUVERESkJxZURERERHpiQUVERESkp/8HtnYimSaEfiMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "variables = best_gbm._model_json['output']['variable_importances']['variable']\n",
    "y_pos = np.arange(len(variables))\n",
    "scaled_importance = best_gbm._model_json['output']['variable_importances']['scaled_importance']\n",
    "ax.barh(y_pos, scaled_importance, align='center', color='green', ecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(variables)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Scaled Importance')\n",
    "ax.set_title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-create GBM Model using only predictors with high variable importance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'trestbps', 'thalach', 'oldpeak', 'ca', 'thal', 'cp_2']\n"
     ]
    }
   ],
   "source": [
    "predictors2 = df.drop(['target_1','restecg_2','cp_3','fbs_1','cp_1','restecg_1','sex_1','exang_1','slope','chol'], axis = 1).columns\n",
    "# del predictors[-1]\n",
    "print(predictors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = df.split_frame(\n",
    "    ratios=[0.6,0.2], \n",
    "    seed=101, \n",
    "    destination_frames=['train.hex','valid.hex','test.hex']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "# Train and validate a cartesian grid of GBMs\n",
    "gbm_grid3 = H2OGridSearch(model = gbm_grid,\n",
    "                          grid_id = 'gbm_grid3',\n",
    "                          hyper_params = gbm_params1)\n",
    "\n",
    "gbm_grid3.train(x=predictors2\n",
    "                , y=response\n",
    "                , training_frame=train\n",
    "                , validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the grid results, sorted by validation AUC\n",
    "gbm_gridperf3 = gbm_grid3.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm3 = gbm_gridperf3.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.17698539188577925\n",
      "RMSE: 0.42069631788949524\n",
      "LogLoss: 0.5668920349945668\n",
      "Mean Per-Class Error: 0.20123106060606055\n",
      "AUC: 0.8513257575757576\n",
      "AUCPR: 0.8256048220590629\n",
      "Gini: 0.7026515151515151\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2640301438148829: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>(9.0/32.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>(4.0/33.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>(13.0/65.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1   Error          Rate\n",
       "0      0  23.0   9.0  0.2812    (9.0/32.0)\n",
       "1      1   4.0  29.0  0.1212    (4.0/33.0)\n",
       "2  Total  27.0  38.0     0.2   (13.0/65.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.264030</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.827238</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.264030</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.264030</td>\n",
       "      <td>0.606211</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.514883</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.264030</td>\n",
       "      <td>0.798769</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold      value   idx\n",
       "0                        max f1   0.264030   0.816901  37.0\n",
       "1                        max f2   0.020474   0.882353  54.0\n",
       "2                  max f0point5   0.827238   0.840000  22.0\n",
       "3                  max accuracy   0.264030   0.800000  37.0\n",
       "4                 max precision   0.999389   1.000000   0.0\n",
       "5                    max recall   0.020474   1.000000  54.0\n",
       "6               max specificity   0.999389   1.000000   0.0\n",
       "7              max absolute_mcc   0.264030   0.606211  37.0\n",
       "8    max min_per_class_accuracy   0.514883   0.750000  32.0\n",
       "9   max mean_per_class_accuracy   0.264030   0.798769  37.0\n",
       "10                      max tns   0.999389  32.000000   0.0\n",
       "11                      max fns   0.999389  32.000000   0.0\n",
       "12                      max fps   0.002646  32.000000  64.0\n",
       "13                      max tps   0.020474  33.000000  54.0\n",
       "14                      max tnr   0.999389   1.000000   0.0\n",
       "15                      max fnr   0.999389   0.969697   0.0\n",
       "16                      max fpr   0.002646   1.000000  64.0\n",
       "17                      max tpr   0.020474   1.000000  54.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 50.77 %, avg score: 50.31 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.999324</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999338</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.999192</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999314</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.999065</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>96.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.990966</td>\n",
       "      <td>1.313131</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.995119</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.997645</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>31.313131</td>\n",
       "      <td>77.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.956878</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984979</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.994722</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>96.969697</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.905508</td>\n",
       "      <td>1.688312</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.933019</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.973126</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>68.831169</td>\n",
       "      <td>77.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.732209</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.590909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.814661</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.936557</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>-1.515152</td>\n",
       "      <td>59.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.514883</td>\n",
       "      <td>1.125541</td>\n",
       "      <td>1.492195</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.870151</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>12.554113</td>\n",
       "      <td>49.219467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.244519</td>\n",
       "      <td>1.313131</td>\n",
       "      <td>1.464646</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.300972</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.782585</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>31.313131</td>\n",
       "      <td>46.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.168711</td>\n",
       "      <td>0.328283</td>\n",
       "      <td>1.313131</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.217840</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.707286</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>-67.171717</td>\n",
       "      <td>31.313131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.046541</td>\n",
       "      <td>0.562771</td>\n",
       "      <td>1.212121</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.098517</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.625336</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>-43.722944</td>\n",
       "      <td>21.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.328283</td>\n",
       "      <td>1.120690</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.562863</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-67.171717</td>\n",
       "      <td>12.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.503057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.015385         0.999324  1.969697   \n",
       "1         2                  0.030769         0.999282  1.969697   \n",
       "2         3                  0.030769         0.999268  0.000000   \n",
       "3         4                  0.046154         0.999192  1.969697   \n",
       "4         5                  0.061538         0.999065  1.969697   \n",
       "5         6                  0.107692         0.997129  1.969697   \n",
       "6         7                  0.153846         0.990966  1.313131   \n",
       "7         8                  0.200000         0.956878  1.969697   \n",
       "8         9                  0.307692         0.905508  1.688312   \n",
       "9        10                  0.400000         0.732209  0.984848   \n",
       "10       11                  0.507692         0.514883  1.125541   \n",
       "11       12                  0.600000         0.244519  1.313131   \n",
       "12       13                  0.692308         0.168711  0.328283   \n",
       "13       14                  0.800000         0.046541  0.562771   \n",
       "14       15                  0.892308         0.011491  0.328283   \n",
       "15       16                  1.000000         0.002646  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.969697       1.000000  0.999389                  1.000000   \n",
       "1          1.969697       1.000000  0.999287                  1.000000   \n",
       "2          1.969697       0.000000  0.000000                  1.000000   \n",
       "3          1.969697       1.000000  0.999267                  1.000000   \n",
       "4          1.969697       1.000000  0.999133                  1.000000   \n",
       "5          1.969697       1.000000  0.998005                  1.000000   \n",
       "6          1.772727       0.666667  0.995119                  0.900000   \n",
       "7          1.818182       1.000000  0.984979                  0.923077   \n",
       "8          1.772727       0.857143  0.933019                  0.900000   \n",
       "9          1.590909       0.500000  0.814661                  0.807692   \n",
       "10         1.492195       0.571429  0.623500                  0.757576   \n",
       "11         1.464646       0.666667  0.300972                  0.743590   \n",
       "12         1.313131       0.166667  0.217840                  0.666667   \n",
       "13         1.212121       0.285714  0.098517                  0.615385   \n",
       "14         1.120690       0.166667  0.021427                  0.568966   \n",
       "15         1.000000       0.000000  0.007520                  0.507692   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.999389      0.030303                 0.030303   96.969697   \n",
       "1           0.999338      0.030303                 0.060606   96.969697   \n",
       "2           0.999338      0.000000                 0.060606 -100.000000   \n",
       "3           0.999314      0.030303                 0.090909   96.969697   \n",
       "4           0.999269      0.030303                 0.121212   96.969697   \n",
       "5           0.998727      0.090909                 0.212121   96.969697   \n",
       "6           0.997645      0.060606                 0.272727   31.313131   \n",
       "7           0.994722      0.090909                 0.363636   96.969697   \n",
       "8           0.973126      0.181818                 0.545455   68.831169   \n",
       "9           0.936557      0.090909                 0.636364   -1.515152   \n",
       "10          0.870151      0.121212                 0.757576   12.554113   \n",
       "11          0.782585      0.121212                 0.878788   31.313131   \n",
       "12          0.707286      0.030303                 0.909091  -67.171717   \n",
       "13          0.625336      0.060606                 0.969697  -43.722944   \n",
       "14          0.562863      0.030303                 1.000000  -67.171717   \n",
       "15          0.503057      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         96.969697  \n",
       "1         96.969697  \n",
       "2         96.969697  \n",
       "3         96.969697  \n",
       "4         96.969697  \n",
       "5         96.969697  \n",
       "6         77.272727  \n",
       "7         81.818182  \n",
       "8         77.272727  \n",
       "9         59.090909  \n",
       "10        49.219467  \n",
       "11        46.464646  \n",
       "12        31.313131  \n",
       "13        21.212121  \n",
       "14        12.068966  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_gbm_perf3 = best_gbm3.model_performance(test)\n",
    "print(best_gbm_perf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n",
      "0.82\n",
      "0.8298795180722892\n"
     ]
    }
   ],
   "source": [
    "gs_rd_gbm_recall = round(27/33 , 2)\n",
    "gs_rd_gbm_precision = round(27/32, 2)\n",
    "gs_rd_gbm_f1 = 2*((gs_rd_gbm_precision * gs_rd_gbm_recall)/(gs_rd_gbm_precision + gs_rd_gbm_recall))\n",
    "\n",
    "print(gs_rd_gbm_precision)\n",
    "print(gs_rd_gbm_recall)\n",
    "print(gs_rd_gbm_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate GBM using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca', 'thal', 'sex_1', 'fbs_1', 'exang_1', 'cp_1', 'cp_2', 'cp_3', 'restecg_1', 'restecg_2']\n"
     ]
    }
   ],
   "source": [
    "predictors = df.drop(['target_1'], axis = 1).columns\n",
    "# del predictors[-1]\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.split_frame(\n",
    "    ratios=[0.7], \n",
    "    seed=101, \n",
    "    destination_frames=['train.hex','test.hex']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "## Depth 10 is usually plenty of depth for most datasets, but you never know\n",
    "hyper_params = {'max_depth' : [3,5,7,9]}\n",
    "\n",
    "#Build initial GBM Model\n",
    "gbm_grid_cv = H2OGradientBoostingEstimator(\n",
    "        ## more trees is better if the learning rate is small enough \n",
    "        ## here, use \"more than enough\" trees - we have early stopping\n",
    "        ntrees=10000,\n",
    "        ## smaller learning rate is better\n",
    "        ## since we have learning_rate_annealing, we can afford to start with a \n",
    "        #bigger learning rate\n",
    "        learn_rate=0.05,\n",
    "        ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "        ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "        learn_rate_annealing = 0.99,\n",
    "        ## sample 90% of rows per tree\n",
    "        sample_rate = 0.9,\n",
    "        ## sample 90% of columns per split\n",
    "        col_sample_rate = 0.9,\n",
    "        ## fix a random number generator seed for reproducibility\n",
    "        seed = 101,\n",
    "        ## score every 10 trees to make early stopping reproducible \n",
    "        #(it depends on the scoring interval)\n",
    "        score_tree_interval = 10, \n",
    "        ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "        #5 consecutive scoring events\n",
    "        stopping_rounds = 10,\n",
    "        stopping_metric = \"AUC\",\n",
    "        stopping_tolerance = 1e-4,\n",
    "        nfolds = 3)\n",
    "\n",
    "#Build grid search with previously made GBM and hyper parameters\n",
    "grid_cv = H2OGridSearch(model = gbm_grid_cv\n",
    "                     ,hyper_params = hyper_params,\n",
    "                         grid_id = 'depth_grid_cv',\n",
    "                         search_criteria = {'strategy': \"Cartesian\"})\n",
    "\n",
    "\n",
    "#Train grid search\n",
    "grid_cv.train(x=predictors, \n",
    "           y=response,\n",
    "           training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max_depth              model_ids                 auc\n",
      "0           3  depth_grid_cv_model_1  0.8757879124953653\n",
      "1           9  depth_grid_cv_model_4  0.8747682610307749\n",
      "2           7  depth_grid_cv_model_3  0.8729143492769744\n",
      "3           5  depth_grid_cv_model_2  0.8706896551724137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_grid_cv = grid_cv.get_grid(sort_by='auc',decreasing=True)\n",
    "print(sorted_grid_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM hyperparameters\n",
    "gbm_params1 = {'learn_rate': [0.01, 0.1],\n",
    "                'max_depth': [3, 7, 9], \n",
    "                'sample_rate': [0.8, 1.0],\n",
    "                'col_sample_rate': [0.8, 0.9]\n",
    "}\n",
    "\n",
    "\n",
    "gbm_grid_cv = H2OGradientBoostingEstimator(\n",
    "        ## more trees is better if the learning rate is small enough \n",
    "        ## here, use \"more than enough\" trees - we have early stopping\n",
    "        ntrees=10000,\n",
    "        ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "        ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "        learn_rate_annealing = 0.99,\n",
    "        ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "        #5 consecutive scoring events\n",
    "        stopping_rounds = 10,\n",
    "        stopping_metric = \"AUC\",\n",
    "        stopping_tolerance = 1e-4,\n",
    "        distribution = \"bernoulli\",\n",
    "        seed = 101,\n",
    "        score_tree_interval = 10,\n",
    "        nfolds = 3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "# Train and validate a cartesian grid of GBMs\n",
    "gbm_grid_cv = H2OGridSearch(model = gbm_grid_cv,\n",
    "                          grid_id = 'gbm_grid_cv',\n",
    "                          hyper_params = gbm_params1)\n",
    "\n",
    "gbm_grid_cv.train(x=predictors\n",
    "                , y=response\n",
    "                , training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grid results, sorted by validation AUC\n",
    "gbm_grid_perf_cv = gbm_grid_cv.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm_cv = gbm_grid_perf_cv.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.12619543219640103\n",
      "RMSE: 0.3552399642444541\n",
      "LogLoss: 0.4383037979951221\n",
      "Mean Per-Class Error: 0.14829931972789112\n",
      "AUC: 0.8938775510204081\n",
      "AUCPR: 0.869705530772403\n",
      "Gini: 0.7877551020408162\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3268838733995616: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>(10.0/45.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>(4.0/49.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>39.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>(14.0/94.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1   Error          Rate\n",
       "0      0  35.0  10.0  0.2222   (10.0/45.0)\n",
       "1      1   4.0  45.0  0.0816    (4.0/49.0)\n",
       "2  Total  39.0  55.0  0.1489   (14.0/94.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.326884</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.136927</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.629240</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.466690</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.326884</td>\n",
       "      <td>0.705814</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.466690</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.466690</td>\n",
       "      <td>0.851701</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold      value   idx\n",
       "0                        max f1   0.326884   0.865385  54.0\n",
       "1                        max f2   0.136927   0.902256  69.0\n",
       "2                  max f0point5   0.629240   0.866667  43.0\n",
       "3                  max accuracy   0.466690   0.851064  46.0\n",
       "4                 max precision   0.997045   1.000000   0.0\n",
       "5                    max recall   0.010675   1.000000  85.0\n",
       "6               max specificity   0.997045   1.000000   0.0\n",
       "7              max absolute_mcc   0.326884   0.705814  54.0\n",
       "8    max min_per_class_accuracy   0.466690   0.836735  46.0\n",
       "9   max mean_per_class_accuracy   0.466690   0.851701  46.0\n",
       "10                      max tns   0.997045  45.000000   0.0\n",
       "11                      max fns   0.997045  48.000000   0.0\n",
       "12                      max fps   0.003446  45.000000  93.0\n",
       "13                      max tps   0.010675  49.000000  85.0\n",
       "14                      max tnr   0.997045   1.000000   0.0\n",
       "15                      max fnr   0.997045   0.979592   0.0\n",
       "16                      max fpr   0.003446   1.000000  93.0\n",
       "17                      max tpr   0.010675   1.000000  85.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 52.13 %, avg score: 51.72 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.994593</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.993183</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.992568</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994812</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.991879</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994224</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.991229</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993710</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.985668</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991547</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.980869</td>\n",
       "      <td>1.438776</td>\n",
       "      <td>1.781341</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.984545</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.989547</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>43.877551</td>\n",
       "      <td>78.134111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.958484</td>\n",
       "      <td>1.534694</td>\n",
       "      <td>1.716434</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.972641</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.985098</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>53.469388</td>\n",
       "      <td>71.643394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.892586</td>\n",
       "      <td>1.492063</td>\n",
       "      <td>1.644315</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.941503</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.971085</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>49.206349</td>\n",
       "      <td>64.431487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.766913</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.716434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829123</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.933727</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>71.643394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.465581</td>\n",
       "      <td>1.492063</td>\n",
       "      <td>1.673469</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.647296</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>49.206349</td>\n",
       "      <td>67.346939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.317556</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>1.541545</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.385916</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.799652</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>-14.739229</td>\n",
       "      <td>54.154519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.169312</td>\n",
       "      <td>0.191837</td>\n",
       "      <td>1.337044</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.236116</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.714268</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>-80.816327</td>\n",
       "      <td>33.704391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.060029</td>\n",
       "      <td>0.426304</td>\n",
       "      <td>1.227755</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.120392</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.643003</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>-57.369615</td>\n",
       "      <td>22.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.014372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.096210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.577747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>9.620991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.191837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.517167</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-80.816327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010638         0.994593  1.918367   \n",
       "1         2                  0.021277         0.993183  1.918367   \n",
       "2         3                  0.031915         0.992568  1.918367   \n",
       "3         4                  0.042553         0.991879  1.918367   \n",
       "4         5                  0.053191         0.991229  1.918367   \n",
       "5         6                  0.106383         0.985668  1.918367   \n",
       "6         7                  0.148936         0.980869  1.438776   \n",
       "7         8                  0.202128         0.958484  1.534694   \n",
       "8         9                  0.297872         0.892586  1.492063   \n",
       "9        10                  0.404255         0.766913  1.918367   \n",
       "10       11                  0.500000         0.465581  1.492063   \n",
       "11       12                  0.595745         0.317556  0.852608   \n",
       "12       13                  0.702128         0.169312  0.191837   \n",
       "13       14                  0.797872         0.060029  0.426304   \n",
       "14       15                  0.893617         0.014372  0.000000   \n",
       "15       16                  1.000000         0.003446  0.191837   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.918367       1.000000  0.997045                  1.000000   \n",
       "1          1.918367       1.000000  0.994408                  1.000000   \n",
       "2          1.918367       1.000000  0.992984                  1.000000   \n",
       "3          1.918367       1.000000  0.992458                  1.000000   \n",
       "4          1.918367       1.000000  0.991654                  1.000000   \n",
       "5          1.918367       1.000000  0.989385                  1.000000   \n",
       "6          1.781341       0.750000  0.984545                  0.928571   \n",
       "7          1.716434       0.800000  0.972641                  0.894737   \n",
       "8          1.644315       0.777778  0.941503                  0.857143   \n",
       "9          1.716434       1.000000  0.829123                  0.894737   \n",
       "10         1.673469       0.777778  0.647296                  0.872340   \n",
       "11         1.541545       0.444444  0.385916                  0.803571   \n",
       "12         1.337044       0.100000  0.236116                  0.696970   \n",
       "13         1.227755       0.222222  0.120392                  0.640000   \n",
       "14         1.096210       0.000000  0.033946                  0.571429   \n",
       "15         1.000000       0.100000  0.008295                  0.521277   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.997045      0.020408                 0.020408   91.836735   \n",
       "1           0.995726      0.020408                 0.040816   91.836735   \n",
       "2           0.994812      0.020408                 0.061224   91.836735   \n",
       "3           0.994224      0.020408                 0.081633   91.836735   \n",
       "4           0.993710      0.020408                 0.102041   91.836735   \n",
       "5           0.991547      0.102041                 0.204082   91.836735   \n",
       "6           0.989547      0.061224                 0.265306   43.877551   \n",
       "7           0.985098      0.081633                 0.346939   53.469388   \n",
       "8           0.971085      0.142857                 0.489796   49.206349   \n",
       "9           0.933727      0.204082                 0.693878   91.836735   \n",
       "10          0.878878      0.142857                 0.836735   49.206349   \n",
       "11          0.799652      0.081633                 0.918367  -14.739229   \n",
       "12          0.714268      0.020408                 0.938776  -80.816327   \n",
       "13          0.643003      0.040816                 0.979592  -57.369615   \n",
       "14          0.577747      0.000000                 0.979592 -100.000000   \n",
       "15          0.517167      0.020408                 1.000000  -80.816327   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         91.836735  \n",
       "1         91.836735  \n",
       "2         91.836735  \n",
       "3         91.836735  \n",
       "4         91.836735  \n",
       "5         91.836735  \n",
       "6         78.134111  \n",
       "7         71.643394  \n",
       "8         64.431487  \n",
       "9         71.643394  \n",
       "10        67.346939  \n",
       "11        54.154519  \n",
       "12        33.704391  \n",
       "13        22.775510  \n",
       "14         9.620991  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_gbm_perf_cv = best_gbm_cv.model_performance(test)\n",
    "print(best_gbm_perf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "0.92\n",
      "0.8671264367816092\n"
     ]
    }
   ],
   "source": [
    "cv_gbm_recall = round(45/49 , 2)\n",
    "cv_gbm_precision = round(45/55, 2)\n",
    "cv_gbm_f1 = 2*((cv_gbm_precision * cv_gbm_recall)/(cv_gbm_precision + cv_gbm_recall))\n",
    "\n",
    "print(cv_gbm_precision)\n",
    "print(cv_gbm_recall)\n",
    "print(cv_gbm_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "variables = best_gbm_cv._model_json['output']['variable_importances']['variable']\n",
    "y_pos = np.arange(len(variables))\n",
    "scaled_importance = best_gbm_cv._model_json['output']['variable_importances']['scaled_importance']\n",
    "ax.barh(y_pos, scaled_importance, align='center', color='green', ecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(variables)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Scaled Importance')\n",
    "ax.set_title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thal</td>\n",
       "      <td>56.045208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca</td>\n",
       "      <td>47.323048</td>\n",
       "      <td>0.844373</td>\n",
       "      <td>0.150716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thalach</td>\n",
       "      <td>33.569996</td>\n",
       "      <td>0.598981</td>\n",
       "      <td>0.106915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>31.558182</td>\n",
       "      <td>0.563084</td>\n",
       "      <td>0.100508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chol</td>\n",
       "      <td>22.408554</td>\n",
       "      <td>0.399830</td>\n",
       "      <td>0.071368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>22.159781</td>\n",
       "      <td>0.395391</td>\n",
       "      <td>0.070575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>slope</td>\n",
       "      <td>20.588825</td>\n",
       "      <td>0.367361</td>\n",
       "      <td>0.065572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cp_2</td>\n",
       "      <td>17.910570</td>\n",
       "      <td>0.319574</td>\n",
       "      <td>0.057042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>age</td>\n",
       "      <td>17.843971</td>\n",
       "      <td>0.318385</td>\n",
       "      <td>0.056830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exang_1</td>\n",
       "      <td>17.608673</td>\n",
       "      <td>0.314187</td>\n",
       "      <td>0.056081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sex_1</td>\n",
       "      <td>9.274458</td>\n",
       "      <td>0.165482</td>\n",
       "      <td>0.029538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_3</td>\n",
       "      <td>6.217346</td>\n",
       "      <td>0.110934</td>\n",
       "      <td>0.019801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>restecg_1</td>\n",
       "      <td>5.303135</td>\n",
       "      <td>0.094622</td>\n",
       "      <td>0.016890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cp_1</td>\n",
       "      <td>4.436601</td>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.014130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fbs_1</td>\n",
       "      <td>1.739546</td>\n",
       "      <td>0.031038</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variable  relative_importance  scaled_importance  percentage\n",
       "0        thal            56.045208           1.000000    0.178495\n",
       "1          ca            47.323048           0.844373    0.150716\n",
       "2     thalach            33.569996           0.598981    0.106915\n",
       "3     oldpeak            31.558182           0.563084    0.100508\n",
       "4        chol            22.408554           0.399830    0.071368\n",
       "5    trestbps            22.159781           0.395391    0.070575\n",
       "6       slope            20.588825           0.367361    0.065572\n",
       "7        cp_2            17.910570           0.319574    0.057042\n",
       "8         age            17.843971           0.318385    0.056830\n",
       "9     exang_1            17.608673           0.314187    0.056081\n",
       "10      sex_1             9.274458           0.165482    0.029538\n",
       "11       cp_3             6.217346           0.110934    0.019801\n",
       "12  restecg_1             5.303135           0.094622    0.016890\n",
       "13       cp_1             4.436601           0.079161    0.014130\n",
       "14      fbs_1             1.739546           0.031038    0.005540\n",
       "15  restecg_2             0.000000           0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbm_cv._model_json['output']['variable_importances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_gbm_perf_cv.plot(type=\"roc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate GBM model using cross validation and reduced set of predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca', 'thal', 'exang_1', 'cp_2']\n"
     ]
    }
   ],
   "source": [
    "predictors_cv2 = df.drop(['target_1','restecg_2','fbs_1','cp_1','restecg_1','cp_3','sex_1'], axis = 1).columns\n",
    "# del predictors[-1]\n",
    "print(predictors_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM hyperparameters\n",
    "gbm_params1 = {'learn_rate': [0.01, 0.1],\n",
    "                'max_depth': [3, 7, 9], # range(new_min, new_max),# \n",
    "                'sample_rate': [0.8, 1.0],\n",
    "                'col_sample_rate': [0.8, 0.9]\n",
    "}\n",
    "\n",
    "\n",
    "gbm_grid_cv = H2OGradientBoostingEstimator(\n",
    "        ## more trees is better if the learning rate is small enough \n",
    "        ## here, use \"more than enough\" trees - we have early stopping\n",
    "        ntrees=10000,\n",
    "        ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "        ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "        learn_rate_annealing = 0.99,\n",
    "        ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "        #5 consecutive scoring events\n",
    "        stopping_rounds = 10,\n",
    "        stopping_metric = \"AUC\",\n",
    "        stopping_tolerance = 1e-4,\n",
    "        distribution = \"bernoulli\",\n",
    "        seed = 101,\n",
    "        score_tree_interval = 10,\n",
    "        nfolds = 3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "# Train and validate a cartesian grid of GBMs\n",
    "gbm_grid_cv2 = H2OGridSearch(model = gbm_grid_cv,\n",
    "                          grid_id = 'gbm_grid_cv2',\n",
    "                          hyper_params = gbm_params1)\n",
    "\n",
    "gbm_grid_cv2.train(x=predictors_cv2\n",
    "                , y=response\n",
    "                , training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grid results, sorted by validation AUC\n",
    "gbm_grid_perf_cv2 = gbm_grid_cv2.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm_cv2 = gbm_grid_perf_cv2.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.1525771146710466\n",
      "RMSE: 0.39061120653540726\n",
      "LogLoss: 0.4821830817297541\n",
      "Mean Per-Class Error: 0.17800453514739234\n",
      "AUC: 0.8920634920634921\n",
      "AUCPR: 0.8727399564779829\n",
      "Gini: 0.7841269841269842\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39443520167906054: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3556</td>\n",
       "      <td>(16.0/45.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>(1.0/49.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>(17.0/94.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1   Error          Rate\n",
       "0      0  29.0  16.0  0.3556   (16.0/45.0)\n",
       "1      1   1.0  48.0  0.0204    (1.0/49.0)\n",
       "2  Total  30.0  64.0  0.1809   (17.0/94.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.394435</td>\n",
       "      <td>0.849558</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.394435</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.583227</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.559556</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.304724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.394435</td>\n",
       "      <td>0.668750</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.519689</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.559556</td>\n",
       "      <td>0.821995</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.206758</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.304724</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.206758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.304724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold      value   idx\n",
       "0                        max f1   0.394435   0.849558  63.0\n",
       "1                        max f2   0.394435   0.923077  63.0\n",
       "2                  max f0point5   0.583227   0.853659  38.0\n",
       "3                  max accuracy   0.559556   0.819149  41.0\n",
       "4                 max precision   0.821437   1.000000   0.0\n",
       "5                    max recall   0.304724   1.000000  77.0\n",
       "6               max specificity   0.821437   1.000000   0.0\n",
       "7              max absolute_mcc   0.394435   0.668750  63.0\n",
       "8    max min_per_class_accuracy   0.519689   0.777778  48.0\n",
       "9   max mean_per_class_accuracy   0.559556   0.821995  41.0\n",
       "10                      max tns   0.821437  45.000000   0.0\n",
       "11                      max fns   0.821437  48.000000   0.0\n",
       "12                      max fps   0.206758  45.000000  93.0\n",
       "13                      max tps   0.304724  49.000000  77.0\n",
       "14                      max tnr   0.821437   1.000000   0.0\n",
       "15                      max fnr   0.821437   0.979592   0.0\n",
       "16                      max fpr   0.206758   1.000000  93.0\n",
       "17                      max tpr   0.304724   1.000000  77.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 52.13 %, avg score: 53.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821437</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.819103</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821283</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.817702</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820446</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819689</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.815750</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819062</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.803131</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.812150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815606</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>91.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.775477</td>\n",
       "      <td>1.438776</td>\n",
       "      <td>1.781341</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787795</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.807660</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>43.877551</td>\n",
       "      <td>78.134111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.767088</td>\n",
       "      <td>1.534694</td>\n",
       "      <td>1.716434</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.770431</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.797863</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>53.469388</td>\n",
       "      <td>71.643394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.695502</td>\n",
       "      <td>1.705215</td>\n",
       "      <td>1.712828</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.735571</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.777840</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>70.521542</td>\n",
       "      <td>71.282799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.595391</td>\n",
       "      <td>1.726531</td>\n",
       "      <td>1.716434</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.640185</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.741615</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>72.653061</td>\n",
       "      <td>71.643394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.528549</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>1.551020</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.553753</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.705642</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>-14.739229</td>\n",
       "      <td>55.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.452784</td>\n",
       "      <td>1.065760</td>\n",
       "      <td>1.473032</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.672321</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>6.575964</td>\n",
       "      <td>47.303207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.372550</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>1.395176</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.417976</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.633784</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>-4.081633</td>\n",
       "      <td>39.517625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.314809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346714</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.599336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>22.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.256470</td>\n",
       "      <td>0.213152</td>\n",
       "      <td>1.119048</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.291779</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.566383</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-78.684807</td>\n",
       "      <td>11.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226989</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.530277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010638         0.821150  1.918367   \n",
       "1         2                  0.021277         0.819103  1.918367   \n",
       "2         3                  0.031915         0.817702  1.918367   \n",
       "3         4                  0.042553         0.816795  1.918367   \n",
       "4         5                  0.053191         0.815750  1.918367   \n",
       "5         6                  0.106383         0.803131  1.918367   \n",
       "6         7                  0.148936         0.775477  1.438776   \n",
       "7         8                  0.202128         0.767088  1.534694   \n",
       "8         9                  0.297872         0.695502  1.705215   \n",
       "9        10                  0.404255         0.595391  1.726531   \n",
       "10       11                  0.500000         0.528549  0.852608   \n",
       "11       12                  0.595745         0.452784  1.065760   \n",
       "12       13                  0.702128         0.372550  0.959184   \n",
       "13       14                  0.797872         0.314809  0.000000   \n",
       "14       15                  0.893617         0.256470  0.213152   \n",
       "15       16                  1.000000         0.206758  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.918367       1.000000  0.821437                  1.000000   \n",
       "1          1.918367       1.000000  0.821128                  1.000000   \n",
       "2          1.918367       1.000000  0.818774                  1.000000   \n",
       "3          1.918367       1.000000  0.817417                  1.000000   \n",
       "4          1.918367       1.000000  0.816553                  1.000000   \n",
       "5          1.918367       1.000000  0.812150                  1.000000   \n",
       "6          1.781341       0.750000  0.787795                  0.928571   \n",
       "7          1.716434       0.800000  0.770431                  0.894737   \n",
       "8          1.712828       0.888889  0.735571                  0.892857   \n",
       "9          1.716434       0.900000  0.640185                  0.894737   \n",
       "10         1.551020       0.444444  0.553753                  0.808511   \n",
       "11         1.473032       0.555556  0.498313                  0.767857   \n",
       "12         1.395176       0.500000  0.417976                  0.727273   \n",
       "13         1.227755       0.000000  0.346714                  0.640000   \n",
       "14         1.119048       0.111111  0.291779                  0.583333   \n",
       "15         1.000000       0.000000  0.226989                  0.521277   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.821437      0.020408                 0.020408   91.836735   \n",
       "1           0.821283      0.020408                 0.040816   91.836735   \n",
       "2           0.820446      0.020408                 0.061224   91.836735   \n",
       "3           0.819689      0.020408                 0.081633   91.836735   \n",
       "4           0.819062      0.020408                 0.102041   91.836735   \n",
       "5           0.815606      0.102041                 0.204082   91.836735   \n",
       "6           0.807660      0.061224                 0.265306   43.877551   \n",
       "7           0.797863      0.081633                 0.346939   53.469388   \n",
       "8           0.777840      0.163265                 0.510204   70.521542   \n",
       "9           0.741615      0.183673                 0.693878   72.653061   \n",
       "10          0.705642      0.081633                 0.775510  -14.739229   \n",
       "11          0.672321      0.102041                 0.877551    6.575964   \n",
       "12          0.633784      0.102041                 0.979592   -4.081633   \n",
       "13          0.599336      0.000000                 0.979592 -100.000000   \n",
       "14          0.566383      0.020408                 1.000000  -78.684807   \n",
       "15          0.530277      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         91.836735  \n",
       "1         91.836735  \n",
       "2         91.836735  \n",
       "3         91.836735  \n",
       "4         91.836735  \n",
       "5         91.836735  \n",
       "6         78.134111  \n",
       "7         71.643394  \n",
       "8         71.282799  \n",
       "9         71.643394  \n",
       "10        55.102041  \n",
       "11        47.303207  \n",
       "12        39.517625  \n",
       "13        22.775510  \n",
       "14        11.904762  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_gbm_perf_cv2 = best_gbm_cv2.model_performance(test)\n",
    "print(best_gbm_perf_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.98\n",
      "0.8497109826589595\n"
     ]
    }
   ],
   "source": [
    "cv_rd_gbm_recall = round(48/49 , 2)\n",
    "cv_rd_gbm_precision = round(48/64, 2)\n",
    "cv_rd_gbm_f1 = 2*((cv_rd_gbm_precision * cv_rd_gbm_recall)/(cv_rd_gbm_precision + cv_rd_gbm_recall))\n",
    "\n",
    "print(cv_rd_gbm_precision)\n",
    "print(cv_rd_gbm_recall)\n",
    "print(cv_rd_gbm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify best performing GBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, Validation, Test split with full set of predictor fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n",
      "0.82\n",
      "0.8298795180722892\n"
     ]
    }
   ],
   "source": [
    "print(gs_gbm_precision)\n",
    "print(gs_gbm_recall)\n",
    "print(gs_gbm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, Validation, Test split with reduced set of predictor fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n",
      "0.82\n",
      "0.8298795180722892\n"
     ]
    }
   ],
   "source": [
    "print(gs_rd_gbm_precision)\n",
    "print(gs_rd_gbm_recall)\n",
    "print(gs_rd_gbm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation with all predictor fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "0.9\n",
      "0.858139534883721\n"
     ]
    }
   ],
   "source": [
    "print(cv_gbm_precision)\n",
    "print(cv_gbm_recall)\n",
    "print(cv_gbm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation with reduced set of predictor fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.98\n",
      "0.8497109826589595\n"
     ]
    }
   ],
   "source": [
    "print(cv_rd_gbm_precision)\n",
    "print(cv_rd_gbm_recall)\n",
    "print(cv_rd_gbm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Comparison\n",
    "When reviewing the performance of our best Logit and GBM models (with respect to F1 score) we find that our Logit model slightly outperforms our GBM model with respect to precision. However, our GBM model outperforms our Logit model with respect to Recall.\n",
    "\n",
    "Since in this example the cost of false negatives outweigh the cost of false positives, we would want to use the GBM model as identifies the greatest percentage of total heart disease patients while only slightly underperforming with respect to precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top performing Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84, 0.8936170212765957, 0.8659793814432989, None)"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred_logreg_sfm, average=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top performing GBM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "0.92\n",
      "0.8671264367816092\n"
     ]
    }
   ],
   "source": [
    "print(cv_gbm_precision)\n",
    "print(cv_gbm_recall)\n",
    "print(cv_gbm_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carsonransford/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_a1df closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.shutdown(prompt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vars = []\n",
    "for var in dir():\n",
    "    if not var.startswith('_'):\n",
    "        my_vars.append(var)\n",
    "        \n",
    "for x in my_vars:\n",
    "    del globals()[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
